"""
TRL í‘œì¤€ ë°ì´í„° ë¡œë” for GRPO training
"""

import logging
from typing import Dict, Any, List, Optional
from datasets import load_dataset, Dataset, DatasetDict
from transformers import AutoTokenizer, AutoProcessor
import json

logger = logging.getLogger(__name__)

class GRPODataLoader:
    """TRL í‘œì¤€ ë°ì´í„° ë¡œë” for GRPO training"""

    def __init__(
        self,
        model_name: str = "unsloth/Qwen3-0.6B-bnb-4bit",
        max_length: int = 2048
    ):
        self.model_name = model_name
        self.max_length = max_length

        # Load tokenizer only (TRL handles the rest)
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)

        # Set pad token if not exists
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token

        logger.info(f"âœ… TRL DataLoader initialized with model: {model_name}")
    
    def load_dataset(
        self, 
        dataset_name: str = "HuggingFaceH4/ultrafeedback_binarized",
        split: str = "train_prefs",
        max_samples: Optional[int] = None,
        streaming: bool = False
    ) -> DatasetDict:
        """
        Load dataset from HuggingFace Hub
        
        Args:
            dataset_name: Name of the dataset on HuggingFace Hub
            split: Dataset split to load
            max_samples: Maximum number of samples to load
            streaming: Whether to use streaming mode
        """
        logger.info(f"ğŸ“¦ Loading dataset: {dataset_name}")
        
        try:
            if streaming:
                dataset = load_dataset(dataset_name, split=split, streaming=True)
                if max_samples:
                    dataset = dataset.take(max_samples)
                return dataset
            else:
                dataset = load_dataset(dataset_name, split=split)
                if max_samples:
                    dataset = dataset.select(range(min(max_samples, len(dataset))))
                return dataset
                
        except Exception as e:
            logger.error(f"âŒ Failed to load dataset {dataset_name}: {e}")
            raise
    
    def load_custom_dataset(self, data_path: str) -> DatasetDict:
        """
        Load custom dataset from local files
        
        Args:
            data_path: Path to the dataset file (JSON, JSONL, CSV, etc.)
        """
        logger.info(f"ğŸ“ Loading custom dataset from: {data_path}")
        
        try:
            if data_path.endswith('.jsonl'):
                dataset = load_dataset('json', data_files=data_path)
            elif data_path.endswith('.json'):
                dataset = load_dataset('json', data_files=data_path)
            elif data_path.endswith('.csv'):
                dataset = load_dataset('csv', data_files=data_path)
            else:
                raise ValueError(f"Unsupported file format: {data_path}")
                
            return dataset
            
        except Exception as e:
            logger.error(f"âŒ Failed to load custom dataset: {e}")
            raise
    
    def prepare_grpo_data(self, dataset: Dataset) -> Dataset:
        """
        TRL í‘œì¤€ ë°ì´í„° í˜•ì‹ìœ¼ë¡œ ë³€í™˜

        TRL GRPOëŠ” ë‹¤ìŒ í˜•ì‹ì˜ ë°ì´í„°ë¥¼ ê¸°ëŒ€í•©ë‹ˆë‹¤:
        - prompt/chosen/rejected í•„ë“œ
        ë˜ëŠ”
        - messages í•„ë“œ (ëŒ€í™” í˜•ì‹)
        """
        logger.info("ğŸ”„ Converting to TRL standard format")

        def convert_to_trl_format(example):
            """Convert to TRL standard format"""
            # ì´ë¯¸ TRL í˜•ì‹ì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
            if "prompt" in example and "chosen" in example and "rejected" in example:
                return example

            # UltraFeedback í˜•ì‹ ë³€í™˜
            if "chosen" in example and "rejected" in example:
                chosen = example["chosen"]
                rejected = example["rejected"]

                if isinstance(chosen, list) and isinstance(rejected, list):
                    # chosenê³¼ rejectedê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° (ë©”ì‹œì§€ í˜•ì‹)
                    chosen_text = chosen[-1]["content"] if chosen else ""
                    rejected_text = rejected[-1]["content"] if rejected else ""
                    prompt = chosen[0]["content"] if chosen else ""

                    return {
                        "prompt": prompt,
                        "chosen": chosen_text,
                        "rejected": rejected_text
                    }

            # ê¸°ë³¸ì ìœ¼ë¡œ ì›ë³¸ ë°˜í™˜ (TRLì´ ì²˜ë¦¬)
            return example

        # ë°ì´í„° ë³€í™˜
        processed_dataset = dataset.map(
            convert_to_trl_format,
            desc="Converting to TRL format"
        )

        logger.info(f"âœ… Converted {len(processed_dataset)} samples to TRL format")
        return processed_dataset
    
    def get_sample_data(self, dataset_name: str = "HuggingFaceH4/ultrafeedback_binarized") -> Dict[str, Any]:
        """
        ìƒ˜í”Œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ TRL í˜•ì‹ í™•ì¸

        Args:
            dataset_name: í™•ì¸í•  ë°ì´í„°ì…‹ ì´ë¦„
        """
        logger.info(f"ğŸ” Getting sample data from {dataset_name}")

        try:
            # ì‘ì€ ìƒ˜í”Œ ë¡œë“œ
            dataset = self.load_dataset(dataset_name, max_samples=5)

            # ì²« ë²ˆì§¸ ìƒ˜í”Œ ë°˜í™˜
            if len(dataset) > 0:
                sample = dict(dataset[0])
                logger.info("âœ… Sample data retrieved successfully")
                logger.info(f"ğŸ“‹ Sample keys: {list(sample.keys())}")
                return sample
            else:
                logger.warning("âš ï¸ No samples found in dataset")
                return {}

        except Exception as e:
            logger.error(f"âŒ Failed to get sample data: {e}")
            return {}


def create_grpo_dataloader(
    model_name: str = "unsloth/Qwen3-0.6B-bnb-4bit",
    dataset_name: str = "HuggingFaceH4/ultrafeedback_binarized",
    max_samples: int = 1000,
    max_length: int = 2048
) -> tuple[GRPODataLoader, Dataset]:
    """
    TRL í‘œì¤€ ë°ì´í„° ë¡œë” ìƒì„± ë° ë°ì´í„°ì…‹ ë¡œë“œ

    Args:
        model_name: ëª¨ë¸ ì´ë¦„
        dataset_name: ë°ì´í„°ì…‹ ì´ë¦„
        max_samples: ìµœëŒ€ ìƒ˜í”Œ ìˆ˜
        max_length: ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´

    Returns:
        (data_loader, dataset) íŠœí”Œ
    """
    # ë°ì´í„° ë¡œë” ìƒì„±
    data_loader = GRPODataLoader(
        model_name=model_name,
        max_length=max_length
    )

    # ë°ì´í„°ì…‹ ë¡œë“œ ë° TRL í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    dataset = data_loader.load_dataset(dataset_name, max_samples=max_samples)
    processed_dataset = data_loader.prepare_grpo_data(dataset)

    return data_loader, processed_dataset


