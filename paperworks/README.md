# SPECTRA: Sinkhorn Projected Experts for Consistent TRAjectory Routing for Mixture-of-Experts

ë…¼ë¬¸ ì´ˆì•ˆ ì‘ì—… ë””ë ‰í† ë¦¬

## ğŸ“ íŒŒì¼ êµ¬ì„±

### ë³¸ë¬¸ (Main Paper)
1. **01_abstract.txt** - ì´ˆë¡ ë° ì£¼ìš” ê¸°ì—¬
2. **02_introduction.txt** - ì„œë¡  ë° ì—°êµ¬ ë™ê¸°
3. **03_related_work.txt** - ê´€ë ¨ ì—°êµ¬
4. **04_method.txt** - SPECTRA ë°©ë²•ë¡  ìƒì„¸ ì„¤ëª…
5. **05_experiments.txt** - ì‹¤í—˜ ì„¤ì • ë° í‰ê°€ ë°©ë²•
6. **06_results.txt** - ì‹¤í—˜ ê²°ê³¼ ë° ë¶„ì„
7. **07_discussion.txt** - ë…¼ì˜ ë° í•œê³„ì 
8. **08_conclusion.txt** - ê²°ë¡  ë° í–¥í›„ ì—°êµ¬ ë°©í–¥

### ë¶€ë¡ (Appendix)
9. **09_appendix.txt** - ìˆ˜í•™ì  ì„¸ë¶€ì‚¬í•­, ì¶”ê°€ ì‹¤í—˜, êµ¬í˜„ ì„¸ë¶€ì‚¬í•­

---

## ğŸ“Š ë…¼ë¬¸ ê°œìš”

### í•µì‹¬ ì•„ì´ë””ì–´
OSR (Orthogonal Sinkhorn Routing)ê³¼ Gram matrix ê¸°ë°˜ ì§êµì„± ì œì•½ì„ í†µí•´ MoE ëª¨ë¸ì˜ expert ì „ë¬¸í™”, ë‹¤ì–‘ì„±, ê·¸ë¦¬ê³  ìµœì  ë¶€í•˜ ë¶„ì‚°ì„ ë™ì‹œì— ë‹¬ì„±í•˜ëŠ” ìƒˆë¡œìš´ ë¼ìš°íŒ… ë©”ì»¤ë‹ˆì¦˜. OSRì€ í•™ìŠµ íŒŒë¼ë¯¸í„° ì—†ì´ ìˆ˜í•™ì ìœ¼ë¡œ expert ë¶„ë¦¬ë¥¼ ë³´ì¥í•˜ëŠ” repulsive cost functionì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

### ì£¼ìš” ê¸°ì—¬
1. **OSR (Orthogonal Sinkhorn Routing)**: Repulsive cost functionì„ í†µí•œ ìˆ˜í•™ì  expert ë¶„ë¦¬ ë³´ì¥ (í•™ìŠµ íŒŒë¼ë¯¸í„° 0ê°œ)
2. **Gram Matrix ê¸°ë°˜ Orthogonality Constraints**: Expert ê°„ ì§êµì„±ì„ ëª…ì‹œì ìœ¼ë¡œ ê°•ì œ
3. **GRU ê¸°ë°˜ Sequential Routing**: ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ expert ì„ íƒ ë° ì¼ê´€ëœ ê¶¤ì  ìƒì„±
4. **Expression Projector**: Expert ì „ë¬¸í™” ë°œê²¬ì„ ìœ„í•œ ì§êµ íˆ¬ì˜
5. **Comprehensive Ablation Study**: ê° ì»´í¬ë„ŒíŠ¸ì˜ ê¸°ì—¬ë„ ì •ëŸ‰í™”
6. **Modular Implementation**: ëª¨ë“  HuggingFace ëª¨ë¸ì— ì ìš© ê°€ëŠ¥

### ì£¼ìš” ê²°ê³¼ (ì˜ˆìƒ)
- Switch Transformer ëŒ€ë¹„ **X.X%** ì„±ëŠ¥ í–¥ìƒ
- Expert overlap **XX%** ê°ì†Œ
- Expert collapse ë°©ì§€ (collapse rate: **0%**)
- ê³„ì‚° ì˜¤ë²„í—¤ë“œ ìµœì†Œí™” (**X%**)
- ì „ë¬¸ ë„ë©”ì¸(ì½”ë“œ, ìˆ˜í•™, ê³¼í•™)ì—ì„œ ë” í° ì„±ëŠ¥ í–¥ìƒ

---

## ğŸ”¬ ì—°êµ¬ ë°©ë²•ë¡ 

### SPECTRA êµ¬ì„± ìš”ì†Œ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Input Token                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                â”‚
    â”Œâ”€â”€â–¼â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ GRU â”‚      â”‚ Expression   â”‚
    â”‚     â”‚      â”‚ Projector    â”‚
    â””â”€â”€â”¬â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Gram Matrix    â”‚
         â”‚ Speciality     â”‚
         â”‚ Penalty        â”‚
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Cosine         â”‚
         â”‚ Similarity     â”‚
         â”‚ Scoring        â”‚
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ OSR Cost       â”‚
         â”‚ (Repulsion)    â”‚
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Sinkhorn       â”‚
         â”‚ Optimization   â”‚
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Top-k          â”‚
         â”‚ Selection      â”‚
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Expert         â”‚
         â”‚ Execution      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ìˆ˜í•™ì  ì •ì‹í™”

**Gram Matrix**:
```
G = R Â· R^T  âˆˆ â„^(EÃ—E)
```

**OSR Repulsive Cost** (replaces separate speciality penalty):
```
Cost = -Similarity + Î» Â· Repulsion
Repulsion = |Similarity| @ (Gram(E_expr) âŠ™ (1 - I))Â²
```

**Sinkhorn Optimization**:
```
Q = Sinkhorn(Cost)  # Doubly stochastic matrix
```

**Routing Weights**:
```
w = topk(Q, k)  # From Sinkhorn output
```

---

## ğŸ“ˆ ì‹¤í—˜ ì„¤ì •

### ëª¨ë¸
- GPT-2-Medium (345M)
- LLaMA-2-7B
- Mixtral-8x7B (router êµì²´)

### ë°ì´í„°ì…‹
**Training**: The Pile (100B tokens)

**Evaluation**:
- Language Understanding: MMLU, HellaSwag, ARC, PIQA, BoolQ
- Code: HumanEval, MBPP
- Math: GSM8K, MATH
- Science: PubMedQA, SciFact

### Baseline
- Switch Transformer (Top-1, Top-2)
- Expert Choice Routing
- Hash Routing
- Dense MLP (upper bound)

### Ablation Variants
- SPECTRA w/o Expression
- SPECTRA w/o GRU (Sequential Router)
- SPECTRA w/o OSR (Repulsive Cost)
- SPECTRA w/o Repulsion (Î»=0)
- SPECTRA w/o Orthogonal Constraint

---

## ğŸ’» êµ¬í˜„

### ì½”ë“œ êµ¬ì¡°
```
models/
â”œâ”€â”€ g3moe_model.py          # í•µì‹¬ G3MoE êµ¬í˜„
â”œâ”€â”€ spectra.py         # SPECTRA ë¼ìš°íŒ… (ëª¨ë“ˆí™”)
â”œâ”€â”€ spectra_ablation.py    # Ablation ë³€í˜•
â””â”€â”€ g3moe_config.py         # ì„¤ì • í´ë˜ìŠ¤

eval/
â”œâ”€â”€ information_theoretic_analysis.py  # Expert ë¶„ì„
â””â”€â”€ benchmark_runner.py                # í‰ê°€ í•˜ë„¤ìŠ¤

sft/
â”œâ”€â”€ trainer.py              # í•™ìŠµ ë£¨í”„
â””â”€â”€ config/                 # í•™ìŠµ ì„¤ì •
```

### ì£¼ìš” í•˜ì´í¼íŒŒë¼ë¯¸í„°
```yaml
model:
  num_experts: 8
  num_experts_per_tok: 2
  router_dim: 128
  
loss:
  router_entropy_coef: 0.1  # Entropy minimization for sharp routing
  ortho_loss_coef: 0.01      # Optional orthogonal loss on projector weights
  osr_repulsion_weight: 0.5  # Repulsive cost function coefficient

# Note: Unlike traditional MoE, SPECTRA does not require aux_loss_coef or
# speciality_loss_coef. OSR structurally enforces load balancing and expert
# separation without explicit loss terms.
  
optimizer:
  lr_router: 5e-5
  lr_expert: 1e-5
  lr_other: 1e-5
```

---

## ğŸ“ ë…¼ë¬¸ ì‘ì„± ì§„í–‰ ìƒí™©

### âœ… ì™„ë£Œ
- [x] Abstract
- [x] Introduction
- [x] Related Work
- [x] Method
- [x] Experiments
- [x] Results (í…œí”Œë¦¿)
- [x] Discussion
- [x] Conclusion
- [x] Appendix

### ğŸ”„ ì§„í–‰ ì¤‘
- [ ] ì‹¤ì œ ì‹¤í—˜ ì‹¤í–‰
- [ ] ê²°ê³¼ ë°ì´í„° ìˆ˜ì§‘
- [ ] í†µê³„ ë¶„ì„
- [ ] ì‹œê°í™” ìƒì„±

### ğŸ“‹ ì˜ˆì •
- [ ] LaTeX ë³€í™˜
- [ ] ê·¸ë¦¼ ë° í‘œ ìƒì„±
- [ ] ì°¸ê³ ë¬¸í—Œ ì •ë¦¬
- [ ] ì´ˆë¡ ìµœì í™”
- [ ] ë™ë£Œ ë¦¬ë·°
- [ ] íˆ¬ê³  ì¤€ë¹„

---

## ğŸ¯ íˆ¬ê³  ëª©í‘œ

### ì¶”ì²œ í•™íšŒ/ì €ë„
1. **NeurIPS 2025** (Deadline: ~May 2025)
   - Top-tier ML conference
   - MoE/Efficient models ê´€ë ¨ ê°•ì„¸

2. **ICML 2025** (Deadline: ~February 2025)
   - Theory + empirical work ê· í˜•
   - Routing mechanism í˜ì‹  ê°•ì¡°

3. **ICLR 2026** (Deadline: ~October 2025)
   - Representation learning ê´€ì 
   - Orthogonality ì´ë¡  ê°•ì¡°

4. **JMLR** (Journal, Rolling submission)
   - ê¸´ í˜•ì‹ ë…¼ë¬¸ ê°€ëŠ¥
   - í¬ê´„ì  ablation study ì í•©

### ì˜ˆìƒ ë…¼ë¬¸ ê¸¸ì´
- Main paper: ~8-10 pages (conference format)
- With appendix: ~20-25 pages
- Full version (journal): ~35-40 pages

---

## ğŸ” í•µì‹¬ ë©”ì‹œì§€

### 1ë¬¸ì¥ ìš”ì•½
> Gram matrix ê¸°ë°˜ ì§êµì„± ì œì•½ì„ í†µí•´ MoE expertì˜ ì „ë¬¸í™”ì™€ ë‹¤ì–‘ì„±ì„ ë™ì‹œì— ë‹¬ì„±í•˜ëŠ” ìƒˆë¡œìš´ ë¼ìš°íŒ… ë©”ì»¤ë‹ˆì¦˜

### 3ë¬¸ì¥ ìš”ì•½
> ê¸°ì¡´ MoE ë¼ìš°íŒ…ì€ expert collapseì™€ ì „ë¬¸í™” ë¶€ì¡± ë¬¸ì œë¡œ ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤.
> SPECTRAëŠ” OSR (Orthogonal Sinkhorn Routing)ê³¼ Gram matrixë¥¼ í™œìš©í•œ ì§êµì„± ì œì•½, ê·¸ë¦¬ê³  GRU ê¸°ë°˜ sequential routingì„ ê²°í•©í•˜ì—¬ ì´ ë¬¸ì œë¥¼ í•´ê²°í•œë‹¤. OSRì€ í•™ìŠµ íŒŒë¼ë¯¸í„° ì—†ì´ repulsive cost functionì„ í†µí•´ ìˆ˜í•™ì ìœ¼ë¡œ expert ë¶„ë¦¬ë¥¼ ë³´ì¥í•œë‹¤.
> ì¢…í•©ì ì¸ ablation studyë¥¼ í†µí•´ ê° ì»´í¬ë„ŒíŠ¸ê°€ ì„±ëŠ¥ì— ê¸°ì—¬í•¨ì„ ê²€ì¦í•˜ê³ , íŠ¹íˆ ì „ë¬¸ ë„ë©”ì¸ì—ì„œ í° ì„±ëŠ¥ í–¥ìƒì„ ë‹¬ì„±í–ˆë‹¤.

### ì—˜ë¦¬ë² ì´í„° í”¼ì¹˜ (30ì´ˆ)
> "MoE ëª¨ë¸ì˜ expertë“¤ì´ ë¹„ìŠ·í•œ ê¸°ëŠ¥ì„ í•™ìŠµí•˜ê±°ë‚˜ ì¼ë¶€ë§Œ ì‚¬ìš©ë˜ëŠ” ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.
> ì €í¬ëŠ” OSR (Orthogonal Sinkhorn Routing)ê³¼ Gram matrixë¥¼ ì‚¬ìš©í•´ expertë“¤ì´ ì§êµí•˜ë„ë¡ ê°•ì œí•˜ê³  ìµœì  ë¶€í•˜ ë¶„ì‚°ì„ ë‹¬ì„±í•˜ëŠ” SPECTRAë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. OSRì€ í•™ìŠµ íŒŒë¼ë¯¸í„° ì—†ì´ repulsive cost functionì„ í†µí•´ ìˆ˜í•™ì ìœ¼ë¡œ expert ë¶„ë¦¬ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤.
> ì´ë¥¼ í†µí•´ ê° expertê°€ ì½”ë“œ, ìˆ˜í•™, ê³¼í•™ ë“± ëª…í™•í•œ ë„ë©”ì¸ì„ ì „ë¬¸í™”í•˜ë„ë¡ ìœ ë„í•˜ê³ ,
> Switch Transformer ëŒ€ë¹„ X%ì˜ ì„±ëŠ¥ í–¥ìƒì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.
> ë”ë¶ˆì–´ ëª¨ë“  HuggingFace ëª¨ë¸ì— ì ìš© ê°€ëŠ¥í•œ ëª¨ë“ˆí™”ëœ êµ¬í˜„ì„ ì œê³µí•©ë‹ˆë‹¤."

---

## ğŸ“š ì°¸ê³  ìë£Œ

### í•µì‹¬ ì„ í–‰ ì—°êµ¬
1. **Switch Transformer** (Fedus et al., 2021)
   - í‘œì¤€ MoE routing baseline
   - Top-1 routing + load balancing loss

2. **Mixtral 8x7B** (Jiang et al., 2024)
   - ì˜¤í”ˆì†ŒìŠ¤ sparse MoE
   - ì‹¤ìš©ì  ì„±ëŠ¥ ì…ì¦

3. **Expert Choice Routing** (Zhou et al., 2022)
   - ì—­ë°©í–¥ routing íŒ¨ëŸ¬ë‹¤ì„
   - Load balancing ê°œì„ 

4. **Sparse Upcycling** (Komatsuzaki et al., 2022)
   - Dense â†’ MoE ë³€í™˜
   - íš¨ìœ¨ì  í•™ìŠµ ë°©ë²•

### ìˆ˜í•™ì  ë°°ê²½
- **Gram-Schmidt Orthogonalization**: ì§êµ ê¸°ì € ìƒì„±
- **Gram Matrix**: ë²¡í„° ê°„ ë‚´ì  í–‰ë ¬
- **Frobenius Norm**: í–‰ë ¬ norm ê³„ì‚°

---

## ğŸ”§ ì‹¤í—˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Pre-ì‹¤í—˜
- [ ] ë°ì´í„°ì…‹ ì¤€ë¹„ (The Pile)
- [ ] í‰ê°€ ë²¤ì¹˜ë§ˆí¬ ì„¤ì •
- [ ] Baseline ëª¨ë¸ í•™ìŠµ
- [ ] Hyperparameter grid search
- [ ] ì½”ë“œ ë””ë²„ê¹… ë° ê²€ì¦

### ë³¸ ì‹¤í—˜
- [ ] GPT-2-Medium í•™ìŠµ (Switch, SPECTRA, Ablations)
- [ ] LLaMA-2-7B í•™ìŠµ
- [ ] Mixtral-8x7B router êµì²´
- [ ] ì „ì²´ ë²¤ì¹˜ë§ˆí¬ í‰ê°€
- [ ] Expert ë¶„ì„ (specialization, usage, etc.)

### Post-ì‹¤í—˜
- [ ] í†µê³„ì  ìœ ì˜ì„± ê²€ì •
- [ ] ê²°ê³¼ ì‹œê°í™” (t-SNE, heatmaps, etc.)
- [ ] Error analysis
- [ ] Qualitative examples
- [ ] ìµœì¢… ì„±ëŠ¥ ê²€ì¦

### ì¬í˜„ì„±
- [ ] Random seed ì„¤ì •
- [ ] í™˜ê²½ ì„¤ì • ë¬¸ì„œí™”
- [ ] ëª¨ë“  config íŒŒì¼ ì €ì¥
- [ ] Checkpoint ì €ì¥
- [ ] Logging ì™„ë¹„

---

## ğŸ“Š ì˜ˆìƒ ê²°ê³¼ (í…œí”Œë¦¿)

ì‹¤í—˜ ì™„ë£Œ í›„ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ ê¸°ì…:

### Main Results
| Model | MMLU | HellaSwag | HumanEval | GSM8K | Avg |
|-------|------|-----------|-----------|-------|-----|
| Switch Top-2 | XX.X | XX.X | XX.X | XX.X | XX.X |
| **SPECTRA** | **XX.X** | **XX.X** | **XX.X** | **XX.X** | **XX.X** |
| Improvement | +X.X% | +X.X% | +X.X% | +X.X% | +X.X% |

### Expert Specialization
| Metric | Switch | SPECTRA | Improvement |
|--------|--------|----------|-------------|
| Expert Entropy | X.XX | X.XX | +X.X% |
| Expert Overlap | XX% | XX% | -XX% |
| Gram Orthogonality | XX.X | XX.X | +XX% |
| Collapse Rate | XX% | 0% | -XX% |

---

## âœ‰ï¸ ì—°ë½ì²˜

ì‹¤í—˜ ì§„í–‰ ë° ë…¼ë¬¸ ì‘ì„± ê´€ë ¨ ë¬¸ì˜:
- ì‹¤í—˜ ë‹´ë‹¹: [ì´ë¦„]
- ë…¼ë¬¸ ì‘ì„±: [ì´ë¦„]
- ì½”ë“œ ë¦¬ë·°: [ì´ë¦„]

---

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ë³¸ ì—°êµ¬ ì½”ë“œ ë° ë…¼ë¬¸ ì´ˆì•ˆì€ Apache 2.0 ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤.

---

## ğŸ™ ê°ì‚¬ì˜ ë§

- HuggingFace Transformers íŒ€
- EleutherAI (The Pile ë°ì´í„°ì…‹)
- ê³„ì‚° ìì› ì œê³µ: [ê¸°ê´€ëª…]
- ë…¼ë¬¸ ë¦¬ë·°: [ë¦¬ë·°ì–´ë“¤]

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-11-11  
**ë²„ì „**: 0.1 (ì´ˆì•ˆ)  
**ìƒíƒœ**: ì‹¤í—˜ ëŒ€ê¸° ì¤‘

