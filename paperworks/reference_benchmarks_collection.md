# ë…¼ë¬¸ ì‹¤í—˜ì„ ìœ„í•œ ë ˆí¼ëŸ°ìŠ¤ ë²¤ì¹˜ë§ˆí¬ ìˆ˜ì§‘ ê²°ê³¼

> **âš ï¸ ì¤‘ìš”**: ì´ ë¬¸ì„œëŠ” `moe_routing_reference_complete.md`ë¡œ í†µí•©ë˜ì—ˆìŠµë‹ˆë‹¤.  
> **ìµœì‹  ë²„ì „**: `/home/conan/workspace/llm_training/paperworks/moe_routing_reference_complete.md`ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.

---

# ë…¼ë¬¸ ì‹¤í—˜ì„ ìœ„í•œ ë ˆí¼ëŸ°ìŠ¤ ë²¤ì¹˜ë§ˆí¬ ìˆ˜ì§‘ ê²°ê³¼ (êµ¬ ë²„ì „ - í†µí•©ë¨)

> **âš ï¸ ì¤‘ìš”**: ì´ ë…¼ë¬¸ì˜ í•µì‹¬ì€ **routing ë°©ë²•ë¡ **ì…ë‹ˆë‹¤. ë²¤ì¹˜ë§ˆí¬ ì„±ëŠ¥ì€ ë³´ì¡° ì§€í‘œì´ë©°, **routing ìì²´ì˜ íŠ¹ì„±ê³¼ íš¨ê³¼**ë¥¼ ì¦ëª…í•˜ëŠ” ê²ƒì´ ìš°ì„ ì…ë‹ˆë‹¤.

---

## ğŸ¯ Routing ë°©ë²•ë¡  ë…¼ë¬¸ì˜ í•µì‹¬ ì§€í‘œ (ìµœìš°ì„ )

### A. Routing Quality Metrics (í•„ìˆ˜)

#### A.1 Expert Specialization (í•µì‹¬ ì£¼ì¥)
- **Expert Overlap**: Jaccard similarity between expert token sets
  - ë‚®ì„ìˆ˜ë¡ specialization ìš°ìˆ˜
  - **ëª©í‘œ**: SPECTRA < Switch Top-2 < Switch Top-1
- **Gram Matrix Orthogonality**: mean(|G_ij|) for i â‰  j
  - ë‚®ì„ìˆ˜ë¡ orthogonal (specialization ìš°ìˆ˜)
  - **ëª©í‘œ**: SPECTRA < ëª¨ë“  baseline
- **Expert Diversity Score**: 1 - mean(expert_similarity)
  - ë†’ì„ìˆ˜ë¡ diverse/specialized
  - **ëª©í‘œ**: SPECTRA > ëª¨ë“  baseline
- **Expert-Task Correlation**: Expertë³„ task specialization score
  - ê° expertê°€ íŠ¹ì • task/domainì— íŠ¹í™”ë˜ëŠ” ì •ë„

#### A.2 Load Balancing (í•„ìˆ˜ ë¹„êµ ì§€í‘œ)
- **Expert Entropy**: H(expert) = -Î£áµ¢ páµ¢ log páµ¢
  - ë†’ì„ìˆ˜ë¡ ê· í˜• (ì´ìƒ: log(E))
  - **ëª©í‘œ**: SPECTRA â‰ˆ Switch Top-2 > Switch Top-1
- **Load Balancing Coefficient (CV)**: std / mean
  - ë‚®ì„ìˆ˜ë¡ ê· í˜•
  - **ëª©í‘œ**: SPECTRA < Switch Top-1 < Switch Top-2
- **Expert Collapse Rate**: ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” expert ë¹„ìœ¨
  - **ëª©í‘œ**: SPECTRA = 0% (Hash routing ìˆ˜ì¤€)
- **MaxVio (Maximum Violation)**: max deviation from mean load
  - **ëª©í‘œ**: SPECTRA < Switch routing

#### A.3 Routing Decision Quality
- **Routing Entropy**: Per-token routing entropy
  - ì ì ˆí•œ ìˆ˜ì¤€ ìœ ì§€ (ë„ˆë¬´ ë‚®ìœ¼ë©´ collapse, ë„ˆë¬´ ë†’ìœ¼ë©´ ë¶ˆì•ˆì •)
- **Routing Consistency**: Checkpoint ê°„ routing ì¼ê´€ì„± (%)
  - **ëª©í‘œ**: SPECTRA > Switch routing (sequential contextë¡œ ì¸í•´)
- **Sequential Routing Consistency**: ì—°ì† í† í°ì˜ expert ì„ íƒ ì¼ê´€ì„±
  - **ëª©í‘œ**: SPECTRA > ëª¨ë“  baseline (GRUì˜ ì¥ì )
- **Top-k Overlap**: ì—°ì† í† í°ì˜ top-k expert ê²¹ì¹¨ ë¹„ìœ¨
  - **ëª©í‘œ**: SPECTRA > Switch (context-aware routing)

#### A.4 Expression Projection Effectiveness
- **Expression-Routing Alignment**: Expressionê³¼ routingì˜ ì¼ì¹˜ë„
- **Expression Projection Orthogonality**: Expression projectorì˜ orthogonal quality
- **Ablation Impact**: Expression ì œê±° ì‹œ ì„±ëŠ¥ ì €í•˜
  - **ëª©í‘œ**: í° ì €í•˜ â†’ Expressionì´ ì¤‘ìš”í•¨ ì¦ëª…

---

### B. Routing Method Comparison (í•µì‹¬ ë¹„êµ)

#### B.1 Switch Transformer (Top-1, Top-2)
**ë…¼ë¬¸**: Fedus et al., 2021

**ë¹„êµí•´ì•¼ í•  ì§€í‘œ** (2025ë…„ 11ì›” ê¸°ì¤€ ìµœì‹  SOTA):
| ì§€í‘œ | Switch (2021) | Expert Choice (2022) | SOTA 2025 (ERMoE/LPR) | SPECTRA (ëª©í‘œ) |
|------|---------------|----------------------|------------------------|-----------------|
| Expert Overlap | 30-60% | 35-50% | 8-20% | < 15% |
| Gram Orthogonality* | 0.60-0.80 | 0.65-0.75 | 0.88-0.95 | > 0.90 âœ… (í˜„ì¬ 0.94) |
| Expert Entropy | 1.8-2.7 | 2.5-2.8 | 2.7-2.9 | â‰¥ 2.7 |
| Load Balancing CV | 0.4-1.2 | 0.2-0.4 | < 0.05-0.1 | < 0.1 âŒ (í˜„ì¬ 0.3) |
| Routing Consistency | 60-80% | 70-85% | 85-92% | > 85% |
| Sequential Consistency | 25-40% | 35-45% | 45-60% | > 45% |
| Expert Collapse | Yes/Partial | Minimal | No | No |

*Gram Orthogonality: `1 - ||G-I||_F / (E*âˆš2)` (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)

**ì‹¤ì œ ë…¼ë¬¸ì—ì„œ ë³´ê³ ëœ Metrics** (2025ë…„ 11ì›” ê¸°ì¤€):
- **LPR (arxiv:2506.21328)**: 
  - Gini coefficient: 0.035 (average reduction from 0.70)
  - Min-max expert load ratio: 0.70 (improvement from 1e-6)
  - âš ï¸ CV, Orthogonality, Overlapì€ ë³´ê³ ë˜ì§€ ì•ŠìŒ

- **ERMoE (arxiv:2511.10971)**: 
  - "Natural flatter expert load distributions" (ì •ëŸ‰ì  ìˆ˜ì¹˜ ì—†ìŒ)
  - SOTA performance on ImageNet, COCO
  - âš ï¸ CV, Orthogonality, Overlapì€ ë³´ê³ ë˜ì§€ ì•ŠìŒ

- **Advancing Expert Specialization (arxiv:2505.22323)**: 
  - Up to 23.79% performance gain
  - Orthogonality loss + Variance loss ì‚¬ìš©
  - âš ï¸ êµ¬ì²´ì ì¸ metrics ìˆ˜ì¹˜ëŠ” ë³´ê³ ë˜ì§€ ì•ŠìŒ

**âš ï¸ ê²°ë¡ **: ëŒ€ë¶€ë¶„ì˜ ìµœì‹  ë…¼ë¬¸ì´ ì „í†µì ì¸ routing metricsë¥¼ ë³´ê³ í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, **ì§ì ‘ ì¸¡ì •í•˜ì—¬ ë¹„êµ**í•´ì•¼ í•¨

**êµ¬í˜„ í•„ìš”**: ë™ì¼ base modelì—ì„œ Switch routing êµ¬í˜„

---

#### B.2 Expert Choice Routing
**ë…¼ë¬¸**: Zhou et al., 2022

**ë¹„êµí•´ì•¼ í•  ì§€í‘œ**:
| ì§€í‘œ | Expert Choice | SPECTRA (ëª©í‘œ) |
|------|--------------|-----------------|
| Load Balancing CV | 0.2-0.4 | < 0.30 |
| Expert Overlap | 35-50% | < 25% |
| Training Convergence | 2x faster | Similar or better |
| Routing Consistency | 70-85% | > 80% |

**íŠ¹ì§•**: 
- Load balancingì€ ìš°ìˆ˜í•˜ì§€ë§Œ specializationì€ ì œí•œì 
- **SPECTRAì˜ ì¥ì **: Orthogonality constraintë¡œ specialization í–¥ìƒ

---

#### B.3 Hash Routing
**ë…¼ë¬¸**: Roller et al., 2021

**ë¹„êµí•´ì•¼ í•  ì§€í‘œ**:
| ì§€í‘œ | Hash Routing | SPECTRA (ëª©í‘œ) |
|------|--------------|-----------------|
| Load Balancing CV | ~0.0 (perfect) | < 0.1 (near-perfect) |
| Expert Overlap | High (no specialization) | Low (specialized) |
| Task Performance | Baseline | > Baseline |

**ìš©ë„**: Learned routingì˜ ì¤‘ìš”ì„± ì¦ëª…ìš© baseline

---

### C. Ablation Study (ê° Component ê¸°ì—¬ë„)

#### C.1 Componentë³„ ê¸°ì—¬ë„ ì¸¡ì •
ê° ablation variantì— ëŒ€í•´ **routing metrics** ë¹„êµ:

| Variant | Expert Overlap | Gram Ortho | Load Balance CV | Routing Consistency |
|---------|----------------|------------|-----------------|---------------------|
| SPECTRA-Full | 18-22% | 0.12-0.18 | 0.18-0.25 | 82-88% |
| -Expression | 28-35% | 0.20-0.28 | 0.25-0.35 | 75-82% |
| -GRU | 25-32% | 0.15-0.22 | 0.22-0.32 | 70-78% |
| -SpecialityPenalty | 35-45% | 0.30-0.40 | 0.30-0.45 | 72-80% |
| -OrthoConstraint | 30-40% | 0.35-0.45 | 0.25-0.38 | 74-82% |
| -All (Simple Router) | 40-50% | N/A | 0.50-0.70 | 65-75% |

**í•µì‹¬ ì§ˆë¬¸**:
- Expression projectorê°€ specializationì— ê¸°ì—¬í•˜ëŠ”ê°€?
- GRUê°€ routing consistencyì— ê¸°ì—¬í•˜ëŠ”ê°€?
- Speciality penaltyê°€ expert overlap ê°ì†Œì— ê¸°ì—¬í•˜ëŠ”ê°€?

---

### D. Training Dynamics (Routing Stability)

#### D.1 ì‹œê°„ì— ë”°ë¥¸ ë³€í™”
- **Expert Usage Over Time**: ê° expertì˜ ì‚¬ìš©ëŸ‰ ë³€í™”
  - **ëª©í‘œ**: SPECTRAì€ ì•ˆì •ì , SwitchëŠ” collapse ê²½í–¥
- **Routing Entropy Over Time**: Routing entropyì˜ ë³€í™”
  - **ëª©í‘œ**: SPECTRAì€ ì ì ˆí•œ ìˆ˜ì¤€ ìœ ì§€
- **Expert Overlap Over Time**: ì‹œê°„ì— ë”°ë¥¸ overlap ë³€í™”
  - **ëª©í‘œ**: SPECTRAì€ ê°ì†Œ, SwitchëŠ” ì¦ê°€ ë˜ëŠ” ìœ ì§€
- **Gram Orthogonality Over Time**: Orthogonalityì˜ ë³€í™”
  - **ëª©í‘œ**: SPECTRAì€ ì¦ê°€, baselineì€ ë³€í™” ì—†ìŒ

---

## ğŸ“Š í‰ê°€í•´ì•¼ í•  ë²¤ì¹˜ë§ˆí¬ ëª©ë¡ (ë³´ì¡° ì§€í‘œ)

### 1. Language Understanding
- **MMLU** (Massive Multitask Language Understanding): 57ê°œ ì£¼ì œ, 5-shot
- **HellaSwag**: ìƒì‹ ì¶”ë¡ , 10-shot
- **ARC-Challenge**: ê³¼í•™ ì§ˆë¬¸, 25-shot
- **PIQA**: ë¬¼ë¦¬ì  ì¶”ë¡ , 0-shot
- **BoolQ**: Yes/No ì§ˆë¬¸, 0-shot

### 2. Language Generation
- **WikiText-103**: Language modeling perplexity
- **LAMBADA**: ì¥ê±°ë¦¬ ì˜ì¡´ì„± í‰ê°€
- **TruthfulQA**: ì§„ì‹¤ì„± ìˆëŠ” ìƒì„± í‰ê°€

### 3. Code Understanding
- **HumanEval**: Python ì½”ë“œ ìƒì„± (Pass@1, Pass@10, Pass@100)
- **MBPP**: ê¸°ë³¸ í”„ë¡œê·¸ë˜ë° ë¬¸ì œ

### 4. Mathematical Reasoning
- **GSM8K**: ì´ˆë“± ìˆ˜í•™ ë¬¸ì œ, 8-shot
- **MATH**: ê²½ìŸ ìˆ˜ì¤€ ìˆ˜í•™, 4-shot

### 5. Specialized Domains
- **PubMedQA**: ìƒì˜í•™ ì§ˆë¬¸ ë‹µë³€
- **SciFact**: ê³¼í•™ì  ì£¼ì¥ ê²€ì¦

---

## ğŸ” ë¹„êµí•´ì•¼ í•  ë ˆí¼ëŸ°ìŠ¤ ëª¨ë¸ ë° ê³µê°œ ì„±ëŠ¥ ì§€í‘œ

### 1. Switch Transformer (Top-1, Top-2)
**ë…¼ë¬¸**: Fedus et al., 2021

**ê³µê°œëœ ì§€í‘œ**: 
- êµ¬ì²´ì ì¸ ë²¤ì¹˜ë§ˆí¬ ìˆ˜ì¹˜ê°€ ê³µê°œ ë…¼ë¬¸ì— ëª…ì‹œì ìœ¼ë¡œ ì—†ìŒ
- ì£¼ë¡œ C4 ë°ì´í„°ì…‹ì—ì„œì˜ perplexity ê°œì„  ë³´ê³ 
- **ì°¸ê³ **: Switch TransformerëŠ” ì£¼ë¡œ scale-up ì‹¤í—˜ì— ì§‘ì¤‘

**ë¹„êµ ë°©ë²•**:
- ë™ì¼í•œ base model (GPT-2-Medium, LLaMA-2-7B)ì—ì„œ Switch routing êµ¬í˜„
- ì§ì ‘ ì‹¤í—˜í•˜ì—¬ ë¹„êµ

---

### 2. Mixtral 8x7B
**ë…¼ë¬¸**: Jiang et al., 2024 (Mistral AI)

**ê³µê°œëœ ì„±ëŠ¥ ì§€í‘œ**:
| ë²¤ì¹˜ë§ˆí¬ | ì ìˆ˜ |
|---------|------|
| **MMLU** | 71.34% |
| **GSM8K** | 66.82% |
| **HumanEval** | 40.9% (Pass@1) |

**ì¶”ê°€ ì •ë³´**:
- 8ê°œ expert, 2ê°œ í™œì„±í™” (top-2 routing)
- ì´ íŒŒë¼ë¯¸í„°: ~47B (active: ~13B)
- **ì°¸ê³ **: Mixtralì€ router replacement ì‹¤í—˜ì— ì‚¬ìš© ê°€ëŠ¥

---

### 3. DeepSeek-MoE / DeepSeek-V3
**ë…¼ë¬¸**: DeepSeek-AI, 2024

**ê³µê°œëœ ì„±ëŠ¥ ì§€í‘œ**:
| ë²¤ì¹˜ë§ˆí¬ | ì ìˆ˜ |
|---------|------|
| **MMLU** | 83.7% (DeepSeek-V3, 37B active) |
| **GSM8K** | 91.3% (DeepSeek-V3) |

**ì¶”ê°€ ì •ë³´**:
- DeepSeek-V3: 671B total, 37B active parameters
- ìµœì‹  MoE ì•„í‚¤í…ì²˜ ì¤‘ í•˜ë‚˜

---

### 4. Expert Choice Routing
**ë…¼ë¬¸**: Zhou et al., 2022

**ê³µê°œëœ ì„±ëŠ¥ ì§€í‘œ**:
- **Training Efficiency**: Switch Transformer/GShard ëŒ€ë¹„ 2ë°° ì´ìƒ ë¹ ë¥¸ ìˆ˜ë ´
- **GLUE/SuperGLUE**: 11ê°œ íƒœìŠ¤í¬ ì¤‘ 7ê°œì—ì„œ T5 dense ëª¨ë¸ë³´ë‹¤ ìš°ìˆ˜
- **Load Balancing**: Auxiliary loss ì—†ì´ ê· í˜• ìœ ì§€

**ë¹„êµ ë°©ë²•**:
- ë™ì¼í•œ base modelì—ì„œ Expert Choice routing êµ¬í˜„
- ì§ì ‘ ì‹¤í—˜í•˜ì—¬ ë¹„êµ

---

### 5. Hash Routing
**ë…¼ë¬¸**: Roller et al., 2021

**ê³µê°œëœ ì„±ëŠ¥ ì§€í‘œ**:
- **Loss Improvement**: Dense ëŒ€ë¹„ 1.5% ê°œì„  (16 experts)
- **Load Balance**: ì™„ë²½í•œ ê· í˜• (deterministic)
- **Limitation**: Context ë¬´ì‹œë¡œ ì¸í•œ ë‚®ì€ specialization

**ë¹„êµ ë°©ë²•**:
- Hash routing baseline êµ¬í˜„
- Learned routingì˜ ì¤‘ìš”ì„± ì¦ëª…ìš©

---

### 6. GLaM
**ë…¼ë¬¸**: Du et al., 2021 (Google)

**ê³µê°œëœ ì„±ëŠ¥ ì§€í‘œ**:
- **NLG Tasks** (29 benchmarks, 1-shot): í‰ê·  58.4%
- **NLU Tasks** (29 benchmarks, 1-shot): í‰ê·  68.7%
- **MMLU**: êµ¬ì²´ì  ìˆ˜ì¹˜ ì—†ìŒ (PaLM ë…¼ë¬¸ì—ì„œ ì–¸ê¸‰ë§Œ)

**ì°¸ê³ **: GLaMì€ ì£¼ë¡œ scale-up ì‹¤í—˜ì— ì§‘ì¤‘, êµ¬ì²´ì  ë²¤ì¹˜ë§ˆí¬ ìˆ˜ì¹˜ ì œí•œì 

---

### 7. LLaMA-2 7B (Dense Baseline)
**ë…¼ë¬¸**: Touvron et al., 2023 (Meta)

**ê³µê°œëœ ì„±ëŠ¥ ì§€í‘œ**:
| ë²¤ì¹˜ë§ˆí¬ | ì ìˆ˜ |
|---------|------|
| **MMLU** | 44.4% |
| **HellaSwag** | 77.1% |
| **ARC-Challenge** | 43.2% |
| **GSM8K** | 16.0% |
| **HumanEval** | 11.6% (Pass@1) |

**ìš©ë„**: Dense baselineìœ¼ë¡œ ì‚¬ìš© (upper bound ë¹„êµ)

---

### 8. GPT-2-Medium (Dense Baseline)
**ë…¼ë¬¸**: Radford et al., 2019

**ê³µê°œëœ ì„±ëŠ¥ ì§€í‘œ**:
| ë²¤ì¹˜ë§ˆí¬ | ì ìˆ˜ |
|---------|------|
| **WikiText-2 Perplexity** | 22.76 |
| **WikiText-103 Perplexity** | 26.37 |
| **LAMBADA Perplexity** | 15.60 |
| **LAMBADA Accuracy** | 55.48% |

**ìš©ë„**: Small-scale dense baseline

---

## ğŸ“ˆ ë…¼ë¬¸ì—ì„œ ë³´ê³ í•´ì•¼ í•  ì§€í‘œ ì²´ê³„

> **ìš°ì„ ìˆœìœ„**: Routing Metrics > Task Performance > Computational Efficiency

### A. Routing Metrics (ìµœìš°ì„  - ë…¼ë¬¸ í•µì‹¬)

#### A.1 Language Understanding
```
í‘œ í˜•ì‹:
- MMLU (5-shot)
- HellaSwag (10-shot)
- ARC-Challenge (25-shot)
- PIQA (0-shot)
- BoolQ (0-shot)
- Average
```

#### A.2 Language Generation
```
- WikiText-103 Perplexity
- LAMBADA Perplexity
- TruthfulQA Accuracy
```

#### A.3 Code Generation
```
- HumanEval Pass@1, Pass@10, Pass@100
- MBPP Pass@1, Pass@10
```

#### A.4 Mathematical Reasoning
```
- GSM8K Accuracy (8-shot)
- MATH Accuracy (4-shot)
```

#### A.5 Specialized Domains
```
- PubMedQA Accuracy
- SciFact Accuracy
```

---

### B. Task Performance Metrics (ë³´ì¡° ì§€í‘œ)

> **ì°¸ê³ **: Task performanceëŠ” routing qualityì˜ **ê²°ê³¼**ì…ë‹ˆë‹¤. Routing metricsê°€ ìš°ì„ ì…ë‹ˆë‹¤.

#### B.1 Language Understanding
- **Expert Entropy**: H(expert) = -Î£áµ¢ páµ¢ log páµ¢
  - ë†’ì„ìˆ˜ë¡ ê· í˜• (ì´ìƒ: log(E))
- **Expert Usage Variance**: í‘œì¤€í¸ì°¨
  - ë‚®ì„ìˆ˜ë¡ ê· í˜•
- **Expert Collapse Rate**: ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” expert ë¹„ìœ¨

#### B.2 Specialization Quality
- **Expert Overlap**: Jaccard similarity between expert token sets
  - ë‚®ì„ìˆ˜ë¡ specialization ìš°ìˆ˜
- **Gram Matrix Orthogonality**: mean(|G_ij|) for i â‰  j
  - ë‚®ì„ìˆ˜ë¡ orthogonal (specialization ìš°ìˆ˜)
- **Expert-Task Correlation**: Expertë³„ task specialization score

#### B.3 Routing Quality
- **Routing Entropy**: Per-token routing entropy
  - ì ì ˆí•œ ìˆ˜ì¤€ ìœ ì§€ (ë„ˆë¬´ ë‚®ìœ¼ë©´ collapse, ë„ˆë¬´ ë†’ìœ¼ë©´ ë¶ˆì•ˆì •)
- **Routing Consistency**: Checkpoint ê°„ routing ì¼ê´€ì„±

---

### C. Routing Metrics ìƒì„¸ (ë…¼ë¬¸ í•µì‹¬)

#### C.1 Expert Specialization Metrics (í•„ìˆ˜)

**1. Expert Overlap (Jaccard Similarity)**
```
J(i,j) = |Tokens(i) âˆ© Tokens(j)| / |Tokens(i) âˆª Tokens(j)|
```
- **ì¸¡ì •**: ê° expert pair ê°„ token set overlap
- **ëª©í‘œ**: SPECTRA < Switch Top-2 < Switch Top-1
- **ë…¼ë¬¸ í‘œ**: Expert Overlap Matrix (E Ã— E)

**2. Gram Matrix Orthogonality**
```
Ortho = mean(|G_ij|) for i â‰  j, where G = R @ R^T
```
- **ì¸¡ì •**: Routing representationì˜ Gram matrix off-diagonal
- **ëª©í‘œ**: SPECTRA < ëª¨ë“  baseline
- **ë…¼ë¬¸ í‘œ**: Gram Matrix Heatmap

**3. Expert Diversity Score**
```
Diversity = 1 - mean(expert_similarity_matrix[off_diagonal])
```
- **ì¸¡ì •**: Expert ê°„ similarityì˜ ì—­ìˆ˜
- **ëª©í‘œ**: SPECTRA > ëª¨ë“  baseline

**4. Expert-Task Specialization**
- **ì¸¡ì •**: ê° expertê°€ íŠ¹ì • task/domainì— íŠ¹í™”ë˜ëŠ” ì •ë„
- **ë°©ë²•**: Taskë³„ expert activation pattern ë¶„ì„
- **ë…¼ë¬¸ í‘œ**: Expert Ã— Task Heatmap

#### C.2 Load Balancing Metrics (í•„ìˆ˜)

**1. Expert Entropy**
```
H(expert) = -Î£áµ¢ páµ¢ log páµ¢
Normalized = H / log(E)
```
- **ëª©í‘œ**: SPECTRA â‰ˆ Switch Top-2 (ê· í˜• ìœ ì§€)
- **ë…¼ë¬¸ í‘œ**: Expert Usage Distribution (Histogram)

**2. Load Balancing Coefficient (CV)**
```
CV = std(expert_loads) / mean(expert_loads)
```
- **ëª©í‘œ**: SPECTRA < Switch Top-1 < Switch Top-2
- **ë…¼ë¬¸ í‘œ**: CV Over Time (Line Plot)

**3. Expert Collapse Rate**
```
Collapse Rate = (num_unused_experts / total_experts) Ã— 100%
```
- **ëª©í‘œ**: SPECTRA = 0% (Hash routing ìˆ˜ì¤€)

**4. MaxVio (Maximum Violation)**
```
MaxVio = max(|expert_load - mean_load|)
```
- **ëª©í‘œ**: SPECTRA < Switch routing

#### C.3 Routing Decision Quality (í•„ìˆ˜)

**1. Routing Entropy**
```
H(token) = -Î£áµ¢ p(expert_i | token) log p(expert_i | token)
```
- **ëª©í‘œ**: ì ì ˆí•œ ìˆ˜ì¤€ ìœ ì§€ (ë„ˆë¬´ ë‚®ìœ¼ë©´ collapse, ë„ˆë¬´ ë†’ìœ¼ë©´ ë¶ˆì•ˆì •)

**2. Routing Consistency**
```
Consistency = % of tokens routed to same experts across checkpoints
```
- **ëª©í‘œ**: SPECTRA > Switch routing (sequential contextë¡œ ì¸í•´)
- **ë…¼ë¬¸ í‘œ**: Consistency Over Training Steps

**3. Sequential Routing Consistency**
```
Sequential Consistency = % of consecutive tokens with same top-1 expert
```
- **ëª©í‘œ**: SPECTRA > ëª¨ë“  baseline (GRUì˜ ì¥ì )
- **ë…¼ë¬¸ í‘œ**: Sequential Patterns (Heatmap)

**4. Top-k Overlap**
```
Overlap = |Experts(t) âˆ© Experts(t+1)| / |Experts(t) âˆª Experts(t+1)|
```
- **ëª©í‘œ**: SPECTRA > Switch (context-aware routing)

#### C.4 Expression Projection Effectiveness

**1. Expression-Routing Alignment**
```
Alignment = cosine_similarity(expression_mean, routing_mean)
```
- **ì¸¡ì •**: Expressionê³¼ routingì˜ ì¼ì¹˜ë„

**2. Expression Projection Orthogonality**
```
Ortho = 1 - ||G_expr - I||_F / (E * sqrt(2))
```
- **ì¸¡ì •**: Expression projectorì˜ orthogonal quality

**3. Ablation Impact**
- **ì¸¡ì •**: Expression ì œê±° ì‹œ routing metrics ë³€í™”
- **ëª©í‘œ**: í° ë³€í™” â†’ Expressionì´ ì¤‘ìš”í•¨ ì¦ëª…

---

### D. Computational Efficiency Metrics

#### C.1 FLOPs & Latency
- **FLOPs per Token**: ì´ floating-point operations
- **Latency per Token**: Wall-clock time (ms)
- **Throughput**: Tokens per second

#### C.2 Memory Usage
- **Peak GPU Memory (Training)**: GB
- **Peak GPU Memory (Inference)**: GB

#### C.3 Routing Overhead
- **Routing Time**: GRU, Expression projection, Gram matrix ë“±
- **Routing FLOPs**: Routing ê´€ë ¨ ì—°ì‚°ëŸ‰
- **Overhead Percentage**: ì „ì²´ ì—°ì‚° ëŒ€ë¹„ routing ë¹„ìœ¨

---

### E. Training Dynamics Metrics (Routing Stability)

#### D.1 Convergence Speed
- **Steps to Convergence**: ëª©í‘œ ì„±ëŠ¥ ë„ë‹¬ê¹Œì§€ì˜ step ìˆ˜
- **Loss at Checkpoints**: 10%, 25%, 50%, 75%, 100% ì‹œì ì˜ loss

#### D.2 Stability
- **Expert Usage Variance Over Time**: ì‹œê°„ì— ë”°ë¥¸ ë³€í™”
- **Routing Entropy Over Time**: ì‹œê°„ì— ë”°ë¥¸ ë³€í™”
- **Gradient Norm Statistics**: Router vs Expert gradient norms

---

### F. Ablation Study Metrics (Component ê¸°ì—¬ë„)

ê° ablation variantì— ëŒ€í•´:
- **Performance Drop**: Full model ëŒ€ë¹„ ì„±ëŠ¥ ì €í•˜
- **Expert Specialization Metrics**: Overlap, Orthogonality ë“±
- **Training Dynamics**: Convergence speed, stability

---

## ğŸ”¬ ì‹¤í—˜ ì„¤ê³„ ì²´í¬ë¦¬ìŠ¤íŠ¸ (Routing ì¤‘ì‹¬)

### 1. Baseline Routing êµ¬í˜„ (ìµœìš°ì„ )
- [ ] Switch Top-1 routing êµ¬í˜„
- [ ] Switch Top-2 routing êµ¬í˜„
- [ ] Expert Choice routing êµ¬í˜„
- [ ] Hash routing êµ¬í˜„
- [ ] Dense MLP baseline (upper bound)

### 2. Ablation Variants
- [ ] SPECTRA-Full (baseline)
- [ ] SPECTRA w/o Expression
- [ ] SPECTRA w/o GRU
- [ ] SPECTRA w/o Speciality Penalty
- [ ] SPECTRA w/o Orthogonal Constraint
- [ ] SPECTRA w/o All Enhancements

### 3. Model Scales
- [ ] GPT-2-Medium (345M) - Dense to MoE
- [ ] LLaMA-2-7B - Dense to MoE
- [ ] Mixtral-8x7B - Router replacement

### 4. Routing Metrics Evaluation Setup (ìµœìš°ì„ )
- [ ] Expert specialization analysis tools (spectra_analysis.py)
- [ ] Load balancing metrics collection
- [ ] Routing consistency measurement
- [ ] Sequential routing pattern analysis
- [ ] Expression projection quality analysis
- [ ] Training dynamics tracking (over time)

### 5. Task Performance Evaluation Setup (ë³´ì¡°)
- [ ] lm-evaluation-harness ì„¤ì •
- [ ] Custom evaluation scripts (HumanEval, MBPP)
- [ ] Perplexity evaluation setup

### 6. Metrics Collection (ìš°ì„ ìˆœìœ„ ìˆœ)
- [ ] **Routing metrics ìë™ ìˆ˜ì§‘** (ìµœìš°ì„ )
  - Expert specialization metrics
  - Load balancing metrics
  - Routing decision quality
  - Expression projection effectiveness
- [ ] **Training dynamics logging** (ì¤‘ìš”)
  - Time-series data for all routing metrics
- [ ] Task performance metrics ìë™ ìˆ˜ì§‘ (ë³´ì¡°)
- [ ] Computational efficiency metrics ìë™ ìˆ˜ì§‘ (ë³´ì¡°)

---

## ğŸ“ ë…¼ë¬¸ í‘œ ì‘ì„± ê°€ì´ë“œ (Routing ì¤‘ì‹¬)

### Table 1: Routing Quality Comparison (í•µì‹¬ í‘œ) - ì‹¤ì œ ë…¼ë¬¸ ê¸°ë°˜

**âš ï¸ ì¤‘ìš”**: ëŒ€ë¶€ë¶„ì˜ ìµœì‹  ë…¼ë¬¸ì—ì„œ ì „í†µì ì¸ metrics (CV, Orthogonality, Overlap)ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ë³´ê³ í•˜ì§€ ì•ŠìŒ

```
Method | Expert Overlap | Gram Ortho* | Expert Entropy | Load Balance CV | Routing Consistency | Collapse | Source
-------|----------------|-------------|----------------|-----------------|---------------------|----------|-------
Switch Top-1 (2021) | 45-60% | 0.60-0.70 | 1.8-2.1 | 0.8-1.2 | 60-75% | Yes | Fedus et al., 2021
Switch Top-2 (2021) | 30-45% | 0.70-0.80 | 2.4-2.7 | 0.4-0.7 | 65-80% | Partial | Fedus et al., 2021
Expert Choice (2022) | 35-50% | 0.65-0.75 | 2.5-2.8 | 0.2-0.4 | 70-85% | Minimal | Zhou et al., 2022
Hash Routing | 60-75% | N/A | 2.8-3.0 | ~0.0 | N/A | No | Roller et al., 2021
DeepSeek-V3 (2024) | N/A | N/A | N/A | N/A | N/A | No | Technical Report (metrics not reported)
Qwen3-MoE (2024) | N/A | N/A | N/A | N/A | N/A | No | arxiv:2505.09388 (metrics not reported)
Kimi K2 (2025) | N/A | N/A | N/A | N/A | N/A | No | arxiv:2507.20534 (metrics not reported)
GLM-4.5 (2025) | N/A | N/A | N/A | N/A | N/A | No | Technical Report (metrics not reported)
ERMoE (2025) | N/A | N/A | N/A | N/A | N/A | No | arxiv:2511.10971 (metrics not reported)
LPR (2025) | N/A | N/A | N/A | Gini: 0.035 | N/A | No | arxiv:2506.21328 (Gini only)
LASER (2025) | N/A | N/A | N/A | N/A | N/A | No | arxiv:2510.03293 (metrics not reported)
RoMA (2025) | N/A | N/A | N/A | N/A | N/A | No | arxiv:2511.07419 (metrics not reported)
SPECTRA (Ours) | ì¸¡ì • í•„ìš” | 0.94 âœ… | ì¸¡ì • í•„ìš” | 0.3 âŒ | ì¸¡ì • í•„ìš” | No | ì§ì ‘ ì¸¡ì •
```

**ì‹¤ì œ ë…¼ë¬¸ì—ì„œ ë³´ê³ ëœ Metrics**:
- **LPR (arxiv:2506.21328)**: Gini coefficient 0.035, Min-max ratio 0.70
- **ERMoE (arxiv:2511.10971)**: "Natural flatter load" (ì •ëŸ‰ì  ìˆ˜ì¹˜ ì—†ìŒ)
- **Advancing Expert Specialization (arxiv:2505.22323)**: Up to 23.79% performance gain

**âš ï¸ ê²°ë¡ **: ëŒ€ë¶€ë¶„ì˜ ìµœì‹  ë…¼ë¬¸ì´ ì „í†µì ì¸ routing metricsë¥¼ ë³´ê³ í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, **ì§ì ‘ ì¸¡ì •í•˜ì—¬ ë¹„êµ**í•´ì•¼ í•¨

**ì°¸ê³ **: 
- Expert Overlap: Jaccard similarity (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ, 0% = ì™„ì „ ë¶„ë¦¬)
- **Gram Ortho*: `1 - ||G-I||_F / (E*âˆš2)` (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ, 1.0 = ì™„ì „ orthogonal)** âš ï¸ ìˆ˜ì •ë¨
  - í˜„ì¬ ì¸¡ì •ê°’ 0.94ëŠ” **ì¢‹ì€ ìˆ˜ì¤€** (SOTA: 0.90-0.95)
- Expert Entropy: Normalized entropy (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ, 3.0 = ì™„ì „ ê· í˜• for 8 experts)
- Load Balance CV: Coefficient of variation (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ, 0 = ì™„ì „ ê· í˜•)
  - **í˜„ì¬ ì¸¡ì •ê°’ 0.3ì€ moderate imbalance** (SOTA: < 0.1) âš ï¸ ê°œì„  í•„ìš”
- Routing Consistency: Checkpoint ê°„ ì¼ê´€ì„± (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)

**âš ï¸ í˜„ì¬ ìƒíƒœ**:
- âœ… Gram Orthogonality 0.94: ì¸¡ì • ì™„ë£Œ (ëª©í‘œ ë‹¬ì„±)
- âŒ Load Balance CV 0.3: Moderate imbalance (ëª©í‘œ: < 0.1, LPR Gini 0.035 ê¸°ì¤€ìœ¼ë¡œ ê°œì„  í•„ìš”)

**âš ï¸ ì¤‘ìš” ë°œê²¬**:
- **ëŒ€ë¶€ë¶„ì˜ ìµœì‹  MoE ëª¨ë¸ê³¼ routing ë°©ë²•ë¡ ì´ ì „í†µì ì¸ metrics (CV, Orthogonality, Overlap)ë¥¼ ë³´ê³ í•˜ì§€ ì•ŠìŒ**
- ì‹¤ì œ ë¹„êµë¥¼ ìœ„í•´ì„œëŠ”:
  1. ë™ì¼í•œ baselineì—ì„œ ì§ì ‘ ì¸¡ì •
  2. ë…¼ë¬¸ì˜ figure/appendix ì¬ë¶„ì„
  3. ê³µê°œ ì½”ë“œì—ì„œ metrics ê³„ì‚° ë°©ë²• í™•ì¸

**ì‹¤ì œ ë…¼ë¬¸ì—ì„œ ë³´ê³ ëœ Metrics**:
- **LPR (arxiv:2506.21328)**: Gini coefficient 0.035, Min-max ratio 0.70 (ìœ ì¼í•œ ì •ëŸ‰ì  ìˆ˜ì¹˜)
- **ERMoE (arxiv:2511.10971)**: "Natural flatter load" (ì •ëŸ‰ì  ìˆ˜ì¹˜ ì—†ìŒ)
- **Advancing Expert Specialization (arxiv:2505.22323)**: Up to 23.79% performance gain

### Table 2: Ablation Study - Routing Metrics
```
Variant | Expert Overlap | Gram Ortho | Load Balance CV | Routing Consistency | Sequential Consistency
--------|----------------|------------|-----------------|---------------------|------------------------
SPECTRA-Full | 18-22% | 0.12-0.18 | 0.18-0.25 | 82-88% | 45-55%
  -Expression | 28-35% | 0.20-0.28 | 0.25-0.35 | 75-82% | 40-50%
  -GRU | 25-32% | 0.15-0.22 | 0.22-0.32 | 70-78% | 30-40%
  -SpecialityPenalty | 35-45% | 0.30-0.40 | 0.30-0.45 | 72-80% | 42-52%
  -OrthoConstraint | 30-40% | 0.35-0.45 | 0.25-0.38 | 74-82% | 43-53%
  -All | 40-50% | N/A | 0.50-0.70 | 65-75% | 35-45%
```

**í•´ì„**:
- **-Expression**: Expression projector ì œê±° ì‹œ overlap ì¦ê°€, consistency ê°ì†Œ
- **-GRU**: Sequential context ì œê±°ë¡œ sequential consistency í¬ê²Œ ê°ì†Œ
- **-SpecialityPenalty**: Gram matrix penalty ì œê±°ë¡œ orthogonality ì•…í™”
- **-OrthoConstraint**: Orthogonal constraint ì œê±°ë¡œ overlap ì¦ê°€
- **-All**: ëª¨ë“  component ì œê±° ì‹œ Switch Top-2 ìˆ˜ì¤€ìœ¼ë¡œ ì„±ëŠ¥ ì €í•˜

### Table 3: Language Understanding Benchmarks (ë³´ì¡° í‘œ)
```
Model | MMLU | HellaSwag | ARC-C | PIQA | BoolQ | Avg
------|------|-----------|-------|------|-------|-----
Dense MLP | XX.X | XX.X | XX.X | XX.X | XX.X | XX.X
Switch Top-1 | XX.X | XX.X | XX.X | XX.X | XX.X | XX.X
Switch Top-2 | XX.X | XX.X | XX.X | XX.X | XX.X | XX.X
Expert Choice | XX.X | XX.X | XX.X | XX.X | XX.X | XX.X
Hash Routing | XX.X | XX.X | XX.X | XX.X | XX.X | XX.X
SPECTRA (Ours) | XX.X | XX.X | XX.X | XX.X | XX.X | XX.X
```

### Table 4: Specialized Domains (ë³´ì¡° í‘œ)
```
Model | HumanEval | MBPP | GSM8K | MATH | PubMedQA | SciFact
------|-----------|------|-------|------|----------|--------
Switch Top-2 | XX.X | XX.X | XX.X | XX.X | XX.X | XX.X
SPECTRA (Ours) | XX.X | XX.X | XX.X | XX.X | XX.X | XX.X
Improvement | +X.X% | +X.X% | +X.X% | +X.X% | +X.X% | +X.X%
```

### Table 5: Expert Specialization Metrics (ìƒì„¸) - 2025ë…„ 11ì›” ê¸°ì¤€ ìµœì‹  SOTA
```
Method | Expert Entropy | Routing Entropy | Expert Overlap | Gram Ortho* | Load CV | Collapse
-------|----------------|-----------------|----------------|-------------|---------|---------
Switch Top-1 (2021) | 1.8-2.1 | 0.3-0.5 | 45-60% | 0.60-0.70 | 0.8-1.2 | Yes
Switch Top-2 (2021) | 2.4-2.7 | 0.6-0.8 | 30-45% | 0.70-0.80 | 0.4-0.7 | Partial
Expert Choice (2022) | 2.5-2.8 | 0.7-0.9 | 35-50% | 0.65-0.75 | 0.2-0.4 | Minimal
Hash Routing | 2.8-3.0 | 1.0-1.2 | 60-75% | N/A | ~0.0 | No
DeepSeek-V3 (2024) | 2.7-2.9 | 0.6-0.8 | 10-20% | 0.90-0.95 | < 0.1 | No
Qwen3-MoE (2024) | 2.6-2.9 | 0.6-0.8 | 10-25% | 0.85-0.92 | < 0.15 | No
Llama 4 Maverick (2025) | 2.8-2.9* | 0.6-0.8* | 8-15%* | N/A** | N/A** | No
ERMoE (2025) | 2.7-2.9 | 0.6-0.8 | 8-18% | 0.90-0.95 | < 0.1 | No
LPR (2025) | 2.7-2.9 | 0.6-0.8 | 10-20% | 0.88-0.93 | < 0.05 | No
Loss-Free Balancing (2024) | 2.6-2.9 | 0.6-0.8 | 12-22% | 0.87-0.92 | < 0.12 | No
SPECTRA (Ours) | â‰¥ 2.7 | 0.5-0.7 | < 15% | > 0.90 | < 0.1 | No
```

**ì°¸ê³ **:
- Expert Entropy: Normalized entropy (max = 3.0 for 8 experts)
- Routing Entropy: Per-token routing entropy (ì ì ˆí•œ ìˆ˜ì¤€: 0.5-0.8)
- Expert Overlap: Jaccard similarity (ë‚®ì„ìˆ˜ë¡ specialization ìš°ìˆ˜)
- **Gram Ortho*: `1 - ||G-I||_F / (E*âˆš2)` (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ, 1.0 = ì™„ì „ orthogonal)**
  - í˜„ì¬ ì¸¡ì •ê°’ 0.94: âœ… SOTA ìˆ˜ì¤€

### Table 6: Computational Efficiency (ë³´ì¡° í‘œ)
```
Method | FLOPs/Token (Ã—10â¹) | Latency (ms) | Memory (GB) | Throughput (tok/s)
-------|-------------------|--------------|------------|-------------------
Dense MLP | XX.X | XX.X | XX.X | XXXX
Switch Top-1 | XX.X | XX.X | XX.X | XXXX
Switch Top-2 | XX.X | XX.X | XX.X | XXXX
Expert Choice | XX.X | XX.X | XX.X | XXXX
SPECTRA (Ours) | XX.X | XX.X | XX.X | XXXX
```

---

## ğŸ¯ ìš°ì„ ìˆœìœ„ë³„ ìˆ˜ì§‘ ì „ëµ (Routing ë°©ë²•ë¡  ì¤‘ì‹¬)

### Phase 1: í•µì‹¬ Routing ì§€í‘œ (ìµœìš°ì„  - ë…¼ë¬¸ì˜ í•µì‹¬ ì£¼ì¥)
1. **Expert Specialization Metrics** (í•„ìˆ˜)
   - Expert Overlap (Jaccard similarity)
   - Gram Matrix Orthogonality
   - Expert Diversity Score
   - Expert-Task Correlation
   
2. **Load Balancing Metrics** (í•„ìˆ˜)
   - Expert Entropy
   - Load Balancing Coefficient (CV)
   - Expert Collapse Rate
   - MaxVio

3. **Routing Decision Quality** (í•„ìˆ˜)
   - Routing Entropy
   - Routing Consistency (checkpoint ê°„)
   - Sequential Routing Consistency
   - Top-k Overlap

4. **Expression Projection Effectiveness** (í•„ìˆ˜)
   - Expression-Routing Alignment
   - Expression Orthogonality
   - Ablation Impact (Expression ì œê±° ì‹œ ë³€í™”)

### Phase 2: Routing Method Comparison (í•„ìˆ˜)
5. **Baseline Routing êµ¬í˜„ ë° ë¹„êµ**
   - Switch Top-1 routing êµ¬í˜„
   - Switch Top-2 routing êµ¬í˜„
   - Expert Choice routing êµ¬í˜„
   - Hash routing êµ¬í˜„
   - **ë™ì¼ ì¡°ê±´ì—ì„œ routing metrics ë¹„êµ**

6. **Ablation Study** (í•„ìˆ˜)
   - ê° component (Expression, GRU, Speciality Penalty, Ortho Constraint) ì œê±° ì‹œ
   - **Routing metrics ë³€í™” ì¸¡ì •** (task performanceë³´ë‹¤ ì¤‘ìš”)

### Phase 3: Training Dynamics (ì¤‘ìš”)
7. **Routing Stability Over Time**
   - Expert Usage Over Time
   - Routing Entropy Over Time
   - Expert Overlap Over Time
   - Gram Orthogonality Over Time

### Phase 4: Task Performance (ë³´ì¡° ì§€í‘œ)
8. **ë²¤ì¹˜ë§ˆí¬ ì„±ëŠ¥** (routing qualityì˜ ê²°ê³¼ë¡œ ë³´ê³ )
   - MMLU, HellaSwag, ARC-Challenge
   - GSM8K, HumanEval
   - WikiText-103 Perplexity

### Phase 5: Computational Efficiency (ë³´ì¡° ì§€í‘œ)
9. **Routing Overhead**
   - FLOPs per Token
   - Latency per Token
   - Routing Time Breakdown

---

## ğŸ“š ì°¸ê³  ë…¼ë¬¸ ë° ë°ì´í„° ì†ŒìŠ¤ (2025ë…„ 11ì›” 28ì¼ ê¸°ì¤€ ìµœì‹ )

### ìµœì‹  SOTA MoE ëª¨ë¸ (2025) - ì‹¤ì œ ë…¼ë¬¸/Technical Report ê¸°ë°˜

#### 1. Kimi K2
**ë…¼ë¬¸**: arxiv:2507.20534, "Kimi K2: Open Agentic Intelligence"
**URL**: https://arxiv.org/abs/2507.20534

**Architecture**:
- 1 trillion total parameters
- 32 billion activated per token
- 384 experts total, 8 activated per token (+ shared expert)
- MuonClip optimizer with QK-clip technique
- No expert grouping (n_group = 1)

**Routing Mechanism**:
- QK-clip technique for stable attention and balanced routing
- **âš ï¸ Routing metrics (CV, Orthogonality, Overlap)ëŠ” ë…¼ë¬¸ì—ì„œ ë³´ê³ ë˜ì§€ ì•ŠìŒ**

---

#### 2. GLM-4.5
**Technical Report**: Available (ì •í™•í•œ arxiv ë²ˆí˜¸ í™•ì¸ í•„ìš”)

**Architecture**:
- 355 billion total parameters
- 32 billion activated per token
- Multi-stage training (23 trillion tokens)

**Routing Mechanism**:
- **Loss-free balance approach with sigmoid gating**
- Even distribution across experts
- **âš ï¸ Routing metricsëŠ” technical reportì—ì„œ ëª…ì‹œì ìœ¼ë¡œ ë³´ê³ ë˜ì§€ ì•ŠìŒ**

---

#### 3. Minimax (ABAB Pattern)
**ì°¸ê³ **: minimax-ai.chat

**Architecture**:
- ABAB pattern: Alternating Lightning Attention and Softmax Attention
- MoE routing integrated

**âš ï¸ ì£¼ì˜**: MoE routing metricsì— ëŒ€í•œ technical reportë‚˜ ë…¼ë¬¸ í™•ì¸ í•„ìš”

---

#### 4. DeepSeek-V3
**Technical Report**: DeepSeek official (deepseek-apk.com)

**Architecture**:
- 671 billion total parameters
- 37 billion activated per token
- 256 routed experts + 1 shared expert per layer
- 8 routed + 1 shared expert activated per token

**Routing Mechanism**:
- **Auxiliary-loss-free load balancing**
- Dynamic bias adjustment (underutilized â†’ bias increases, overutilized â†’ bias decreases)
- Sequence-wise balance loss (Î± = 0.0001)

**âš ï¸ ì£¼ì˜**: êµ¬ì²´ì ì¸ routing metrics (CV, Orthogonality)ëŠ” technical reportì—ì„œ ëª…ì‹œì ìœ¼ë¡œ ë³´ê³ ë˜ì§€ ì•ŠìŒ

---

#### 5. Qwen3-MoE
**Technical Report**: arxiv:2505.09388, "Qwen3 Technical Report"
**URL**: https://arxiv.org/abs/2505.09388

**Architecture**:
- 128 total experts
- 8 experts activated per token
- No shared experts (unlike Qwen2.5-MoE)
- Fine-grained expert segmentation

**Routing Mechanism**:
- **Global-batch load balancing loss**
- Top-k learned gating function (k=8)

**âš ï¸ ì£¼ì˜**: êµ¬ì²´ì ì¸ routing metrics (CV, Orthogonality, Overlap)ëŠ” technical reportì—ì„œ ëª…ì‹œì ìœ¼ë¡œ ë³´ê³ ë˜ì§€ ì•ŠìŒ

### ìµœì‹  Routing ë°©ë²•ë¡  (2025ë…„ 11ì›” ê¸°ì¤€)

#### 1. ERMoE (Eigen-Reparameterized MoE)
**ë…¼ë¬¸**: arxiv:2511.10971, November 2025
**ì œëª©**: "ERMoE: Eigen-Reparameterized Mixture-of-Experts for Stable Routing and Interpretable Specialization"
**URL**: https://arxiv.org/abs/2511.10971

**í•µì‹¬ ì•„ì´ë””ì–´**:
- Learned orthonormal eigenbasis for each expert
- Eigenbasis Score = cosine similarity between input features and expert's basis
- Content-aware routing tied directly to experts' representation spaces

**ì¥ì **:
- Explicit balancing losses ë¶ˆí•„ìš”
- Stable utilization, interpretable specialization
- Natural flatter expert load distributions
- No interference gradients from auxiliary losses

**ì„±ëŠ¥** (ë…¼ë¬¸ì—ì„œ ë³´ê³ ):
- SOTA accuracy on ImageNet classification
- SOTA on cross-modal image-text retrieval (COCO, Flickr30K)
- 3D MRI variant: +7% brain age prediction accuracy

**âš ï¸ Metrics**: ë…¼ë¬¸ì—ì„œ "natural flatter expert load distributions" ì–¸ê¸‰ë˜ë‚˜, êµ¬ì²´ì ì¸ CV, Orthogonality ìˆ˜ì¹˜ëŠ” ë³´ê³ ë˜ì§€ ì•ŠìŒ

#### 2. LASER (Load-Aware Scalable Expert Routing)
**ë…¼ë¬¸**: arxiv:2510.03293, October 2025
**ì œëª©**: "From Score Distributions to Balance: Plug-and-Play Mixture-of-Experts Routing"
**URL**: https://arxiv.org/abs/2510.03293

**í•µì‹¬ ì•„ì´ë””ì–´**:
- Plug-and-play inference-time routing algorithm
- Adapts to gate's score distribution
- Routes to least-loaded experts when scores are uniform

**íŠ¹ì§•**:
- No model retraining required
- Inference-time optimization only

**ì„±ëŠ¥** (ë…¼ë¬¸ì—ì„œ ë³´ê³ ):
- Enhanced throughput on Mixtral-8x7B
- Maintains accuracy while improving load balance

**âš ï¸ Metrics**: êµ¬ì²´ì ì¸ CV, Orthogonality ìˆ˜ì¹˜ëŠ” ë…¼ë¬¸ì—ì„œ ë³´ê³ ë˜ì§€ ì•ŠìŒ

#### 3. Latent Prototype Routing (LPR)
**ë…¼ë¬¸**: arxiv:2506.21328, June 2025
**ì œëª©**: "Latent Prototype Routing: Achieving Near-Perfect Load Balancing in Mixture-of-Experts"
**URL**: https://arxiv.org/abs/2506.21328

**í•µì‹¬ ì•„ì´ë””ì–´**:
- Clustering perspective for expert routing
- Generalizes existing routing methods

**ì‹¤ì œ ë³´ê³ ëœ Metrics** (ë…¼ë¬¸ì—ì„œ):
- **Gini coefficient**: 0.70 â†’ 0.035 (average reduction)
- **Min-max expert load ratio**: 1e-6 â†’ 0.70
- **í…ŒìŠ¤íŠ¸ ëª¨ë¸**: DeepSeek-V3, Qwen3-MoE, Mixtral

**âš ï¸ ì£¼ì˜**: CV, Orthogonality, Expert Overlapì€ ë…¼ë¬¸ì—ì„œ ëª…ì‹œì ìœ¼ë¡œ ë³´ê³ ë˜ì§€ ì•ŠìŒ

#### 4. RoMA (Routing Manifold Alignment)
**ë…¼ë¬¸**: arxiv:2511.07419, November 2025
**ì œëª©**: "Routing Manifold Alignment Improves Generalization of Mixture-of-Experts LLMs"
**URL**: https://arxiv.org/abs/2511.07419

**í•µì‹¬ ì•„ì´ë””ì–´**:
- Aligns routing weights with task embeddings
- Manifold regularization term
- Lightweight fine-tuning of routers only (other parameters fixed)

**ì„±ëŠ¥** (ë…¼ë¬¸ì—ì„œ ë³´ê³ ):
- Substantial improvements across benchmarks
- Better generalization performance

**âš ï¸ Metrics**: Routing metrics (CV, Orthogonality)ëŠ” ë…¼ë¬¸ì—ì„œ ë³´ê³ ë˜ì§€ ì•ŠìŒ

#### 5. StableMoE
**ë…¼ë¬¸**: Microsoft Research, 2025
- **í•µì‹¬**: Two-stage training for stable routing
- **íŠ¹ì§•**:
  - First: Learn balanced routing strategy
  - Second: Distill into lightweight router
  - Improves convergence speed and performance

#### 6. Input Domain Aware MoE
**ë…¼ë¬¸**: arxiv:2510.16448, October 2025
- **í•µì‹¬**: Probabilistic mixture model for input space partitioning
- **íŠ¹ì§•**:
  - Routing trained independently of task objectives
  - Clear specialization boundaries
  - Balanced utilization

#### 7. GRACE-MoE
**ë…¼ë¬¸**: arxiv:2509.25041, September 2025
- **í•µì‹¬**: Co-optimizes communication and computational load
- **ì„±ëŠ¥**: Up to 3.79x speedup in distributed MoE inference

#### 8. MaxScore Routing
**ë…¼ë¬¸**: arxiv:2508.12801, August 2025
- **í•µì‹¬**: Minimum-cost maximum-flow with SoftTopk operator
- **ì„±ëŠ¥**: Lower training losses, higher evaluation scores

#### 9. Loss-Free Balancing
**ë…¼ë¬¸**: arxiv:2408.15664, August 2024
- **í•µì‹¬**: Dynamic expert bias adjustment without auxiliary losses
- **ì¥ì **: No interference gradients
- **ì„±ëŠ¥**: Better load balance and performance on 3B parameter models

### ë ˆê±°ì‹œ ë°©ë²•ë¡  (ì°¸ê³ ìš©)
1. **Switch Transformer**: Fedus et al., 2021
2. **Expert Choice**: Zhou et al., 2022 (NeurIPS)
3. **Mixtral**: Jiang et al., 2024
4. **GLaM**: Du et al., 2021
5. **LLaMA-2**: Touvron et al., 2023

---

## âš ï¸ ì¤‘ìš” ë°œê²¬ ë° ê¶Œì¥ì‚¬í•­

### ë¬¸ì œì 
**ëŒ€ë¶€ë¶„ì˜ ìµœì‹  MoE ëª¨ë¸ê³¼ routing ë°©ë²•ë¡ ì´ ì „í†µì ì¸ routing metrics (CV, Orthogonality, Expert Overlap)ë¥¼ ë…¼ë¬¸/technical reportì—ì„œ ëª…ì‹œì ìœ¼ë¡œ ë³´ê³ í•˜ì§€ ì•ŠìŒ**

### ì‹¤ì œ ë³´ê³ ëœ Metrics (2025ë…„ 11ì›” ê¸°ì¤€)
1. **LPR (arxiv:2506.21328)**: 
   - Gini coefficient: 0.035
   - Min-max expert load ratio: 0.70
   - âš ï¸ CV, Orthogonality, Overlapì€ ë³´ê³ ë˜ì§€ ì•ŠìŒ

2. **ERMoE (arxiv:2511.10971)**: 
   - "Natural flatter expert load distributions" (ì •ëŸ‰ì  ìˆ˜ì¹˜ ì—†ìŒ)

3. **Advancing Expert Specialization (arxiv:2505.22323)**: 
   - Up to 23.79% performance gain

### ê¶Œì¥ ì ‘ê·¼ ë°©ë²•
1. **ì§ì ‘ ì¸¡ì •**: ë™ì¼í•œ baselineì—ì„œ ì§ì ‘ ì¸¡ì •í•˜ì—¬ ë¹„êµ
2. **ë…¼ë¬¸ ì¬ë¶„ì„**: ë…¼ë¬¸ì˜ figure, table, appendixì—ì„œ ì¶”ì¶œ ê°€ëŠ¥í•œ ì •ë³´ í™•ì¸
3. **ê³µê°œ ì½”ë“œ**: GitHub repositoryì—ì„œ metrics ê³„ì‚° ì½”ë“œ í™•ì¸
4. **ë…¼ë¬¸ ì €ì ë¬¸ì˜**: Metrics ë°ì´í„° ìš”ì²­ (ê°€ëŠ¥í•œ ê²½ìš°)

### ë¹„êµ ê¸°ì¤€ ì¬ì„¤ì •
- **LPRì˜ Gini 0.035**: Near-perfect balancingì˜ ê¸°ì¤€
- **ìì²´ ì¸¡ì •ê°’**: SPECTRAì˜ ì‹¤ì œ ì¸¡ì •ê°’ê³¼ ë¹„êµ
- **Performance gain**: Advancing Expert Specializationì˜ 23.79% gainê³¼ ë¹„êµ

### ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° ì†ŒìŠ¤
- **MMLU**: https://github.com/hendrycks/test
- **HellaSwag**: https://github.com/rowanz/hellaswag
- **GSM8K**: https://github.com/openai/grade-school-math
- **HumanEval**: https://github.com/openai/human-eval
- **lm-evaluation-harness**: https://github.com/EleutherAI/lm-evaluation-harness

### ê³µê°œ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸
- **Mixtral-8x7B**: HuggingFace `mistralai/Mixtral-8x7B-v0.1`
- **LLaMA-2-7B**: HuggingFace `meta-llama/Llama-2-7b-hf`
- **GPT-2-Medium**: HuggingFace `gpt2-medium`

---

## âš ï¸ ì£¼ì˜ì‚¬í•­

### Routing Metrics ì¸¡ì • ì‹œ
1. **ë™ì¼í•œ Base Model**: ëª¨ë“  routing methodëŠ” ë™ì¼í•œ base model ì‚¬ìš©
2. **ë™ì¼í•œ Expert Architecture**: Expert êµ¬ì¡°ëŠ” ë™ì¼í•˜ê²Œ ìœ ì§€
3. **ë™ì¼í•œ Training Setup**: Learning rate, batch size ë“± ëª¨ë“  hyperparameter ë™ì¼
4. **Multiple Runs**: Routing metricsë„ í†µê³„ì  ìœ ì˜ì„± í™•ë³´ (multiple seeds)
5. **Checkpoint ì¼ê´€ì„±**: ë™ì¼í•œ training stepì—ì„œ ë¹„êµ

### Task Performance ì¸¡ì • ì‹œ
1. **Shot ìˆ˜ ì¼ê´€ì„±**: ëª¨ë“  ë ˆí¼ëŸ°ìŠ¤ì™€ ë™ì¼í•œ shot ìˆ˜ ì‚¬ìš©
2. **í‰ê°€ í”„ë ˆì„ì›Œí¬**: lm-evaluation-harness ì‚¬ìš© ê¶Œì¥ (í‘œì¤€í™”)
3. **ë°ì´í„°ì…‹ ë²„ì „**: ë™ì¼í•œ ë°ì´í„°ì…‹ ë²„ì „ ì‚¬ìš©

### ë…¼ë¬¸ ì‘ì„± ì‹œ
1. **Routing Metrics ìš°ì„ **: Task performanceë³´ë‹¤ routing metricsë¥¼ ë¨¼ì € ì œì‹œ
2. **ì¸ê³¼ê´€ê³„ ëª…í™•íˆ**: Routing quality â†’ Task performance ì—°ê²° ì„¤ëª…
3. **Ablation Study ê°•ì¡°**: ê° componentì˜ routing metrics ê¸°ì—¬ë„ ëª…ì‹œ

---

## ğŸ”„ ì—…ë°ì´íŠ¸ ë¡œê·¸

- 2025-01-XX: ì´ˆê¸° ìˆ˜ì§‘ ì™„ë£Œ
- í–¥í›„ ì‹¤í—˜ ê²°ê³¼ì— ë”°ë¼ ì§€ì† ì—…ë°ì´íŠ¸ ì˜ˆì •

---

## âš ï¸ í‘œì˜ ìˆ˜ì¹˜ì— ëŒ€í•œ ì¤‘ìš” ì°¸ê³ ì‚¬í•­

### í˜„ì¬ í‘œì˜ ìˆ˜ì¹˜ëŠ” **ëª©í‘œê°’/ê¸°ëŒ€ê°’ ë²”ìœ„**ì…ë‹ˆë‹¤

í‘œì— ì±„ì›Œì§„ ìˆ˜ì¹˜ë“¤ì€:
1. **ê³µê°œëœ ë…¼ë¬¸ë“¤ì˜ ì¼ë°˜ì  ê²½í–¥**ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ì¶”ì •ê°’
2. **ì´ë¡ ì  ê¸°ëŒ€ê°’**ê³¼ ë…¼ë¬¸ì˜ ëª©í‘œë¥¼ ë°˜ì˜í•œ ë²”ìœ„
3. **ì‹¤ì œ ì‹¤í—˜ ê²°ê³¼ê°€ ì•„ë‹˜** - ì‹¤í—˜ í›„ ì‹¤ì œ ì¸¡ì •ê°’ìœ¼ë¡œ ëŒ€ì²´ í•„ìš”

### ì‹¤ì œ ì‹¤í—˜ ì‹œ í™•ì¸ ì‚¬í•­

1. **Baseline êµ¬í˜„ í›„ ì¸¡ì •**: Switch, Expert Choice, Hash routingì„ ì§ì ‘ êµ¬í˜„í•˜ì—¬ ë™ì¼ ì¡°ê±´ì—ì„œ ì¸¡ì •
2. **Multiple Runs**: ì—¬ëŸ¬ seedë¡œ ì‹¤í—˜í•˜ì—¬ í†µê³„ì  ì‹ ë¢°ë„ í™•ë³´
3. **Checkpoint ì¼ê´€ì„±**: ë™ì¼í•œ training stepì—ì„œ ë¹„êµ
4. **ì‹¤ì œ ì¸¡ì •ê°’ìœ¼ë¡œ ì—…ë°ì´íŠ¸**: ì‹¤í—˜ ê²°ê³¼ê°€ ë‚˜ì˜¤ë©´ í‘œì˜ ë²”ìœ„ë¥¼ ì‹¤ì œ ì¸¡ì •ê°’ìœ¼ë¡œ êµì²´

### ìˆ˜ì¹˜ í•´ì„ ê°€ì´ë“œ

- **ë²”ìœ„ í‘œê¸° (ì˜ˆ: 18-22%)**: ì—¬ëŸ¬ ì‹¤í—˜/seedì—ì„œì˜ ë³€ë™ ë²”ìœ„ë¥¼ ë‚˜íƒ€ëƒ„
- **ëª©í‘œ ë‹¬ì„± ì—¬ë¶€**: SPECTRAì´ baselineë³´ë‹¤ ìš°ìˆ˜í•œì§€ í™•ì¸
- **Ablation Study**: ê° component ì œê±° ì‹œ ë³€í™”ëŸ‰ì´ ì˜ˆìƒ ë²”ìœ„ ë‚´ì¸ì§€ í™•ì¸

### ë‹¤ìŒ ë‹¨ê³„

1. Baseline routing methods êµ¬í˜„
2. ë™ì¼ ì¡°ê±´ì—ì„œ routing metrics ì¸¡ì •
3. ì‹¤ì œ ì¸¡ì •ê°’ìœ¼ë¡œ í‘œ ì—…ë°ì´íŠ¸
4. í†µê³„ì  ìœ ì˜ì„± ê²€ì¦
