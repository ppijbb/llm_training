import logging
from tqdm import tqdm
from datasets import load_dataset, get_dataset_config_names, concatenate_datasets
from transformers import AutoProcessor
import torch
from typing import Dict, Any, List, Optional
import traceback
import gc
import os
import random
import tempfile
import pathlib
import shutil
import json
import hashlib
from datetime import datetime
from PIL import Image
from datasets import Dataset, DatasetDict, load_dataset, Image as DatasetImage, Sequence, Features, Value

# Configure logger
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
handler = logging.StreamHandler()
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)

def _generate_simple_cache_key(dataset_name: str, max_samples: int, test_size: float, use_streaming: bool) -> str:
    """ìºì‹œ í‚¤ ìƒì„±"""
    cache_data = {
        "dataset_name": dataset_name,
        "max_samples": max_samples,
        "test_size": test_size,
        "use_streaming": use_streaming
    }
    cache_str = json.dumps(cache_data, sort_keys=True, ensure_ascii=False)
    cache_hash = hashlib.md5(cache_str.encode('utf-8')).hexdigest()
    return f"simple_{cache_hash}"

def get_simple_sft_dataset(
    dataset_name: str = "HuggingFaceTB/smoltalk", 
    tokenizer=None,
    max_length: int = 2048,
    max_samples: int = 1000,
    test_size: float = 0.1,
    use_streaming: bool = True,
    chunk_size: int = 1000,
    use_cache: bool = True
):
    """
    ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ SFT ë°ì´í„°ì…‹ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    ëª¨ë“  configë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ìµœì†Œí™”í•©ë‹ˆë‹¤.
    ë°ì´í„°ë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ë””ìŠ¤í¬ì— ì €ì¥í•˜ì—¬ ë©”ëª¨ë¦¬ ì´ˆê³¼ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
    """
    if tokenizer is None:
        raise ValueError("Tokenizer must be provided")
    
    # ìºì‹œ í‚¤ ìƒì„±
    cache_key = _generate_simple_cache_key(dataset_name, max_samples, test_size, use_streaming)
    base_temp_dir = "/mls/conan/tmp"
    cache_dir = os.path.join(base_temp_dir, "cache", cache_key)
    cache_train_path = os.path.join(cache_dir, "train.jsonl")
    cache_test_path = os.path.join(cache_dir, "test.jsonl")
    cache_images_dir = os.path.join(cache_dir, "images")
    cache_meta_path = os.path.join(cache_dir, "cache_meta.json")
    
    # ìºì‹œ í™•ì¸
    if use_cache and os.path.exists(cache_train_path) and os.path.exists(cache_test_path):
        # íŒŒì¼ í¬ê¸° í™•ì¸ (ë¹ˆ íŒŒì¼ì´ ì•„ë‹Œì§€)
        if os.path.getsize(cache_train_path) > 0:
            logger.info(f"ğŸ’¾ ìºì‹œëœ ë°ì´í„°ì…‹ ë°œê²¬: {cache_key}")
            logger.info(f"   - ìºì‹œ ë””ë ‰í† ë¦¬: {cache_dir}")
            
            # ë©”íƒ€ë°ì´í„° í™•ì¸
            if os.path.exists(cache_meta_path):
                try:
                    with open(cache_meta_path, "r", encoding="utf-8") as f:
                        cache_meta = json.load(f)
                        logger.info(f"   - ìºì‹œ ìƒì„± ì‹œê°„: {cache_meta.get('created_at', 'N/A')}")
                        logger.info(f"   - Train ìƒ˜í”Œ ìˆ˜: {cache_meta.get('train_count', 'N/A')}")
                        logger.info(f"   - Test ìƒ˜í”Œ ìˆ˜: {cache_meta.get('test_count', 'N/A')}")
                except Exception as e:
                    logger.warning(f"   âš ï¸ ìºì‹œ ë©”íƒ€ë°ì´í„° ì½ê¸° ì‹¤íŒ¨: {e}")
            
            # ìºì‹œëœ íŒŒì¼ë¡œë¶€í„° ë°ì´í„°ì…‹ ë¡œë“œ
            try:
                data_files = {}
                if os.path.exists(cache_train_path) and os.path.getsize(cache_train_path) > 0:
                    data_files["train"] = cache_train_path
                if os.path.exists(cache_test_path) and os.path.getsize(cache_test_path) > 0:
                    data_files["test"] = cache_test_path
                
                if not data_files:
                    logger.warning("   âš ï¸ ìºì‹œ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì¬ì²˜ë¦¬í•©ë‹ˆë‹¤.")
                    raise FileNotFoundError("Cache files are empty")
                
                logger.info("ğŸ§  ìºì‹œëœ JSONL íŒŒì¼ë¡œë¶€í„° ë°ì´í„°ì…‹ ë¡œë”©...")
                
                # JSONL íŒŒì¼ì„ ì½ì–´ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“  í›„ Dataset.from_list ì‚¬ìš©
                dataset_dict = DatasetDict()
                for split_name, file_path in data_files.items():
                    logger.info(f"   ğŸ“‚ {split_name} split ë¡œë”© ì¤‘...")
                    
                    # JSONL íŒŒì¼ ì½ê¸° ë° ì •ì œ
                    records = []
                    with open(file_path, 'r', encoding='utf-8') as f:
                        for line_num, line in enumerate(f, 1):
                            if not line.strip():
                                continue
                            try:
                                record = json.loads(line.strip())
                                
                                # messages ì •ê·œí™”
                                if 'messages' in record and isinstance(record['messages'], list):
                                    for message in record['messages']:
                                        if not isinstance(message, dict):
                                            continue
                                        if 'content' in message and isinstance(message['content'], list):
                                            for content_item in message['content']:
                                                if not isinstance(content_item, dict):
                                                    continue
                                                # text í•„ë“œê°€ ì—†ê±°ë‚˜ Noneì´ë©´ ë¹ˆ ë¬¸ìì—´ë¡œ
                                                if 'text' not in content_item or content_item.get('text') is None:
                                                    content_item['text'] = ""
                                                # type í•„ë“œê°€ ì—†ìœ¼ë©´ "text"ë¡œ
                                                if 'type' not in content_item:
                                                    content_item['type'] = "text"
                                
                                # images í•„ë“œ ì •ê·œí™” (ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸, ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³´ì¥)
                                if 'images' not in record:
                                    record['images'] = []
                                elif record['images'] is None:
                                    record['images'] = []
                                elif not isinstance(record['images'], list):
                                    record['images'] = []
                                else:
                                    # ì´ë¯¸ì§€ ê²½ë¡œê°€ ë¬¸ìì—´ì¸ì§€ í™•ì¸
                                    record['images'] = [str(img) if img is not None else "" for img in record['images'] if img is not None]
                                
                                records.append(record)
                            except (json.JSONDecodeError, TypeError) as e:
                                logger.debug(f"   âš ï¸ {split_name} íŒŒì¼ {line_num}ë²ˆì§¸ ì¤„ JSON íŒŒì‹± ì‹¤íŒ¨, ê±´ë„ˆëœ€: {e}")
                                continue
                    
                    # Dataset.from_listë¡œ ìƒì„±
                    if records:
                        dataset_dict[split_name] = Dataset.from_list(records)
                        logger.info(f"   âœ… {split_name} split ë¡œë“œ ì™„ë£Œ: {len(dataset_dict[split_name])}ê°œ ìƒ˜í”Œ")
                    else:
                        logger.warning(f"   âš ï¸ {split_name} splitì— ìœ íš¨í•œ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤.")
                        # ë¹ˆ ë°ì´í„°ì…‹ ìƒì„±
                        dataset_dict[split_name] = Dataset.from_list([])
                
                # ì´ë¯¸ì§€ ê²½ë¡œ ì²˜ë¦¬
                logger.info("ğŸ–¼ï¸ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì´ë¯¸ì§€ ê°ì²´ë¡œ ìºìŠ¤íŒ… (lazy loading)...")
                for split in dataset_dict:
                    def preprocess_images(example):
                        """ì´ë¯¸ì§€ ë°ì´í„° ì „ì²˜ë¦¬ - ì¤‘ì²© ë¦¬ìŠ¤íŠ¸ í‰ë©´í™”"""
                        if 'images' in example and example['images']:
                            # ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                            image_paths = example['images']
                            if isinstance(image_paths, list):
                                fixed_paths = []
                                for img_path in image_paths:
                                    if isinstance(img_path, str) and img_path.strip():
                                        if not os.path.isabs(img_path):
                                            img_path = os.path.join(cache_images_dir, os.path.basename(img_path))
                                        # íŒŒì¼ ì¡´ì¬ í™•ì¸
                                        if os.path.exists(img_path):
                                            fixed_paths.append(img_path)
                                example['images'] = validate_image_data(fixed_paths)
                            else:
                                example['images'] = validate_image_data(example['images']) if example['images'] else []
                        elif 'images' not in example:
                            example['images'] = []
                        return example
                    
                    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì ìš©
                    dataset_dict[split] = dataset_dict[split].map(preprocess_images)
                    
                    # ì´ë¯¸ì§€ í•„ë“œë¥¼ DatasetImageë¡œ ìºìŠ¤íŒ…
                    current_features = dataset_dict[split].features
                    new_features = current_features.copy()
                    if 'images' in new_features:
                        new_features['images'] = Sequence(DatasetImage(decode=True))
                        dataset_dict[split] = dataset_dict[split].cast(new_features)
                
                logger.info("âœ… ìºì‹œëœ ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ")
                return dataset_dict
                
            except Exception as e:
                logger.warning(f"   âš ï¸ ìºì‹œ ë¡œë“œ ì‹¤íŒ¨, ì¬ì²˜ë¦¬í•©ë‹ˆë‹¤: {e}")
                traceback.print_exc()
                # ìºì‹œ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë¡œì§ìœ¼ë¡œ ì§„í–‰
    
    # ìºì‹œê°€ ì—†ê±°ë‚˜ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš° ê¸°ì¡´ ì²˜ë¦¬ ë¡œì§
    logger.info(f"ğŸ“¦ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ë¡œë”© (V2 - JSONL): {dataset_name}")
    logger.info(f"   - max_samples: {max_samples}")
    logger.info(f"   - streaming: {use_streaming}")
    
    log_memory_usage("ë°ì´í„°ì…‹ ë¡œë”© ì‹œì‘")
    
    # ìºì‹œ ë””ë ‰í† ë¦¬ ì‚¬ìš©
    os.makedirs(cache_dir, exist_ok=True)
    images_dir = cache_images_dir
    os.makedirs(images_dir, exist_ok=True)

    try:
        available_configs = get_dataset_config_names(dataset_name)
        selected_configs = []
        for i in range(25):
            random.shuffle(available_configs)
            selected_configs += [random.choice(available_configs)]
        available_configs = selected_configs
        logger.info(f"   ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ configs: {len(available_configs)}ê°œ")
        logger.info(f"   ğŸ¯ ëª¨ë“  config ì‚¬ìš©: {len(available_configs)}ê°œ")
        
        samples_per_config = max(1, max_samples // len(available_configs))
        logger.info(f"   ğŸ“Š Configë‹¹ ìƒ˜í”Œ ìˆ˜: {samples_per_config}ê°œ")
        
        total_processed = 0
        image_counter = 0
        train_count, test_count = 0, 0
        
        train_jsonl_path = cache_train_path
        test_jsonl_path = cache_test_path

        with open(train_jsonl_path, "w", encoding="utf-8") as train_f, \
             open(test_jsonl_path, "w", encoding="utf-8") as test_f:
            
            config_pbar = tqdm(available_configs, desc="Config ì²˜ë¦¬", unit="config")
            
            for i, config in enumerate(config_pbar):
                if total_processed >= max_samples:
                    break
                    
                try:
                    config_pbar.set_description(f"Config {i+1}/{len(available_configs)}: {config[:30]}...")
                    
                    config_dataset = load_dataset(
                        path=dataset_name, 
                        name=config,
                        split="train", 
                        streaming=True
                    )
                    
                    sample_pbar = tqdm(total=samples_per_config, desc=f"ìƒ˜í”Œ ì²˜ë¦¬", unit="sample", leave=False)
                    
                    for sample in config_dataset:
                        if total_processed >= max_samples:
                            break
                        
                        converted = convert_sample_to_messages(sample, dataset_name)
                        if not converted:
                            continue

                        # ì´ë¯¸ì§€ê°€ ìˆëŠ”ì§€ ë¨¼ì € í™•ì¸ - ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ ìƒ˜í”Œ ê±´ë„ˆëœ€
                        if "images" not in converted or not converted["images"]:
                            logger.debug(f"âš ï¸ ì´ë¯¸ì§€ê°€ ì—†ëŠ” ìƒ˜í”Œ ê±´ë„ˆëœ€: {sample}")
                            continue
                        
                        # ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ê°€ ì¤‘ì²©ëœ ê²½ìš° í‰ë©´í™”
                        flattened_images = validate_image_data(converted["images"])
                        if not flattened_images:
                            logger.debug(f"âš ï¸ ìœ íš¨í•œ ì´ë¯¸ì§€ê°€ ì—†ëŠ” ìƒ˜í”Œ ê±´ë„ˆëœ€: {sample}")
                            continue

                        # ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ê²½ë¡œë¡œ ëŒ€ì²´
                        image_paths = []
                        valid_sample = True
                        
                        for img_obj in flattened_images:
                            if isinstance(img_obj, Image.Image):
                                try:
                                    img_path = os.path.join(images_dir, f"{image_counter}.png")
                                    img_obj.save(img_path, "PNG")
                                    image_paths.append(img_path)
                                    image_counter += 1
                                except Exception as img_e:
                                    logger.warning(f"âš ï¸ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨, ìƒ˜í”Œ ê±´ë„ˆëœ€: {img_e}")
                                    valid_sample = False
                                    break
                            elif img_obj is not None:
                                # Noneì´ ì•„ë‹Œ ë‹¤ë¥¸ íƒ€ì…ì˜ ì´ë¯¸ì§€ ê°ì²´ ì²˜ë¦¬
                                logger.warning(f"âš ï¸ ì§€ì›ë˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {type(img_obj)}")
                                valid_sample = False
                                break
                        
                        if not valid_sample or not image_paths:
                            logger.debug(f"âš ï¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨ë¡œ ìƒ˜í”Œ ê±´ë„ˆëœ€: {sample}")
                            continue
                        
                        converted["images"] = image_paths

                        is_train = (total_processed % int(1/test_size)) != 0
                        
                        if is_train:
                            train_f.write(json.dumps(converted) + "\n")
                            train_count += 1
                        else:
                            test_f.write(json.dumps(converted) + "\n")
                            test_count += 1

                        total_processed += 1
                        
                        sample_pbar.update(1)
                        memory_gb = get_memory_usage()
                        sample_pbar.set_postfix({
                            "ì´ ì²˜ë¦¬": f"{total_processed}/{max_samples}",
                            "Train": train_count,
                            "Test": test_count,
                            "ë©”ëª¨ë¦¬": f"{memory_gb:.1f}GB"
                        })
                    
                    sample_pbar.close()
                    del config_dataset
                    gc.collect()
                    
                except Exception as e:
                    tqdm.write(f"âš ï¸ Config {config} ì‹¤íŒ¨: {e}")
                    continue
            
            config_pbar.close()

        logger.info(f"âœ… ìƒ˜í”Œ ìˆ˜ì§‘ ë° ë””ìŠ¤í¬ ì €ì¥ ì™„ë£Œ: Train {train_count}ê°œ, Test {test_count}ê°œ")
        
        data_files = {}
        if train_count > 0:
            data_files["train"] = train_jsonl_path
        if test_count > 0:
            data_files["test"] = test_jsonl_path

        if not data_files:
            raise ValueError("ë³€í™˜ëœ í›ˆë ¨ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ì…‹ í˜•ì‹ì„ í™•ì¸í•˜ì„¸ìš”.")
        
        logger.info("ğŸ§  JSONL íŒŒì¼ë¡œë¶€í„° ë°ì´í„°ì…‹ ë¡œë”©...")
        dataset_dict = load_dataset("json", data_files=data_files)
        
        logger.info("ğŸ–¼ï¸ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì´ë¯¸ì§€ ê°ì²´ë¡œ ìºìŠ¤íŒ… (lazy loading)...")
        for split in dataset_dict:
            # ìƒˆë¡œìš´ Features ê°ì²´ ìƒì„±
            current_features = dataset_dict[split].features
            new_features = current_features.copy()
            if 'images' in new_features and isinstance(new_features['images'], Sequence):
                # ì¤‘ì²© ë¦¬ìŠ¤íŠ¸ ë¬¸ì œë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ì´ë¯¸ì§€ ë°ì´í„° ì „ì²˜ë¦¬
                def preprocess_images(example):
                    """ì´ë¯¸ì§€ ë°ì´í„° ì „ì²˜ë¦¬ - ì¤‘ì²© ë¦¬ìŠ¤íŠ¸ í‰ë©´í™”"""
                    if 'images' in example and example['images']:
                        example['images'] = validate_image_data(example['images'])
                    return example
                
                # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì ìš©
                dataset_dict[split] = dataset_dict[split].map(preprocess_images)
                new_features['images'] = Sequence(DatasetImage(decode=True))
                dataset_dict[split] = dataset_dict[split].cast(new_features)

        logger.info("âœ… ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ")
        
        # ì²˜ë¦¬ ì™„ë£Œ í›„ ë©”íƒ€ë°ì´í„° ì €ì¥
        try:
            cache_meta = {
                "created_at": datetime.now().isoformat(),
                "train_count": train_count,
                "test_count": test_count,
                "dataset_name": dataset_name,
                "max_samples": max_samples,
                "test_size": test_size,
                "use_streaming": use_streaming,
                "cache_key": cache_key
            }
            with open(cache_meta_path, "w", encoding="utf-8") as f:
                json.dump(cache_meta, f, indent=2, ensure_ascii=False)
            logger.info(f"ğŸ’¾ ë°ì´í„°ì…‹ ìºì‹œ ì €ì¥ ì™„ë£Œ: {cache_dir}")
        except Exception as e:
            logger.warning(f"âš ï¸ ìºì‹œ ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
        
        return dataset_dict

    except Exception as e:
        logger.error(f"âŒ ë°ì´í„°ì…‹ ë¡œë”© ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        # ì‹¤íŒ¨ ì‹œì—ë„ ìºì‹œ ë””ë ‰í† ë¦¬ëŠ” ìœ ì§€ (ë¶€ë¶„ì ìœ¼ë¡œ ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ìˆì„ ìˆ˜ ìˆìŒ)
        # shutil.rmtree(cache_dir, ignore_errors=True)
        raise Exception(f"ğŸ˜¢ ë°ì´í„°ì…‹ ë¡œë”© ì‹œë„ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.") from e


def convert_sample_to_messages(sample: Dict[str, Any], dataset_name: str) -> Optional[Dict[str, Any]]:
    """ìƒ˜í”Œì„ messages í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    
    # safe_flatten_images í•¨ìˆ˜ ì‚¬ìš©
    
    if dataset_name == "HuggingFaceTB/smoltalk" or "smoltalk" in dataset_name.lower():
        if "messages" in sample and isinstance(sample["messages"], list):
            img = sample.get("image", [])
            if not isinstance(img, list):
                img = [img] if img is not None else []
            # ì¤‘ì²© ë¦¬ìŠ¤íŠ¸ í‰ë©´í™” ë° None ê°’ ì œê±°
            img = validate_image_data(img)
            # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ None ë°˜í™˜ (ìƒ˜í”Œ ê±´ë„ˆëœ€)
            if not img:
                return None
            
            # ë©”ì‹œì§€ ê²€ì¦ ë° ìµœì í™”
            messages = validate_messages(sample["messages"])
            return {"messages": messages, "images": img}
    
    elif "orca-agentinstruct" in dataset_name:
        if "messages" in sample and isinstance(sample["messages"], list):
            img = sample.get("image", [])
            if not isinstance(img, list):
                img = [img] if img is not None else []
            # ì¤‘ì²© ë¦¬ìŠ¤íŠ¸ í‰ë©´í™” ë° None ê°’ ì œê±°
            img = validate_image_data(img)
            
            # ë©”ì‹œì§€ ê²€ì¦ ë° ìµœì í™”
            messages = validate_messages(sample["messages"])
            sample.update({"messages": messages, "images": img})
            return sample
    
    # ê¸°ë³¸ instruction-output í˜•ì‹ ì²˜ë¦¬
    if "instruction" in sample and "output" in sample:
        messages = [
            {"role": "user", "content": [{"type": "image"}, {"type": "text", "text": sample["instruction"]}]},
            {"role": "assistant", "content": sample["output"]}
        ]
        img = sample.get("image", [])
        if not isinstance(img, list):
            img = [img] if img is not None else []
        # ì¤‘ì²© ë¦¬ìŠ¤íŠ¸ í‰ë©´í™” ë° None ê°’ ì œê±°
        img = validate_image_data(img)
        # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ None ë°˜í™˜ (ìƒ˜í”Œ ê±´ë„ˆëœ€)
        if not img:
            return None
        return {"messages": messages, "images": img}
    
    # conversations í˜•ì‹ ì²˜ë¦¬
    if "conversations" in sample and isinstance(sample["conversations"], list):
        messages = []
        first_user_message_found = False
        for conv in sample["conversations"]:
            if isinstance(conv, dict) and "from" in conv and "value" in conv:
                role = "user" if conv["from"] in ["human", "user"] else "assistant"
                content = []
                if role == "user" and not first_user_message_found:
                    content.append({"type": "image"})
                    first_user_message_found = True
                content.append({"type": "text", "text": conv["value"]})
                messages.append({"role": role, "content": content})
        if messages:
            img = sample.get("image", [])
            if not isinstance(img, list):
                img = [img] if img is not None else []
            # ì¤‘ì²© ë¦¬ìŠ¤íŠ¸ í‰ë©´í™” ë° None ê°’ ì œê±°
            img = validate_image_data(img)
            return {"messages": messages, "images": img}
    
    # text í•„ë“œë§Œ ìˆëŠ” ê²½ìš° (ë‹¨ìˆœí•œ í…ìŠ¤íŠ¸)
    if "text" in sample and isinstance(sample["text"], str):
        # ê°„ë‹¨í•œ ëŒ€í™”ë¡œ ë³€í™˜
        messages = [
            {"role": "user", "content": [{"type": "image"}, {"type": "text", "text": "Continue the following text:"}]},
            {"role": "assistant", "content": sample["text"]}
        ]
        img = sample.get("image", [])
        if not isinstance(img, list):
            img = [img] if img is not None else []
        # ì¤‘ì²© ë¦¬ìŠ¤íŠ¸ í‰ë©´í™” ë° None ê°’ ì œê±°
        img = validate_image_data(img)
        # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ None ë°˜í™˜ (ìƒ˜í”Œ ê±´ë„ˆëœ€)
        if not img:
            return None
        return {"messages": messages, "images": img}
    
    return None


def process_sample(sample: Dict[str, Any], tokenizer, max_length: int):
    """ìƒ˜í”Œì„ í† í¬ë‚˜ì´ì¦ˆí•˜ì—¬ í›ˆë ¨ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    try:
        if "messages" not in sample:
            return None
        
        # ë©”ì‹œì§€ ìœ íš¨ì„± ê²€ì‚¬
        messages = sample["messages"]
        if not isinstance(messages, list) or len(messages) == 0:
            return None
        
        # ê° ë©”ì‹œì§€ê°€ ì˜¬ë°”ë¥¸ í˜•ì‹ì¸ì§€ í™•ì¸
        for msg in messages:
            if not isinstance(msg, dict) or "role" not in msg or "content" not in msg:
                return None
            if not isinstance(msg["content"], str) or len(msg["content"].strip()) == 0:
                return None
        
        # ì±„íŒ… í…œí”Œë¦¿ ì ìš© - AutoProcessor í˜¸í™˜ì„± ê°œì„ 
        try:
            # AutoProcessorì¸ ê²½ìš° tokenizer ì†ì„±ì„ í†µí•´ ì ‘ê·¼
            if hasattr(tokenizer, 'tokenizer'):
                actual_tokenizer = tokenizer.tokenizer
            else:
                actual_tokenizer = tokenizer
            
            tokenized = actual_tokenizer.apply_chat_template(
                messages,
                tokenize=True,
                add_generation_prompt=False,
                # max_length=max_length,
                # truncation=True,
                return_dict=True,
                return_tensors="pt"
            )
        except Exception as e1:
            # ëŒ€ì•ˆ ë°©ë²•: ì±„íŒ… í…œí”Œë¦¿ ì—†ì´ ì§ì ‘ í…ìŠ¤íŠ¸ ë³€í™˜
            logger.warning(f"   âš ï¸ apply_chat_template ì‹¤íŒ¨, ëŒ€ì•ˆ ë°©ë²• ì‹œë„: {e1}")
            
            # ë©”ì‹œì§€ë¥¼ ì§ì ‘ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            text = ""
            for msg in messages:
                if msg["role"] == "user":
                    text += f"<start_of_turn>user\n{msg['content']}<end_of_turn>\n"
                elif msg["role"] == "assistant":
                    text += f"<start_of_turn>model\n{msg['content']}<end_of_turn>\n"
            
            # í† í¬ë‚˜ì´ì§•
            if hasattr(tokenizer, 'tokenizer'):
                actual_tokenizer = tokenizer.tokenizer
            else:
                actual_tokenizer = tokenizer
            
            tokenized = actual_tokenizer(
                text,
                max_length=max_length,
                # truncation=True,
                # padding=False,
                return_tensors="pt"
            )
        
        if tokenized is None:
            return None
        
        # í…ì„œë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ Datasetì— ì €ì¥ ê°€ëŠ¥í•˜ê²Œ í•¨
        result = {}
        for key, value in tokenized.items():
            if isinstance(value, torch.Tensor):
                result[key] = value.squeeze().tolist()
            else:
                result[key] = value
        
        # ìµœì†Œ ê¸¸ì´ í™•ì¸ (ë„ˆë¬´ ì§§ì€ ì‹œí€€ìŠ¤ ì œì™¸)
        if "input_ids" in result and len(result["input_ids"]) < 10:
            return None
        
        return result
        
    except Exception as e:
        # ë””ë²„ê¹…ì„ ìœ„í•´ ì˜ˆì™¸ ì •ë³´ ì¶œë ¥ (ì²˜ìŒ ëª‡ ê°œë§Œ)
        logger.error(f"âŒ í† í¬ë‚˜ì´ì§• ì˜ˆì™¸: {str(e)}")
        logger.error(f"   ìƒ˜í”Œ: {sample}")
        logger.error(f"   í† í¬ë‚˜ì´ì € íƒ€ì…: {type(tokenizer)}")
        logger.error(f"   í† í¬ë‚˜ì´ì €ì— chat_templateì´ ìˆëŠ”ê°€: {hasattr(tokenizer, 'chat_template')}")
        if hasattr(tokenizer, 'chat_template'):
            logger.error(f"   chat_template ê¸¸ì´: {len(str(tokenizer.chat_template)) if tokenizer.chat_template else 0}")
        import traceback
        traceback.print_exc()
        return None

def create_memory_efficient_collate_fn(tokenizer, max_length: int = 2048):
    """ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ collate function"""
    if hasattr(tokenizer, 'tokenizer'):
        actual_tokenizer = tokenizer.tokenizer
    else:
        actual_tokenizer = tokenizer
    
    # safe_flatten_images í•¨ìˆ˜ ì‚¬ìš©
    
    def collate_fn(examples):
        # ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë°°ì¹˜ ì²˜ë¦¬
        batch_input_ids = []
        batch_attention_mask = []
        
        for ex in examples:
            if "messages" in ex:
                # ì´ë¯¸ì§€ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš° ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
                if "images" in ex and ex["images"]:
                    # ì¤‘ì²© ë¦¬ìŠ¤íŠ¸ ë¬¸ì œ í•´ê²°
                    ex["images"] = validate_image_data(ex["images"])
                
                # ì‹¤ì‹œê°„ í† í¬ë‚˜ì´ì§• (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
                try:
                    # ë¨¼ì € í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    text = actual_tokenizer.apply_chat_template(
                        ex["messages"],
                        tokenize=False,
                        add_generation_prompt=False
                    )
                    
                    # ê·¸ ë‹¤ìŒ í† í¬ë‚˜ì´ì§•
                    tokenized = actual_tokenizer(
                        text,
                        max_length=max_length,
                        truncation=True,
                        padding=False,
                        return_tensors="pt"
                    )
                    
                    if tokenized is not None and "input_ids" in tokenized:
                        batch_input_ids.append(tokenized["input_ids"].squeeze())
                        batch_attention_mask.append(tokenized["attention_mask"].squeeze())
                except Exception as e:
                    logger.warning(f"í† í¬ë‚˜ì´ì§• ì‹¤íŒ¨: {e}")
                    continue
        
        if not batch_input_ids:
            return None
        
        # íŒ¨ë”© ì²˜ë¦¬
        from torch.nn.utils.rnn import pad_sequence
        
        input_ids = pad_sequence(
            batch_input_ids, 
            batch_first=True, 
            padding_value=actual_tokenizer.pad_token_id or actual_tokenizer.eos_token_id
        )
        attention_mask = pad_sequence(
            batch_attention_mask, 
            batch_first=True, 
            padding_value=0
        )
        
        # labelsëŠ” input_idsì™€ ë™ì¼ (causal LM)
        labels = input_ids.clone()
        
        # íŒ¨ë”© í† í°ì€ loss ê³„ì‚°ì—ì„œ ì œì™¸
        pad_token_id = actual_tokenizer.pad_token_id or actual_tokenizer.eos_token_id
        labels[labels == pad_token_id] = -100
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del batch_input_ids, batch_attention_mask
        gc.collect()
        
        return {
            "input_ids": input_ids,
            "attention_mask": attention_mask,
            "labels": labels
        }
    
    return collate_fn

def create_simple_collate_fn(processor, max_length: int = 2048):
    """SFTTrainerìš© ì»¤ìŠ¤í…€ data collator - ì´ë¯¸ì§€ ì¤‘ì²© ë¦¬ìŠ¤íŠ¸ ë¬¸ì œ í•´ê²°"""
    from trl.trainer.sft_trainer import DataCollatorForVisionLanguageModeling
    
    class CustomSFTDataCollator(DataCollatorForVisionLanguageModeling):
        def __init__(self, processor, max_length: int = 2048):
            super().__init__(processor = processor, max_length = max_length)
            self.processor = processor
            self.max_length = max_length
            
        def __call__(self, features):
            # ì´ë¯¸ì§€ ë°ì´í„° ê²€ì¦ - ì´ë¯¸ì§€ê°€ ì—†ëŠ” ìƒ˜í”Œì€ ì˜¤ë¥˜ ë°œìƒ
            assert features is not None, "features is None"
            batch_images = []
            batch_messages = []

            for i, feature in enumerate(features):
                if "messages" in feature:
                    feature["messages"] = validate_messages(feature["messages"])
                    # batch_messages.append(
                    #     self.processor.apply_chat_template(
                    #         feature["messages"], 
                    #         add_generation_prompt=False, 
                    #         tokenize=False)
                    #     )
                if 'images' not in feature or not feature['images']:
                    raise ValueError(f"ìƒ˜í”Œ {i}ì— ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤! ëª¨ë“  ìƒ˜í”Œì€ ì´ë¯¸ì§€ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.")
                
                # ì¤‘ì²© ë¦¬ìŠ¤íŠ¸ ë¬¸ì œ í•´ê²°
                feature['images'] = validate_image_data(feature['images'])
                if not feature['images']:
                    raise ValueError(f"ìƒ˜í”Œ {i}ì˜ ì´ë¯¸ì§€ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
                # batch_images.append(feature['images'])
            # processorë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ì²˜ë¦¬
            try:
                return self.torch_call(
                    examples=features
                )

                # return self.processor(
                #     images=safe_flatten_images(batch_images),
                #     text=batch_messages)


            except Exception as e:
                import traceback
                traceback.print_exc()
                print(f"âš ï¸ Processor ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                print(features)
                # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì²˜ë¦¬
                return features
    
    return CustomSFTDataCollator(processor)

def validate_messages(messages):
    """ë©”ì‹œì§€ ë°ì´í„°ì˜ ìœ íš¨ì„±ì„ ê²€ì‚¬í•˜ê³  ì¤‘ì²© ë¦¬ìŠ¤íŠ¸ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤."""
    for message in messages:
        content = message.get("content")
        if not content or not isinstance(content, list):
            continue
            
        # ë¹ ë¥¸ í•„í„°ë§: image íƒ€ì…ì—ì„œ text í‚¤ë§Œ ì œê±°
        for item in content:
            if (isinstance(item, dict) and 
                item.get("type") == "image" and 
                "text" in item):
                item.pop("text", None)
    
    return messages

def safe_flatten_images(images):
    """
    ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ì•ˆì „í•˜ê²Œ í‰ë©´í™”í•˜ì—¬ ì¤‘ì²© ë¦¬ìŠ¤íŠ¸ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.
    transformersì˜ image_utils.pyì—ì„œ ë°œìƒí•˜ëŠ” ValueErrorë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
    """
    if not images:
        return []
    
    flattened = []
    for img in images:
        if isinstance(img, list):
            # ì¤‘ì²©ëœ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì¬ê·€ì ìœ¼ë¡œ í‰ë©´í™”
            flattened.extend(safe_flatten_images(img))
        elif img is not None:
            flattened.append(img)
    
    return flattened

def validate_image_data(images):
    """
    ì´ë¯¸ì§€ ë°ì´í„°ì˜ ìœ íš¨ì„±ì„ ê²€ì‚¬í•˜ê³  ì¤‘ì²© ë¦¬ìŠ¤íŠ¸ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.
    """
    if images is None:
        return []
    
    if not images:
        return []
    
    # ì¤‘ì²© ë¦¬ìŠ¤íŠ¸ í‰ë©´í™”
    flattened = safe_flatten_images(images)
    
    # None ê°’ ì œê±°
    valid_images = [img for img in flattened if img is not None]
    
    return valid_images

def get_memory_usage():
    """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    import psutil
    process = psutil.Process(os.getpid())
    memory_info = process.memory_info()
    return memory_info.rss / (1024 * 1024 * 1024)  # GB ë‹¨ìœ„

def log_memory_usage(stage: str):
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ë¡œê¹…í•©ë‹ˆë‹¤."""
    memory_gb = get_memory_usage()
    logger.info(f"   ğŸ’¾ {stage} - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_gb:.2f} GB")

# í…ŒìŠ¤íŠ¸ìš© ì‘ì€ ë°ì´í„°ì…‹ ë¹Œë” í•¨ìˆ˜ë“¤
def smoltalk_dataset(tokenizer, max_samples: int = 500, use_streaming: bool = True):
    """SmolTalk ë°ì´í„°ì…‹ ë¹Œë” (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )"""
    log_memory_usage("SmolTalk ë°ì´í„°ì…‹ ì‹œì‘")
    dataset = get_simple_sft_dataset(
        dataset_name="HuggingFaceTB/smoltalk",
        tokenizer=tokenizer,
        max_samples=max_samples,
        use_streaming=use_streaming,
        chunk_size=50
    )
    log_memory_usage("SmolTalk ë°ì´í„°ì…‹ ì™„ë£Œ")
    return dataset

def orca_mini_dataset(tokenizer, max_samples: int = 500, use_streaming: bool = True):
    """Orca ë¯¸ë‹ˆ ë°ì´í„°ì…‹ ë¹Œë” (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )"""
    log_memory_usage("Orca ë°ì´í„°ì…‹ ì‹œì‘")
    dataset = get_simple_sft_dataset(
        dataset_name="microsoft/orca-agentinstruct-1M-v1",
        tokenizer=tokenizer, 
        max_samples=max_samples,
        use_streaming=use_streaming,
        chunk_size=50
    )
    log_memory_usage("Orca ë°ì´í„°ì…‹ ì™„ë£Œ")
    return dataset

def create_memory_efficient_dataset(
    dataset_name: str,
    tokenizer,
    max_samples: int = 1000,
    chunk_size: int = 50,
    use_streaming: bool = True
):
    """ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë°ì´í„°ì…‹ ìƒì„±ê¸°"""
    log_memory_usage(f"{dataset_name} ë°ì´í„°ì…‹ ì‹œì‘")
    
    dataset = get_simple_sft_dataset(
        dataset_name=dataset_name,
        tokenizer=tokenizer,
        max_samples=max_samples,
        use_streaming=use_streaming,
        chunk_size=chunk_size
    )
    
    log_memory_usage(f"{dataset_name} ë°ì´í„°ì…‹ ì™„ë£Œ")
    return dataset

def get_available_configs(dataset_name: str) -> List[str]:
    """ë°ì´í„°ì…‹ì˜ ì‚¬ìš© ê°€ëŠ¥í•œ config ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        configs = get_dataset_config_names(dataset_name)
        logger.info(f"ğŸ“‹ {dataset_name} ì‚¬ìš© ê°€ëŠ¥í•œ configs ({len(configs)}ê°œ):")
        for i, config in enumerate(configs[:10]):  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥
            logger.info(f"   {i+1}. {config}")
        if len(configs) > 10:
            logger.info(f"   ... ë° {len(configs) - 10}ê°œ ë”")
        return configs
    except Exception as e:
        logger.error(f"âŒ config ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return []


if __name__ == "__main__":
    # ë©”ëª¨ë¦¬ íš¨ìœ¨ì  í…ŒìŠ¤íŠ¸
    from transformers import AutoTokenizer
    
    logger.info("ğŸš€ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    log_memory_usage("í”„ë¡œê·¸ë¨ ì‹œì‘")
    
    tokenizer = AutoTokenizer.from_pretrained("google/gemma-2b-it")
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
    
    log_memory_usage("í† í¬ë‚˜ì´ì € ë¡œë“œ í›„")
    
    # Config ì²˜ë¦¬ í™•ì¸ì„ ìœ„í•œ í…ŒìŠ¤íŠ¸
    try:
        logger.info("ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ config í™•ì¸")
        configs = get_available_configs("HuggingFaceTB/smoltalk")
        logger.info(f"ì´ {len(configs)}ê°œ config ë°œê²¬")
    except Exception as e:
        logger.error(f"Config í™•ì¸ ì‹¤íŒ¨: {e}")
    
    # SmolTalk ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ (ìŠ¤íŠ¸ë¦¬ë°) - ëª¨ë“  config ì²˜ë¦¬
    try:
        logger.info("ğŸ“¦ SmolTalk ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ (ìŠ¤íŠ¸ë¦¬ë° - ëª¨ë“  config)")
        dataset = smoltalk_dataset(tokenizer, max_samples=100, use_streaming=True)
        log_memory_usage("SmolTalk ë°ì´í„°ì…‹ ìƒì„± í›„")
        
        logger.info(f"ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ: {dataset}")
        
        # ì²« ë²ˆì§¸ ìƒ˜í”Œ í™•ì¸
        try:
            first_sample = dataset['train'][0]
            logger.info(f"ìƒ˜í”Œ ì˜ˆì‹œ: {first_sample}")
        except Exception as e:
            logger.error(f"ìƒ˜í”Œ ì ‘ê·¼ ì‹¤íŒ¨: {e}")
            
    except Exception as e:
        logger.error(f"SmolTalk ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    
    # ì¼ë°˜ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ (ë¹„ìŠ¤íŠ¸ë¦¬ë°)
    try:
        logger.info("ğŸ“¦ SmolTalk ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ (ì¼ë°˜)")
        dataset2 = smoltalk_dataset(tokenizer, max_samples=100, use_streaming=False)
        log_memory_usage("SmolTalk ì¼ë°˜ ë°ì´í„°ì…‹ ìƒì„± í›„")
        
        logger.info(f"ì¼ë°˜ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ: {dataset2}")
            
    except Exception as e:
        logger.error(f"SmolTalk ì¼ë°˜ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    
    log_memory_usage("í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    logger.info("âœ… ë©”ëª¨ë¦¬ íš¨ìœ¨ì  í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
