from datasets import load_dataset, concatenate_datasets, Dataset, Features, Value, Sequence, Image as ImageFeature
import json
from typing import List, Dict, Any
from tqdm import tqdm
import os
import requests
from PIL import Image
from io import BytesIO

# ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì…‹ ëª©ë¡
dataset_configs = [
    ("Salesforce/blip3-kale", "core"),
    ("liuhaotian/LLaVA-Instruct-150K", None),
    ("Lin-Chen/ShareGPT4V", "ShareGPT4V")
]

def construct_image_url(image_path, dataset_name):
    """ë°ì´í„°ì…‹ë³„ë¡œ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì‹¤ì œ URLë¡œ ë³€í™˜"""
    if dataset_name == "Lin-Chen/ShareGPT4V":
        # ShareGPT4VëŠ” COCO ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©
        if image_path.startswith('coco/'):
            # coco/train2017/000000000009.jpg -> COCO ì´ë¯¸ì§€ URL
            filename = os.path.basename(image_path)
            return f"http://images.cocodataset.org/train2017/{filename}"
    elif dataset_name == "liuhaotian/LLaVA-Instruct-150K":
        # LLaVAë„ COCO ì´ë¯¸ì§€ë¥¼ ì£¼ë¡œ ì‚¬ìš©
        if not image_path.startswith('http'):
            # íŒŒì¼ëª…ë§Œ ìˆëŠ” ê²½ìš° COCO URL êµ¬ì„± ì‹œë„
            return f"http://images.cocodataset.org/train2017/{image_path}"
    
    return None

def load_image_from_url_or_path(image_source, dataset_name=None):
    """
    URLì´ë‚˜ ê²½ë¡œì—ì„œ ì‹¤ì œ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    """
    try:
        # ì´ë¯¸ PIL Image ê°ì²´ì¸ ê²½ìš°
        if hasattr(image_source, 'size') and hasattr(image_source, 'convert'):
            return image_source.convert('RGB')
        
        # ë¬¸ìì—´ì¸ ê²½ìš° (URL ë˜ëŠ” íŒŒì¼ëª…)
        if isinstance(image_source, str):
            # HTTP/HTTPS URLì¸ ê²½ìš°
            if image_source.startswith('http://') or image_source.startswith('https://'):
                response = requests.get(image_source, timeout=15)
                response.raise_for_status()
                image = Image.open(BytesIO(response.content))
                return image.convert('RGB')
            
            # ë¡œì»¬ íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°
            elif os.path.exists(image_source):
                image = Image.open(image_source)
                return image.convert('RGB')
            
            # íŒŒì¼ëª…ë§Œ ìˆëŠ” ê²½ìš° - URL êµ¬ì„± ì‹œë„
            else:
                if dataset_name:
                    constructed_url = construct_image_url(image_source, dataset_name)
                    if constructed_url:
                        print(f"ğŸ”— URL êµ¬ì„± ì‹œë„: {constructed_url}")
                        try:
                            response = requests.get(constructed_url, timeout=15)
                            response.raise_for_status()
                            image = Image.open(BytesIO(response.content))
                            print(f"âœ… êµ¬ì„±ëœ URLì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ ì„±ê³µ: {image.size}")
                            return image.convert('RGB')
                        except:
                            print(f"âš ï¸ êµ¬ì„±ëœ URLì—ì„œ ë¡œë“œ ì‹¤íŒ¨: {constructed_url}")
                
                print(f"âš ï¸ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŒ: {image_source}")
                return None
        
        # bytes ë°ì´í„°ì¸ ê²½ìš°
        elif isinstance(image_source, bytes):
            image = Image.open(BytesIO(image_source))
            return image.convert('RGB')
            
        else:
            return None
        
    except Exception as e:
        print(f"âš ï¸ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def convert_to_target_format(sample: Dict[str, Any], dataset_name: str) -> Dict[str, Any]:
    """
    ê° ë°ì´í„°ì…‹ì˜ ìƒ˜í”Œì„ ëª©í‘œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    ëª©í‘œ í˜•ì‹:
    {
        "messages": [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "ì§ˆë¬¸", "index": null},
                    {"type": "image", "text": null, "index": 0}
                ]
            },
            {
                "role": "assistant", 
                "content": [
                    {"type": "text", "text": "ë‹µë³€", "index": null}
                ]
            }
        ],
        "images": [actual_image_object]
    }
    """
    
    result = {
        "messages": [],
        "images": []
    }
    
    # ì´ë¯¸ì§€ ì¶”ì¶œ ë° ë¡œë“œ
    image_obj = None
    if "image" in sample and sample["image"] is not None:
        # dataset_nameì„ ì „ë‹¬í•˜ì—¬ URL êµ¬ì„± ê°€ëŠ¥í•˜ë„ë¡ í•¨
        image_obj = load_image_from_url_or_path(sample["image"], dataset_name)
    elif "images" in sample and sample["images"] is not None:
        if isinstance(sample["images"], list) and len(sample["images"]) > 0:
            image_obj = load_image_from_url_or_path(sample["images"][0], dataset_name)
        else:
            image_obj = load_image_from_url_or_path(sample["images"], dataset_name)
    elif dataset_name == "Salesforce/blip3-kale" and "url" in sample:
        # blip3-kaleì€ url í•„ë“œì— ì´ë¯¸ì§€ URLì´ ìˆìŒ
        image_obj = load_image_from_url_or_path(sample["url"], dataset_name)
    
    if image_obj is not None:
        result["images"].append(image_obj)
        print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¡œë“œ ì„±ê³µ: {getattr(image_obj, 'size', 'unknown size')}")
    
    # ë°ì´í„°ì…‹ë³„ conversations ì²˜ë¦¬
    conversations = None
    
    if dataset_name == "Lin-Chen/ShareGPT4V":
        conversations = sample.get("conversations", [])
    elif dataset_name == "liuhaotian/LLaVA-Instruct-150K":  
        conversations = sample.get("conversations", [])
    elif dataset_name == "Salesforce/blip3-kale":
        # blip3-kaleì€ caption í•„ë“œë¥¼ ì‚¬ìš©
        caption = sample.get("caption", "").strip()
        if caption:
            # captionì„ assistant ì‘ë‹µìœ¼ë¡œ ì²˜ë¦¬
            conversations = [
                {"from": "human", "value": "Describe this image."},
                {"from": "gpt", "value": caption}
            ]
        else:
            # cogvlm_caption ì‹œë„
            cogvlm_caption = sample.get("cogvlm_caption", "").strip()
            if cogvlm_caption:
                conversations = [
                    {"from": "human", "value": "Describe this image."},
                    {"from": "gpt", "value": cogvlm_caption}
                ]
    
    if not conversations:
        return None  # ë³€í™˜í•  ìˆ˜ ì—†ëŠ” ìƒ˜í”Œ
    
    # conversationsë¥¼ messagesë¡œ ë³€í™˜
    for i, conv in enumerate(conversations):
        if not isinstance(conv, dict):
            continue
            
        # role ê²°ì •
        role = "assistant"
        if "from" in conv:
            if conv["from"] in ["human", "user"]:
                role = "user"
            elif conv["from"] in ["gpt", "assistant"]:
                role = "assistant"
        
        # content ìƒì„±
        content_list = []
        text_content = conv.get("value", "")
        
        if text_content:
            # <image> íƒœê·¸ ì œê±° (ì´ë¯¸ì§€ëŠ” ë³„ë„ ì²˜ë¦¬)
            text_content = text_content.replace("<image>", "").strip()
            
            if text_content:  # ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš°ë§Œ
                content_list.append({
                    "type": "text",
                    "text": text_content,
                    "index": None
                })
        
        # ì²« ë²ˆì§¸ user ë©”ì‹œì§€ì— ì´ë¯¸ì§€ ì¶”ê°€
        if role == "user" and i == 0 and result["images"]:
            content_list.append({
                "type": "image", 
                "text": None,
                "index": 0
            })
        
        if content_list:  # contentê°€ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€
            result["messages"].append({
                "role": role,
                "content": content_list
            })
    
    return result if result["messages"] else None

def process_dataset(dataset_name: str, config_name: str = None, max_samples: int = None):
    """ë°ì´í„°ì…‹ì„ ì²˜ë¦¬í•˜ì—¬ ëª©í‘œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    try:
        print(f"\nğŸ”„ ì²˜ë¦¬ ì¤‘: {dataset_name}")
        if config_name:
            print(f"   Config: {config_name}")
        
        # ë°ì´í„°ì…‹ ë¡œë“œ - ì‘ì€ ë°°ì¹˜ë¡œ ì²˜ë¦¬í•˜ì—¬ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í™•ë³´
        try:
            if config_name:
                full_dataset = load_dataset(dataset_name, config_name, split="train")
            else:
                full_dataset = load_dataset(dataset_name, split="train")
        except Exception as e:
            print(f"âŒ ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return
        
        # ì²˜ë¦¬í•  ìƒ˜í”Œ ìˆ˜ ê²°ì •
        total_samples = len(full_dataset)
        samples_to_process = min(max_samples or total_samples, total_samples)
        
        print(f"ğŸ“Š ì´ {total_samples}ê°œ ìƒ˜í”Œ ì¤‘ {samples_to_process}ê°œ ì²˜ë¦¬ ì˜ˆì •")
        
        processed_samples = []
        success_count = 0
        
        # ì‘ì€ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ ê´€ë¦¬)
        batch_size = 100
        for start_idx in range(0, samples_to_process, batch_size):
            end_idx = min(start_idx + batch_size, samples_to_process)
            batch = full_dataset.select(range(start_idx, end_idx))
            
            print(f"ğŸ”„ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘: {start_idx+1}-{end_idx}/{samples_to_process}")
            
            for sample in tqdm(batch, desc=f"Processing batch"):
                # ë³€í™˜ ì‹œë„
                converted = convert_to_target_format(sample, dataset_name)
                if converted:
                    processed_samples.append(converted)
                    success_count += 1
                    
                    # ì²˜ìŒ ëª‡ ê°œ ìƒ˜í”Œì—ì„œ ì´ë¯¸ì§€ í™•ì¸
                    if success_count <= 3 and converted["images"]:
                        print(f"âœ… {dataset_name}: {len(converted['images'])}ê°œ ì´ë¯¸ì§€ í¬í•¨")
                
                # ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•œ ì¤‘ê°„ yield
                if len(processed_samples) >= 200:
                    yield processed_samples
                    processed_samples = []
            
            # ë°°ì¹˜ ì²˜ë¦¬ í›„ ë©”ëª¨ë¦¬ ì •ë¦¬
            del batch
        
        if processed_samples:
            yield processed_samples
            
        print(f"âœ… {dataset_name}: {success_count}/{count} ìƒ˜í”Œ ë³€í™˜ ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ {dataset_name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")

def merge_and_create_dataset(output_name: str = "unified-multimodal-sft", max_samples_per_dataset: int = None):
    """ëª¨ë“  ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì…‹ì„ ë³‘í•©í•˜ê³  ëª©í‘œ í˜•ì‹ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤."""
    print("ğŸš€ ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì…‹ ë³‘í•© ì‹œì‘...")
    
    all_samples = []
    
    for dataset_name, config_name in dataset_configs:
        try:
            for batch in process_dataset(dataset_name, config_name, max_samples_per_dataset):
                all_samples.extend(batch)
                print(f"ğŸ“Š í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ìƒ˜í”Œ ìˆ˜: {len(all_samples)}")
        except Exception as e:
            print(f"âŒ {dataset_name} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            continue
    
    if not all_samples:
        print("âŒ ë³€í™˜ëœ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    print(f"\nğŸ¯ ì´ {len(all_samples)}ê°œ ìƒ˜í”Œ ë³€í™˜ ì™„ë£Œ")
    
    # ë°ì´í„° ê²€ì¦
    valid_samples = 0
    image_samples = 0
    
    for sample in all_samples[:100]:  # ì²˜ìŒ 100ê°œë§Œ ê²€ì¦
        if "messages" in sample and "images" in sample:
            valid_samples += 1
            if sample["images"]:
                image_samples += 1
    
    print(f"ğŸ“‹ ìƒ˜í”Œ ê²€ì¦ (ì²˜ìŒ 100ê°œ): {valid_samples}/100 ìœ íš¨, {image_samples}/100 ì´ë¯¸ì§€ í¬í•¨")
    
    # Dataset ìƒì„± - ì´ë¯¸ì§€ featureë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •
    print("ğŸ“¦ Dataset ê°ì²´ ìƒì„± ì¤‘...")
    
    # HuggingFace Image feature êµ¬ì¡° ì •ì˜
    features = Features({
        "messages": Sequence({
            "role": Value("string"),
            "content": Sequence({
                "type": Value("string"),
                "text": Value("string"),
                "index": Value("int64")
            })
        }),
        "images": Sequence(ImageFeature())  # ì´ë¯¸ì§€ feature ëª…ì‹œ
    })
    
    unified_dataset = Dataset.from_list(all_samples, features=features)
    
    # ë¡œì»¬ ì €ì¥
    print("ğŸ’¾ ë¡œì»¬ ì €ì¥ ì¤‘...")
    unified_dataset.save_to_disk(f"./{output_name}")
    
    # í—ˆê¹…í˜ì´ìŠ¤ ì—…ë¡œë“œ ì‹œë„
    try:
        print("ğŸš€ í—ˆê¹…í˜ì´ìŠ¤ ì—…ë¡œë“œ ì‹œë„...")
        unified_dataset.push_to_hub(output_name, private=False)
        print(f"âœ… ì„±ê³µì ìœ¼ë¡œ {output_name}ìœ¼ë¡œ ì—…ë¡œë“œ!")
    except Exception as e:
        print(f"âš ï¸ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        print("ğŸ’¾ ë¡œì»¬ ì €ì¥ì€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    return unified_dataset

def inspect_dataset(dataset_path: str = "./unified-multimodal-sft"):
    """ìƒì„±ëœ ë°ì´í„°ì…‹ ê²€ì‚¬"""
    try:
        print(f"ğŸ” ë°ì´í„°ì…‹ ê²€ì‚¬: {dataset_path}")
        
        dataset = Dataset.load_from_disk(dataset_path)
        print(f"ğŸ“Š ì´ ìƒ˜í”Œ ìˆ˜: {len(dataset)}")
        
        # êµ¬ì¡° ê²€ì‚¬
        sample_with_image = None
        sample_without_image = None
        
        for sample in dataset:
            if sample.get("images") and not sample_with_image:
                sample_with_image = sample
            elif not sample.get("images") and not sample_without_image:
                sample_without_image = sample
            
            if sample_with_image and sample_without_image:
                break
        
        # ì´ë¯¸ì§€ í¬í•¨ ìƒ˜í”Œ ì˜ˆì‹œ
        if sample_with_image:
            print(f"\nğŸ–¼ï¸ ì´ë¯¸ì§€ í¬í•¨ ìƒ˜í”Œ ì˜ˆì‹œ:")
            print(f"   ì´ë¯¸ì§€ ìˆ˜: {len(sample_with_image['images'])}")
            print(f"   ë©”ì‹œì§€ ìˆ˜: {len(sample_with_image['messages'])}")
            
            # ì²« ë²ˆì§¸ ë©”ì‹œì§€ êµ¬ì¡° í™•ì¸
            if sample_with_image['messages']:
                first_msg = sample_with_image['messages'][0]
                print(f"   ì²« ë²ˆì§¸ ë©”ì‹œì§€ role: {first_msg.get('role')}")
                print(f"   ì²« ë²ˆì§¸ ë©”ì‹œì§€ content ìˆ˜: {len(first_msg.get('content', []))}")
                
                for j, content in enumerate(first_msg.get('content', [])[:3]):
                    content_type = content.get('type', 'unknown')
                    if content_type == 'text':
                        text_preview = content.get('text', '')[:50] + "..." if len(content.get('text', '')) > 50 else content.get('text', '')
                        print(f"     Content {j+1}: {content_type} - '{text_preview}'")
                    else:
                        print(f"     Content {j+1}: {content_type} - index: {content.get('index')}")
        
        # í†µê³„
        image_count = sum(1 for sample in dataset if sample.get("images"))
        print(f"\nğŸ“ˆ ì´ë¯¸ì§€ í¬í•¨ ìƒ˜í”Œ: {image_count}/{len(dataset)} ({image_count/len(dataset)*100:.1f}%)")
        
        return dataset
        
    except Exception as e:
        print(f"âŒ ê²€ì‚¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import sys
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "merge":
            if len(sys.argv) < 3:
                print("âŒ ë¦¬í¬ì§€í† ë¦¬ ì´ë¦„ì´ í•„ìš”í•©ë‹ˆë‹¤!")
                print("ì‚¬ìš©ë²•: python upload_sft_dataset.py merge <repository_name> [max_samples_per_dataset]")
                return
            
            repository_name = sys.argv[2]
            max_samples = int(sys.argv[3]) if len(sys.argv) > 3 else None
            
            print(f"ğŸ¯ íƒ€ê²Ÿ ë¦¬í¬ì§€í† ë¦¬: {repository_name}")
            dataset = merge_and_create_dataset(output_name=repository_name, max_samples_per_dataset=max_samples)
            if dataset:
                print("ğŸ‰ ë³‘í•© ì™„ë£Œ!")
                
        elif sys.argv[1] == "inspect":
            dataset_path = sys.argv[2] if len(sys.argv) > 2 else "./unified-multimodal-sft"
            inspect_dataset(dataset_path)
            
    else:
        print("ì‚¬ìš©ë²•:")
        print("  python upload_sft_dataset.py merge <repository_name> [max_samples_per_dataset]")
        print("  python upload_sft_dataset.py inspect [dataset_path]")
        print("")
        print("ì˜ˆì‹œ:")
        print("  python upload_sft_dataset.py merge my-multimodal-dataset 1000")
        print("  python upload_sft_dataset.py merge my-multimodal-dataset")  # ì „ì²´ ë°ì´í„°
        print("  python upload_sft_dataset.py inspect ./my-multimodal-dataset")

if __name__ == "__main__":
    main()