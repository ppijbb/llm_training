from datasets import load_dataset, concatenate_datasets, Dataset, Features, Value, Sequence, Image as ImageFeature, load_from_disk, DatasetDict
from huggingface_hub import HfApi
import json
from typing import List, Dict, Any, Optional, cast
from tqdm.auto import tqdm
import os
import requests
from PIL import Image
from io import BytesIO
from huggingface_hub.utils.tqdm import disable_progress_bars
import concurrent.futures
from functools import partial
import threading
import time
from urllib.parse import urlparse
import hashlib
import gc
import datetime
import argparse
import sys
import pandas as pd
import tempfile
import shutil

# PNG í…ìŠ¤íŠ¸ ì²­í¬ í¬ê¸° ì œí•œ ì¦ê°€ (Decompressed data too large ì˜¤ë¥˜ í•´ê²°)
# ì¼ë¶€ ì´ë¯¸ì§€ì— ë§¤ìš° í° ë©”íƒ€ë°ì´í„°ê°€ í¬í•¨ëœ ê²½ìš°ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•¨
from PIL import PngImagePlugin
PngImagePlugin.MAX_TEXT_CHUNK = 100 * 1024 * 1024 # 100MBë¡œ ì œí•œ ì¦ê°€

disable_progress_bars()  # ì§„í–‰ í‘œì‹œì¤„ ë¹„í™œì„±í™”

# ì´ë¯¸ì§€ ìºì‹œ ë° ì„¸ì…˜ ì„¤ì •
image_cache = {}
cache_lock = threading.Lock()

# ì„¸ì…˜ í’€ ìƒì„± (ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì—°ê²°)
session = requests.Session()
session.headers.update({
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
})

# ë°ì´í„°ì…‹ë³„ ëª¨ë“œ ì„ íƒ ë§¤í•‘ (reasoning ëª¨ë“œì™€ instruction ëª¨ë“œ êµ¬ë¶„)
DATASET_MODE_MAPPING = {
    # Reasoning ëª¨ë“œê°€ ì í•©í•œ ë°ì´í„°ì…‹ë“¤ (ë³µì¡í•œ ì¶”ë¡ ê³¼ ë…¼ë¦¬ì  ì‚¬ê³ ê°€ í•„ìš”í•œ ë°ì´í„°ì…‹)
    "HuggingFaceTB/smoltalk": "reasoning",
    "PrincetonPLI/Instruct-SkillMix-SDD": "reasoning", 
    "nvidia/OpenCodeInstruct": "reasoning",
    "microsoft/orca-agentinstruct-1M-v1": "reasoning",
    "open-r1/Mixture-of-Thoughts": "reasoning",
    "NousResearch/Hermes-3-Dataset": "reasoning",
    
    # Instruction ëª¨ë“œê°€ ì í•©í•œ ë°ì´í„°ì…‹ë“¤ (ëª…í™•í•œ ì§€ì‹œì‚¬í•­ ìˆ˜í–‰ê³¼ ëŒ€í™”ì— íŠ¹í™”ëœ ë°ì´í„°ì…‹)
    "R0k1e/UltraLink": "instruction",
    "allenai/WildChat-1M": "instruction",
    "MaziyarPanahi/Llama-Nemotron-Post-Training-Dataset-v1-ShareGPT": "instruction",
    "nvidia/Llama-Nemotron-Post-Training-Dataset": "instruction",
    "Salesforce/blip3-kale": "instruction",
    "liuhaotian/LLaVA-Instruct-150K": "instruction",
    "Lin-Chen/ShareGPT4V": "instruction",
    "nvidia/Llama-Nemotron-VLM-Dataset-v1": "instruction"
}

# í†µí•© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ - ê°„ê²°í•˜ê³  ëª…í™•í•œ ë²„ì „
UNIFIED_SYSTEM_PROMPT = """You are an AI assistant. You have two modes:

**REASONING MODE**: Use "Let me think through this step by step..." for complex problems, coding, math, or when user requests deep thinking.

**INSTRUCTION MODE**: Follow instructions directly for simple tasks, questions, or conversations.

Choose mode based on user request. For images, analyze carefully and choose appropriate mode."""

# ë°ì´í„°ì…‹ë³„ ëª¨ë“œ ì„ íƒ ë§¤í•‘
DATASET_MODE_MAPPING = {
    # Reasoning ëª¨ë“œê°€ ì í•©í•œ ë°ì´í„°ì…‹ë“¤
    "HuggingFaceTB/smoltalk": "reasoning",
    "PrincetonPLI/Instruct-SkillMix-SDD": "reasoning", 
    "nvidia/OpenCodeInstruct": "reasoning",
    "microsoft/orca-agentinstruct-1M-v1": "reasoning",
    "open-r1/Mixture-of-Thoughts": "reasoning",
    "NousResearch/Hermes-3-Dataset": "reasoning",
    
    # Instruction ëª¨ë“œê°€ ì í•©í•œ ë°ì´í„°ì…‹ë“¤
    "R0k1e/UltraLink": "instruction",
    "allenai/WildChat-1M": "instruction",
    "MaziyarPanahi/Llama-Nemotron-Post-Training-Dataset-v1-ShareGPT": "instruction",
    "nvidia/Llama-Nemotron-Post-Training-Dataset": "instruction",
    "Salesforce/blip3-kale": "instruction",
    "liuhaotian/LLaVA-Instruct-150K": "instruction",
    "Lin-Chen/ShareGPT4V": "instruction",
    "nvidia/Llama-Nemotron-VLM-Dataset-v1": "instruction"
}

# ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì…‹ ëª©ë¡
dataset_configs = [
    ("HuggingFaceTB/smoltalk", "all"),
    ("R0k1e/UltraLink", None),
    ("PrincetonPLI/Instruct-SkillMix-SDD", None),
    ("allenai/WildChat-1M", None),
    ("nvidia/OpenCodeInstruct", None),
    ("microsoft/orca-agentinstruct-1M-v1", "default"),  # default config ì‚¬ìš©
    ("MaziyarPanahi/Llama-Nemotron-Post-Training-Dataset-v1-ShareGPT", "default"),  # default config ì‚¬ìš©
    ("nvidia/Llama-Nemotron-Post-Training-Dataset", "SFT"),  # SFT config ì‚¬ìš©
    ("open-r1/Mixture-of-Thoughts", "all"),
    ("Salesforce/blip3-kale", "core"),
    ("liuhaotian/LLaVA-Instruct-150K", None),
    ("Lin-Chen/ShareGPT4V", "ShareGPT4V"),
    # ì¶”ê°€: Hermes-3, Nemotron VLM v1
    ("NousResearch/Hermes-3-Dataset", None),
    ("nvidia/Llama-Nemotron-VLM-Dataset-v1", None)
]

def get_system_prompt_for_dataset(dataset_name: str) -> str:
    """ë°ì´í„°ì…‹ì— ì ì ˆí•œ í†µí•© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return UNIFIED_SYSTEM_PROMPT

def get_dataset_mode(dataset_name: str) -> str:
    """ë°ì´í„°ì…‹ì˜ ê¸°ë³¸ ëª¨ë“œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return DATASET_MODE_MAPPING.get(dataset_name, "instruction")

def add_system_prompt_to_messages(messages: List[Dict[str, Any]], system_prompt: str, dataset_name: str) -> List[Dict[str, Any]]:
    """ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ì˜ ë§¨ ì•ì— ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ ëª¨ë“œ ì„ íƒ ì§€ì‹œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤. ê¸°ì¡´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ê°€ ìˆë‹¤ë©´ ë³‘í•©í•©ë‹ˆë‹¤."""
    if not messages:
        return messages
    
    # ë°ì´í„°ì…‹ì˜ ê¸°ë³¸ ëª¨ë“œ ê°€ì ¸ì˜¤ê¸°
    default_mode = get_dataset_mode(dataset_name)
    
    # ê¸°ì¡´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì¶”ì¶œ
    existing_system_prompt = ""
    non_system_messages = []
    
    for message in messages:
        if message.get("role") == "system":
            # ê¸°ì¡´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë‚´ìš© ì¶”ì¶œ
            content = message.get("content", [])
            if isinstance(content, list) and len(content) > 0:
                existing_system_prompt = str(content[0].get("text", ""))
            elif isinstance(content, str):
                existing_system_prompt = content
        else:
            non_system_messages.append(message)
    
    # ëª¨ë“œ ì„ íƒ ì§€ì‹œë¥¼ í¬í•¨í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
    mode_instruction = f"\n\n**Current Context:** This dataset typically requires {default_mode.upper()} MODE responses. However, adapt the mode based on the specific user request as outlined in the system prompt above."
    
    # ê¸°ì¡´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ ìƒˆë¡œìš´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë³‘í•©
    if existing_system_prompt:
        # ê¸°ì¡´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ê°€ ìˆìœ¼ë©´ ë³‘í•©
        combined_system_prompt = f"{existing_system_prompt}\n\n{system_prompt}{mode_instruction}"
    else:
        # ê¸°ì¡´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œìš´ ê²ƒë§Œ ì‚¬ìš©
        combined_system_prompt = system_prompt + mode_instruction
    
    # ë³‘í•©ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì²« ë²ˆì§¸ ë©”ì‹œì§€ë¡œ ì¶”ê°€
    system_message = {
        "role": "system",
        "content": [{"type": "text", "text": combined_system_prompt}]
    }
    
    return [system_message] + non_system_messages

def construct_image_url(
    image_path,
    dataset_name
):
    """ë°ì´í„°ì…‹ë³„ë¡œ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì‹¤ì œ URLë¡œ ë³€í™˜"""
    if dataset_name == "Lin-Chen/ShareGPT4V":
        # ShareGPT4VëŠ” COCO ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©
        if image_path.startswith('coco/'):
            # coco/train2017/000000000009.jpg -> COCO ì´ë¯¸ì§€ URL
            filename = os.path.basename(image_path)
            return f"http://images.cocodataset.org/train2017/{filename}"
    elif dataset_name == "liuhaotian/LLaVA-Instruct-150K":
        # LLaVAë„ COCO ì´ë¯¸ì§€ë¥¼ ì£¼ë¡œ ì‚¬ìš©
        if not image_path.startswith('http'):
            # íŒŒì¼ëª…ë§Œ ìˆëŠ” ê²½ìš° COCO URL êµ¬ì„± ì‹œë„
            return f"http://images.cocodataset.org/train2017/{image_path}"
    
    return None

def get_image_cache_key(image_url):
    """ì´ë¯¸ì§€ URLì—ì„œ ìºì‹œ í‚¤ ìƒì„±"""
    return hashlib.md5(image_url.encode()).hexdigest()

def download_image_with_retry(image_url, max_retries=3, timeout=10):
    """ì¬ì‹œë„ ë¡œì§ì´ ìˆëŠ” ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ"""
    for attempt in range(max_retries):
        try:
            response = session.get(image_url, timeout=timeout)
            response.raise_for_status()
            return response.content
        except Exception as e:
            if attempt == max_retries - 1:
                return None
            time.sleep(0.5 * (2 ** attempt))  # ì§€ìˆ˜ ë°±ì˜¤í”„
    return None

def load_image_from_url_or_path(
    image_source,
    dataset_name=None
):
    """
    URLì´ë‚˜ ê²½ë¡œì—ì„œ ì‹¤ì œ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤. (ìºì‹œ ë° ìµœì í™” í¬í•¨)
    """
    try:
        # ì´ë¯¸ PIL Image ê°ì²´ì¸ ê²½ìš°
        if hasattr(image_source, 'size') and hasattr(image_source, 'convert'):
            return image_source.convert('RGB')
        
        # ë¬¸ìì—´ì¸ ê²½ìš° (URL ë˜ëŠ” íŒŒì¼ëª…)
        if isinstance(image_source, str):
            # HTTP/HTTPS URLì¸ ê²½ìš°
            if image_source.startswith('http://') or image_source.startswith('https://'):
                # ìºì‹œ í™•ì¸
                cache_key = get_image_cache_key(image_source)
                with cache_lock:
                    if cache_key in image_cache:
                        return image_cache[cache_key]
                
                # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                image_data = download_image_with_retry(image_source)
                if image_data:
                    image = Image.open(BytesIO(image_data))
                    image = image.convert('RGB')
                    
                    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì œí•œì„ ìœ„í•œ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
                    max_size = (1024, 1024)
                    if image.size[0] > max_size[0] or image.size[1] > max_size[1]:
                        image.thumbnail(max_size, Image.Resampling.LANCZOS)
                    
                    # ìºì‹œì— ì €ì¥ (ìµœê·¼ 100ê°œë§Œ ìœ ì§€)
                    with cache_lock:
                        if len(image_cache) >= 100:
                            # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
                            oldest_key = next(iter(image_cache))
                            del image_cache[oldest_key]
                        image_cache[cache_key] = image
                    
                    return image
                return None
            
            # ë¡œì»¬ íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°
            elif os.path.exists(image_source):
                image = Image.open(image_source)
                image = image.convert('RGB')
                # í¬ê¸° ì¡°ì •
                max_size = (1024, 1024)
                if image.size[0] > max_size[0] or image.size[1] > max_size[1]:
                    image.thumbnail(max_size, Image.Resampling.LANCZOS)
                return image
            
            # íŒŒì¼ëª…ë§Œ ìˆëŠ” ê²½ìš° - URL êµ¬ì„± ì‹œë„
            else:
                if dataset_name:
                    constructed_url = construct_image_url(image_source, dataset_name)
                    if constructed_url:
                        return load_image_from_url_or_path(constructed_url, dataset_name)
                return None
        
        # bytes ë°ì´í„°ì¸ ê²½ìš°
        elif isinstance(image_source, bytes):
            image = Image.open(BytesIO(image_source))
            image = image.convert('RGB')
            # í¬ê¸° ì¡°ì •
            max_size = (1024, 1024)
            if image.size[0] > max_size[0] or image.size[1] > max_size[1]:
                image.thumbnail(max_size, Image.Resampling.LANCZOS)
            return image
            
        else:
            return None
        
    except Exception as e:
        return None

def process_image_batch(
    image_sources_with_info,
    max_workers=8
):
    """ì´ë¯¸ì§€ ë°°ì¹˜ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬"""
    results = []
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        # ëª¨ë“  ì´ë¯¸ì§€ ë¡œë“œ ì‘ì—…ì„ ë™ì‹œì— ì‹œì‘
        future_to_info = {
            executor.submit(load_image_from_url_or_path, img_source, dataset_name): (img_source, dataset_name, idx)
            for idx, (img_source, dataset_name) in enumerate(image_sources_with_info)
        }
        
        # ê²°ê³¼ ìˆ˜ì§‘
        for future in concurrent.futures.as_completed(future_to_info):
            img_source, dataset_name, idx = future_to_info[future]
            try:
                result = future.result()
                results.append((idx, result))
            except Exception as e:
                results.append((idx, None))
    
    # ì›ë˜ ìˆœì„œëŒ€ë¡œ ì •ë ¬
    results.sort(key=lambda x: x[0])
    return [result for _, result in results]

def convert_to_target_format(
    sample: Dict[str, Any], 
    dataset_name: str
) -> Optional[Dict[str, Any]]:
    """
    ê° ë°ì´í„°ì…‹ì˜ ìƒ˜í”Œì„ ëª©í‘œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    - messages: List[{ role: string, content: List[{type: "text"|"image", text: string}] }]
    - images: [PIL.Image] (ë©€í‹°ëª¨ë‹¬ì—ì„œë§Œ)
    """

    result: Dict[str, Any] = {
        "messages": [],
        "images": [],
        "source_dataset": dataset_name,
        "original_data": sample.copy()
    }
    
    # ë°ì´í„°ì…‹ì— ì ì ˆí•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
    system_prompt = get_system_prompt_for_dataset(dataset_name)

    try:
        # í…ìŠ¤íŠ¸ ì „ìš© ë°ì´í„°ì…‹ë“¤ ì²˜ë¦¬
        if dataset_name == "HuggingFaceTB/smoltalk":
            if "messages" in sample and isinstance(sample["messages"], list):
                for msg in sample["messages"]:
                    if isinstance(msg, dict) and "role" in msg and "content" in msg:
                        result["messages"].append({
                            "role": msg["role"],
                            "content": [{"type": "text", "text": str(msg["content"])}]
                        })

        elif dataset_name == "R0k1e/UltraLink":
            if "data" in sample and isinstance(sample["data"], list) and len(sample["data"]) >= 2:
                data = sample["data"]
                for i in range(0, len(data), 2):
                    if i + 1 < len(data):
                        result["messages"].extend([
                            {"role": "user", "content": [{"type": "text", "text": str(data[i])}]},
                            {"role": "assistant", "content": [{"type": "text", "text": str(data[i + 1])}]}
                        ])

        elif dataset_name == "PrincetonPLI/Instruct-SkillMix-SDD":
            if "instruction" in sample and "output" in sample:
                user_content_str = str(sample["instruction"])
                if "input" in sample and sample["input"] and str(sample["input"]).strip():
                    user_content_str += f"\n\nInput: {sample['input']}"

                result["messages"] = [
                    {"role": "user", "content": [{"type": "text", "text": user_content_str}]},
                    {"role": "assistant", "content": [{"type": "text", "text": str(sample["output"]) }]}
                ]

        elif dataset_name == "allenai/WildChat-1M":
            if "conversation" in sample and isinstance(sample["conversation"], list):
                for conv in sample["conversation"]:
                    if isinstance(conv, dict) and "role" in conv and "content" in conv:
                        result["messages"].append({
                            "role": conv["role"],
                            "content": [{"type": "text", "text": str(conv["content"]) }]
                        })

        elif dataset_name == "nvidia/OpenCodeInstruct":
            if "input" in sample and "output" in sample:
                result["messages"] = [
                    {"role": "user", "content": [{"type": "text", "text": str(sample["input"]) }]},
                    {"role": "assistant", "content": [{"type": "text", "text": str(sample["output"]) }]}
                ]

        elif dataset_name == "microsoft/orca-agentinstruct-1M-v1":
            if "messages" in sample and isinstance(sample["messages"], list):
                for msg in sample["messages"]:
                    if isinstance(msg, dict) and "role" in msg and "content" in msg:
                        result["messages"].append({
                            "role": msg["role"],
                            "content": [{"type": "text", "text": str(msg["content"]) }]
                        })

        elif "Nemotron" in dataset_name:
            if "conversations" in sample and isinstance(sample["conversations"], list):
                for conv in sample["conversations"]:
                    if isinstance(conv, dict) and "from" in conv and "value" in conv:
                        role = "user" if conv["from"] in ["human", "user"] else "assistant"
                        result["messages"].append({
                            "role": role,
                            "content": [{"type": "text", "text": str(conv["value"]) }]
                        })

        elif dataset_name == "NousResearch/Hermes-3-Dataset":
            # Hermes-3ëŠ” conversations ë°°ì—´ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            convs = sample.get("conversations") or sample.get("messages")
            if isinstance(convs, list):
                for conv in convs:
                    if not isinstance(conv, dict):
                        continue
                    frm = conv.get("from") or conv.get("role")
                    val = str(conv.get("value") or conv.get("content") or "")
                    if not frm:
                        continue
                    role = "user" if frm in ["human", "user"] else ("assistant" if frm in ["gpt", "assistant"] else frm)
                    result["messages"].append({
                        "role": role,
                        "content": [{"type": "text", "text": val }]
                    })

        elif dataset_name == "nvidia/Llama-Nemotron-VLM-Dataset-v1":
            # VLM v1: ë‹¤ì–‘í•œ ì„œë¸ŒìŠ¤í”Œë¦¿, captioning ë¥˜ëŠ” ì´ë¯¸ì§€ + ìº¡ì…˜ êµ¬ì¡°
            # ì˜ˆì‹œ í•„ë“œ: image_url/image_path, caption/response ë“±ì„ ê°€ì •í•˜ê³  ë§¤í•‘
            image_obj = None
            for k in ["image", "image_path", "image_url", "url"]:
                if k in sample and sample[k]:
                    image_obj = load_image_from_url_or_path(sample[k])
                    if image_obj is not None:
                        result["images"].append(image_obj)
                        break
            caption = str(sample.get("caption") or sample.get("response") or sample.get("value") or "").strip()
            if caption:
                user_content: List[Dict[str, Any]] = [{"type": "text", "text": "Describe this image.", "image": ""}]
                if result["images"]:
                    user_content.append({"type": "image", "text": "", "image": ""})
                result["messages"] = [
                    {"role": "user", "content": user_content},
                    {"role": "assistant", "content": [{"type": "text", "text": caption, "image": ""}]}
                ]

        elif dataset_name == "open-r1/Mixture-of-Thoughts":
            if "messages" in sample and isinstance(sample["messages"], list):
                for msg in sample["messages"]:
                    if isinstance(msg, dict) and "role" in msg and "content" in msg:
                        result["messages"].append({
                            "role": msg["role"],
                            "content": [{"type": "text", "text": str(msg["content"]) }]
                        })

        # ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì…‹ë“¤ ì²˜ë¦¬
        elif dataset_name in ["Lin-Chen/ShareGPT4V", "liuhaotian/LLaVA-Instruct-150K"]:
            # ì´ë¯¸ì§€ ì¶”ì¶œ ë° ë¡œë“œ
            image_obj = None
            if "image" in sample and sample["image"] is not None:
                image_obj = load_image_from_url_or_path(sample["image"], dataset_name)
            elif "images" in sample and sample["images"] is not None:
                if isinstance(sample["images"], list) and len(sample["images"]) > 0:
                    image_obj = load_image_from_url_or_path(sample["images"][0], dataset_name)
                else:
                    image_obj = load_image_from_url_or_path(sample["images"], dataset_name)

            if image_obj is not None:
                result["images"].append(image_obj)

            # conversations ì²˜ë¦¬ (content: List[{type,text}] + ì´ë¯¸ì§€ í† í°ì€ ë³„ë„ itemë¡œ í‘œí˜„)
            if "conversations" in sample and isinstance(sample["conversations"], list):
                for i, conv in enumerate(sample["conversations"]):
                    if not isinstance(conv, dict):
                        continue

                    # role ê²°ì •
                    role = "assistant"
                    if "from" in conv:
                        if conv["from"] in ["human", "user"]:
                            role = "user"
                        elif conv["from"] in ["gpt", "assistant"]:
                            role = "assistant"
                    content_list: List[Dict[str, Any]] = []
                    text_content = str(conv.get("value", "")).strip()
                    if text_content:
                        # ì› ë°ì´í„°ì— <image> í† í°ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´, ë¶„ë¦¬í•˜ì—¬ image itemìœ¼ë¡œ ë³´ì¡´
                        if "<image>" in text_content:
                            # ê° í† í° ì•ë’¤ í…ìŠ¤íŠ¸ë„ ë³´ì¡´
                            segments = [seg for seg in text_content.split("<image>")]
                            for sidx, seg in enumerate(segments):
                                seg = seg.strip()
                                if seg:
                                    content_list.append({"type": "text", "text": seg})
                                if sidx != len(segments) - 1:
                                    content_list.append({"type": "image", "text": None})
                        else:
                            content_list.append({"type": "text", "text": text_content})
                    # ì²« turnì— ì´ë¯¸ì§€ê°€ ì¡´ì¬í•˜ì§€ë§Œ í…ìŠ¤íŠ¸ì— <image> í† í°ì´ ì „í˜€ ì—†ëŠ” ê²½ìš°, image itemì„ ì¶”ê°€
                    if role == "user" and i == 0 and result["images"] and not any(it.get('type') == 'image' for it in content_list):
                        content_list.append({"type": "image", "text": None})

                    if content_list:
                        result["messages"].append({
                            "role": role,
                            "content": content_list
                        })

        elif dataset_name == "Salesforce/blip3-kale":
            # ì´ë¯¸ì§€ ë¡œë“œ
            image_obj = None
            if "url" in sample:
                image_obj = load_image_from_url_or_path(sample["url"], dataset_name)
            elif "image" in sample:
                image_obj = load_image_from_url_or_path(sample["image"], dataset_name)

            if image_obj is not None:
                result["images"].append(image_obj)

            # captionì„ ëŒ€í™” í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (content ë¦¬ìŠ¤íŠ¸ êµ¬ì¡°)
            caption = str(sample.get("caption", "")).strip()
            if not caption:
                caption = str(sample.get("cogvlm_caption", "")).strip()

            if caption:
                user_content: List[Dict[str, Any]] = [{"type": "text", "text": "Describe this image.", "image": ""}]
                if result["images"]:
                    # content.imageì— ìƒëŒ€ ê²½ë¡œë¥¼ ë„£ì„ ìˆ˜ ìˆìœ¼ë‚˜, ì´ ì‹œì ì—ì„œëŠ” ì´ë¯¸ì§€ íŒŒì¼ëª…ì´ ì•„ì§ ì—†ìœ¼ë¯€ë¡œ ë¹ˆ ë¬¸ìì—´ ìœ ì§€
                    user_content.append({"type": "image", "text": "", "image": ""})

                result["messages"] = [
                    {"role": "user", "content": user_content},
                    {"role": "assistant", "content": [{"type": "text", "text": caption, "image": ""}]}
                ]

        # ë¹ˆ messagesì¸ ê²½ìš° None ë°˜í™˜
        if not result["messages"]:
            return None
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ë©”ì‹œì§€ ë§¨ ì•ì— ì¶”ê°€
        result["messages"] = add_system_prompt_to_messages(result["messages"], system_prompt, dataset_name)
            
        return result

    except Exception as e:
        # ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ None ë°˜í™˜í•˜ì—¬ ê±´ë„ˆë›°ê¸°
        print(f"ìƒ˜í”Œ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ (ê±´ë„ˆë›°ê¸°): {dataset_name} - {str(e)}")
        return None

def process_samples_batch(
    samples_batch, 
    dataset_name, 
    max_workers=8
):
    """ìƒ˜í”Œ ë°°ì¹˜ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬"""
    # ì´ë¯¸ì§€ê°€ ìˆëŠ” ìƒ˜í”Œë“¤ì„ ë¨¼ì € ì‹ë³„
    image_samples = []
    non_image_samples = []
    
    for i, sample in enumerate(samples_batch):
        has_image = False
        
        # ì´ë¯¸ì§€ê°€ ìˆëŠ” ë°ì´í„°ì…‹ì¸ì§€ í™•ì¸
        if dataset_name in ["Lin-Chen/ShareGPT4V", "liuhaotian/LLaVA-Instruct-150K", "Salesforce/blip3-kale"]:
            if ("image" in sample and sample["image"]) or ("images" in sample and sample["images"]) or ("url" in sample and sample["url"]):
                has_image = True
        
        if has_image:
            image_samples.append((i, sample))
        else:
            non_image_samples.append((i, sample))
    
    # ì´ë¯¸ì§€ê°€ ì—†ëŠ” ìƒ˜í”Œë“¤ì„ ë¨¼ì € ë¹ ë¥´ê²Œ ì²˜ë¦¬
    results: List[Optional[Dict[str, Any]]] = [None] * len(samples_batch)
    
    for i, sample in non_image_samples:
        converted = convert_to_target_format(sample, dataset_name)
        results[i] = converted
    
    # ì´ë¯¸ì§€ê°€ ìˆëŠ” ìƒ˜í”Œë“¤ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬
    if image_samples:
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_idx = {
                executor.submit(convert_to_target_format, sample, dataset_name): i
                for i, sample in image_samples
            }
            
            for future in concurrent.futures.as_completed(future_to_idx):
                idx = future_to_idx[future]
                try:
                    result = future.result()
                    results[idx] = result
                except Exception as e:
                    results[idx] = None
    
    return [r for r in results if r is not None]

def process_dataset(
    dataset_name: str,
    config_name: Optional[str] = None,
    max_samples: Optional[int] = None,
    num_workers: int = 8
):
    """ë°ì´í„°ì…‹ì„ ì²˜ë¦¬í•˜ì—¬ ëª©í‘œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. (ë³‘ë ¬ ì²˜ë¦¬ ì¶”ê°€)"""
    try:
        # íŠ¹ì • ë°ì´í„°ì…‹ë“¤ì˜ split ì„¤ì •
        if dataset_name == "microsoft/orca-agentinstruct-1M-v1":
            split_candidates = ["creative_content", "train"]
        elif dataset_name == "MaziyarPanahi/Llama-Nemotron-Post-Training-Dataset-v1-ShareGPT":
            split_candidates = ["chat", "train"]
        elif dataset_name == "nvidia/Llama-Nemotron-Post-Training-Dataset":
            split_candidates = ["chat", "train"]
        elif dataset_name == "nvidia/Llama-Nemotron-VLM-Dataset-v1":
            # ë‹¤ì–‘í•œ ì„œë¸ŒìŠ¤í”Œë¦¿ ì¡´ì¬: captioning_x, ocr_x, vqa_x ë“±
            # ì´ ë°ì´í„°ì…‹ì€ split ì •ë³´ ë¶ˆì¼ì¹˜ ë¬¸ì œê°€ ìˆì–´ì„œ íŠ¹ë³„ ì²˜ë¦¬
            split_candidates = ["train"]
        else:
            split_candidates = ["train"]
        
        # ë°ì´í„°ì…‹ ë¡œë“œ (ì—¬ëŸ¬ í›„ë³´ split ìˆœíšŒ)
        full_dataset = None
        last_err = None
        
        # íŠ¹ì • ë°ì´í„°ì…‹ë“¤ì€ streaming=Falseë¡œ ì²˜ë¦¬ (split ì •ë³´ ë¶ˆì¼ì¹˜ ë¬¸ì œ í•´ê²°)
        use_streaming = True
        special_handling = False
        
        if dataset_name == "nvidia/Llama-Nemotron-VLM-Dataset-v1":
            use_streaming = False
            special_handling = True
            print(f"â„¹ï¸ {dataset_name}: split ì •ë³´ ë¶ˆì¼ì¹˜ ë¬¸ì œë¡œ ì¸í•´ íŠ¹ë³„ ì²˜ë¦¬ ëª¨ë“œ í™œì„±í™”")
        
        for split in split_candidates:
            try:
                if config_name:
                    full_dataset = load_dataset(dataset_name, config_name, split=split, streaming=use_streaming)
                else:
                    full_dataset = load_dataset(dataset_name, split=split, streaming=use_streaming)
                break
            except Exception as e:
                last_err = e
                print(f"âš ï¸ split '{split}' ë¡œë“œ ì‹¤íŒ¨: {e}")
                continue
                
        if full_dataset is None:
            # Nemotron VLM ì²˜ëŸ¼ ë‹¤ì–‘í•œ splitì´ ìˆì„ ê²½ìš° ì „ì²´ splitì„ ë¶ˆëŸ¬ì™€ ìˆœíšŒ
            try:
                ds_all = load_dataset(dataset_name, config_name) if config_name else load_dataset(dataset_name)
                # ê°€ëŠ¥í•œ ì²« split ì„ íƒ
                for split_name in ds_all.keys():
                    try:
                        full_dataset = load_dataset(dataset_name, config_name, split=split_name, streaming=use_streaming) if config_name else load_dataset(dataset_name, split=split_name, streaming=use_streaming)
                        print(f"âœ… split '{split_name}'ë¡œ ì§„í–‰")
                        break
                    except Exception as e:
                        print(f"âš ï¸ split '{split_name}' ë¡œë“œ ì‹¤íŒ¨: {e}")
                        continue
            except Exception as e2:
                print(f"âŒ ë°ì´í„°ì…‹ split íƒìƒ‰ ì‹¤íŒ¨: {e2}")
                # split ì •ë³´ ë¶ˆì¼ì¹˜ ë¬¸ì œê°€ ìˆëŠ” ê²½ìš° ì „ì²´ ë°ì´í„°ì…‹ì„ í•œ ë²ˆì— ë¡œë“œ ì‹œë„
                if "split" in str(e2).lower() or "expected" in str(e2).lower():
                    print(f"ğŸ”„ split ì •ë³´ ë¶ˆì¼ì¹˜ ë¬¸ì œ ê°ì§€. ì „ì²´ ë°ì´í„°ì…‹ì„ í•œ ë²ˆì— ë¡œë“œ ì‹œë„...")
                    
                            # íŠ¹ë³„ ì²˜ë¦¬ ëª¨ë“œì¸ ê²½ìš° huggingface_hubì—ì„œ split ì •ë³´ë¥¼ ë¨¼ì € í™•ì¸
        if special_handling:
            print(f"ğŸ”„ íŠ¹ë³„ ì²˜ë¦¬ ëª¨ë“œ: huggingface_hubì—ì„œ split ì •ë³´ í™•ì¸ ì¤‘...")
            try:
                api = HfApi()
                # ë°ì´í„°ì…‹ì˜ split ì •ë³´ë¥¼ ë¨¼ì € í™•ì¸
                dataset_info = api.dataset_info(dataset_name)
                available_splits = list(dataset_info.splits.keys())
                print(f"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ split: {available_splits}")
                
                # ì‚¬ìš© ê°€ëŠ¥í•œ split ì¤‘ì—ì„œ ì²« ë²ˆì§¸ë¥¼ ì„ íƒí•˜ì—¬ ë¡œë“œ
                if available_splits:
                    selected_split = available_splits[0]
                    print(f"ğŸ”„ ì„ íƒëœ split: {selected_split}")
                    
                    try:
                        if config_name:
                            full_dataset = load_dataset(dataset_name, config_name, split=selected_split, streaming=use_streaming)
                        else:
                            full_dataset = load_dataset(dataset_name, split=selected_split, streaming=use_streaming)
                        print(f"âœ… {selected_split} split ë¡œë“œ ì„±ê³µ!")
                    except Exception as split_e:
                        print(f"âš ï¸ {selected_split} split ë¡œë“œ ì‹¤íŒ¨: {split_e}")
                        # ë‹¤ë¥¸ splitë“¤ë„ ì‹œë„
                        for split_name in available_splits[1:]:
                            try:
                                print(f"ğŸ”„ {split_name} split ì‹œë„ ì¤‘...")
                                if config_name:
                                    full_dataset = load_dataset(dataset_name, config_name, split=split_name, streaming=use_streaming)
                                else:
                                    full_dataset = load_dataset(dataset_name, split=split_name, streaming=use_streaming)
                                print(f"âœ… {split_name} split ë¡œë“œ ì„±ê³µ!")
                                break
                            except Exception as other_split_e:
                                print(f"âš ï¸ {split_name} split ì‹¤íŒ¨: {other_split_e}")
                                continue
                        else:
                            print(f"âŒ ëª¨ë“  split ë¡œë“œ ì‹¤íŒ¨")
                            return
                else:
                    print(f"âŒ ì‚¬ìš© ê°€ëŠ¥í•œ splitì´ ì—†ìŠµë‹ˆë‹¤")
                    return
                    
            except Exception as e3:
                print(f"âš ï¸ huggingface_hubì—ì„œ split ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e3}")
                # fallback: ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì‹œë„
                try:
                    if config_name:
                        full_dataset = load_dataset(dataset_name, config_name, trust_remote_code=True, streaming=use_streaming)
                    else:
                        full_dataset = load_dataset(dataset_name, trust_remote_code=True, streaming=use_streaming)
                    print(f"âœ… trust_remote_code=Trueë¡œ ë°ì´í„°ì…‹ ë¡œë“œ ì„±ê³µ")
                except Exception as e4:
                    print(f"âŒ fallback ë°©ì‹ë„ ì‹¤íŒ¨: {e4}")
                    return
            else:
                # ì¼ë°˜ì ì¸ fallback ì‹œë„
                try:
                    if config_name:
                        full_dataset = load_dataset(dataset_name, config_name, streaming=use_streaming)
                    else:
                        full_dataset = load_dataset(dataset_name, streaming=use_streaming)
                    print(f"âœ… ì „ì²´ ë°ì´í„°ì…‹ ë¡œë“œ ì„±ê³µ")
                except Exception as e3:
                    print(f"âŒ ì „ì²´ ë°ì´í„°ì…‹ ë¡œë“œë„ ì‹¤íŒ¨: {e3}")
                    return
                    
        if full_dataset is None:
            print(f"âŒ ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨(ëª¨ë“  split): {last_err}")
            return

        success_count = 0
        total_count = 0
        batch_size = max(8, num_workers)  # ë°°ì¹˜ í¬ê¸°ë¥¼ ì›Œì»¤ ìˆ˜ì— ë§ì¶¤
        current_batch = []
        
        # ì§„í–‰ ìƒí™© í‘œì‹œë¥¼ ìœ„í•œ tqdm ì„¤ì •
        desc = f"{dataset_name.split('/')[-1]}"
        if config_name:
            desc += f"({config_name})"
        
        # leave=Falseë¥¼ ì¶”ê°€í•˜ì—¬ ì™„ë£Œ í›„ ì§„í–‰ ë§‰ëŒ€ê°€ ì‚¬ë¼ì§€ë„ë¡ í•¨
        progress_bar = tqdm(desc=desc, unit="samples", leave=False)
        
        # ë°ì´í„° ì²˜ë¦¬ (streaming ì—¬ë¶€ì— ë”°ë¼ ë‹¤ë¥´ê²Œ ì²˜ë¦¬)
        if use_streaming:
            # ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° ì²˜ë¦¬
            for sample in full_dataset:
                if max_samples and total_count >= max_samples:
                    break
                
                current_batch.append(sample)
                total_count += 1
                
                # ë°°ì¹˜ê°€ ì°¼ê±°ë‚˜ ë§ˆì§€ë§‰ ìƒ˜í”Œì¸ ê²½ìš° ì²˜ë¦¬
                if len(current_batch) >= batch_size or (max_samples and total_count >= max_samples):
                    # ë°°ì¹˜ ì²˜ë¦¬
                    batch_results = process_samples_batch(current_batch, dataset_name, num_workers)
                    
                    if batch_results:
                        success_count += len(batch_results)
                        yield batch_results
                    
                    progress_bar.update(len(current_batch))
                    progress_bar.set_postfix({
                        "processed": f"{success_count}/{total_count}",
                        "success_rate": f"{success_count/total_count*100:.1f}%"
                    })
                    
                    current_batch = []
            
            # ë‚¨ì€ ë°°ì¹˜ ì²˜ë¦¬
            if current_batch:
                batch_results = process_samples_batch(current_batch, dataset_name, num_workers)
                if batch_results:
                    success_count += len(batch_results)
                    yield batch_results
                progress_bar.update(len(current_batch))
        else:
            # ì¼ë°˜ Dataset ê°ì²´ ì²˜ë¦¬ (ì „ì²´ ë°ì´í„°ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬)
            total_samples_in_dataset = len(full_dataset)
            if max_samples:
                total_samples_in_dataset = min(total_samples_in_dataset, max_samples)
            
            print(f"ğŸ“Š ì „ì²´ {total_samples_in_dataset}ê°œ ìƒ˜í”Œì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬ ì¤‘...")
            
            # ì „ì²´ ë°ì´í„°ë¥¼ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
            for i in range(0, total_samples_in_dataset, batch_size):
                end_idx = min(i + batch_size, total_samples_in_dataset)
                batch_samples = list(full_dataset.select(range(i, end_idx)))
                
                # ë°°ì¹˜ ì²˜ë¦¬
                batch_results = process_samples_batch(batch_samples, dataset_name, num_workers)
                
                if batch_results:
                    success_count += len(batch_results)
                    yield batch_results
                
                total_count = end_idx
                progress_bar.update(len(batch_samples))
                progress_bar.set_postfix({
                    "processed": f"{success_count}/{total_count}",
                    "success_rate": f"{success_count/total_count*100:.1f}%"
                })
        
        progress_bar.close()
        
        # ì™„ë£Œ ë©”ì‹œì§€ë¥¼ ë°˜í™˜ê°’ìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ë‚˜ì¤‘ì— í•œ ë²ˆì— ì¶œë ¥í•˜ë„ë¡ í•¨
        yield f"âœ… {dataset_name}: {success_count}/{total_count} ìƒ˜í”Œ ë³€í™˜ ì™„ë£Œ (ì„±ê³µë¥ : {success_count/total_count*100:.1f}%)" if total_count > 0 else f"â„¹ï¸ {dataset_name}: ì²˜ë¦¬í•  ìƒ˜í”Œ ì—†ìŒ"

    except Exception as e:
        yield f"âŒ {dataset_name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"

def generate_cleaned_records(file_path: str):
    """
    Reads a JSONL file line-by-line, cleans the data, and yields records.
    This generator approach is highly memory-efficient.
    """
    with open(file_path, 'r', encoding='utf-8') as f:
        # tqdm will show processing speed (it/s) without a total count,
        # which avoids reading the file twice.
        for line in tqdm(f, desc="Streaming and cleaning records"):
            try:
                record = json.loads(line)
                
                # Clean the 'messages' field in-place for efficiency
                # messages -> conversationsë¡œ ì´í–‰. ê¸°ì¡´ messagesëŠ” ë¬´ì‹œí•˜ê³  conversationsë§Œ ìœ ì§€
                if 'messages' in record and isinstance(record['messages'], list):
                    conversations = []
                    for m in record['messages']:
                        role = m.get('role', '')
                        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” conversationsì—ì„œ ì œì™¸ (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ëŠ” ë³„ë„ë¡œ ì²˜ë¦¬)
                        if role == 'system':
                            continue
                        frm = 'human' if role == 'user' else ('gpt' if role == 'assistant' else role)
                        parts: List[str] = []
                        for it in m.get('content', []) or []:
                            if not isinstance(it, dict):
                                continue
                            if it.get('type') == 'text':
                                txt = str(it.get('text') or '')
                                if txt:
                                    parts.append(txt)
                            elif it.get('type') == 'image':
                                img_ref = it.get('image') or ''
                                parts.append(f"<image:{img_ref}>" if img_ref else "<image>")
                        conversations.append({'from': frm, 'value': '\n'.join(parts)})
                    record['conversations'] = conversations
                    del record['messages']

                yield record

            except (json.JSONDecodeError, TypeError):
                print(f"Skipping malformed line: {line.strip()}")

def merge_and_create_dataset(
    output_name: str = "unified-multimodal-sft", 
    max_samples_per_dataset: Optional[int] = None, 
    num_workers: int = 8,  # ë” ì ì€ ì›Œì»¤ ìˆ˜ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½
    local_path: str = "./",
):
    """
    ëª¨ë“  ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì…‹ì„ ë³‘í•©í•˜ê³  ëª©í‘œ í˜•ì‹ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
    ë©”ëª¨ë¦¬ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì¤‘ê°„ ê²°ê³¼ë¥¼ ë””ìŠ¤í¬ì— ì €ì¥í•˜ëŠ” ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    print(f"ğŸš€ ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì…‹ ë³‘í•© ì‹œì‘... (ì›Œì»¤ ìˆ˜: {num_workers})")
    
    # 1. ì„ì‹œ ì €ì¥ ê³µê°„ ì„¤ì •
    staging_dir = f"{local_path}/{output_name}_staging".replace("//", "/")
    images_dir = os.path.join(staging_dir, "images")
    os.makedirs(images_dir, exist_ok=True)
    jsonl_path = os.path.join(staging_dir, "data.jsonl")
    
    tqdm.write(f"ğŸ“‚ ì„ì‹œ ì €ì¥ ê²½ë¡œ: {staging_dir}")

    # JSON ì§ë ¬í™”ë¥¼ ìœ„í•œ datetime í•¸ë“¤ëŸ¬
    def datetime_handler(x):
        if isinstance(x, datetime.datetime):
            return x.isoformat()
        raise TypeError(f"Object of type {type(x).__name__} is not JSON serializable")

    total_samples = 0
    image_counter = 0
    completion_messages = []

    # 2. ë°ì´í„°ë¥¼ JSONLê³¼ ì´ë¯¸ì§€ íŒŒì¼ë¡œ ë””ìŠ¤í¬ì— ì €ì¥ (ì´ë¯¸ì§€ ê²½ë¡œ ë³´ì¡´)
    with open(jsonl_path, "w", encoding="utf-8") as f:
        dataset_progress = tqdm(dataset_configs, desc="ë°ì´í„°ì…‹ ì²˜ë¦¬", unit="dataset")

        for dataset_name, config_name in dataset_progress:
            dataset_progress.set_description(f"ì²˜ë¦¬ì¤‘: {dataset_name.split('/')[-1]}")
            try:
                for result in process_dataset(dataset_name, config_name, max_samples_per_dataset, num_workers):
                    if isinstance(result, list): # ë°°ì¹˜ ê²°ê³¼
                        for sample in result:
                            # ì´ë¯¸ì§€ ì²˜ë¦¬: PIL ê°ì²´ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ë˜ ìƒëŒ€ê²½ë¡œë§Œ ì €ì¥
                            image_paths = []
                            if sample.get("images"):
                                for img in sample["images"]:
                                    if hasattr(img, 'save'):
                                        image_filename = f"{image_counter:08d}.png"
                                        # ì´ë¯¸ì§€ íŒŒì¼ ì €ì¥
                                        img_save_path = os.path.join(images_dir, image_filename)
                                        img.save(img_save_path, "PNG")
                                        # ìƒëŒ€ ê²½ë¡œë§Œ ì €ì¥ (staging_dir ê¸°ì¤€)
                                        image_paths.append(os.path.join("images", image_filename))
                                        image_counter += 1
                            
                            sample["images"] = image_paths

                            # messages.content ë‚´ image ì•„ì´í…œì— ê²½ë¡œ ë§¤í•‘ (ìˆœì„œëŒ€ë¡œ í• ë‹¹)
                            try:
                                if sample.get("messages"):
                                    img_idx = 0
                                    for m in sample["messages"]:
                                        content_list = m.get("content")
                                        if isinstance(content_list, list):
                                            for item in content_list:
                                                if isinstance(item, dict) and item.get("type") == "image":
                                                    if img_idx < len(image_paths):
                                                        item["image"] = image_paths[img_idx]
                                                        img_idx += 1
                                                    else:
                                                        # ë‚¨ëŠ” ê²½ë¡œê°€ ì—†ìœ¼ë©´ None ìœ ì§€
                                                        item.setdefault("image", None)
                            except Exception:
                                pass

                            # Hermes ìŠ¤íƒ€ì¼ 'conversations' í•„ë“œ ë™ì‹œ ìƒì„± (viewer í˜¸í™˜)
                            try:
                                conversations = []
                                for m in sample.get("messages", []):
                                    role = m.get("role", "")
                                    frm = "human" if role == "user" else ("gpt" if role == "assistant" else role)
                                    parts: List[str] = []
                                    for it in m.get("content", []) or []:
                                        if not isinstance(it, dict):
                                            continue
                                        if it.get("type") == "text":
                                            txt = str(it.get("text") or "")
                                            if txt:
                                                parts.append(txt)
                                        elif it.get("type") == "image":
                                            img_ref = it.get("image") or ""
                                            if img_ref:
                                                parts.append(f"<image:{img_ref}>")
                                            else:
                                                parts.append("<image>")
                                    conversations.append({"from": frm, "value": "\n".join(parts)})
                                sample["conversations"] = conversations
                            except Exception:
                                pass
                            
                            # original_dataë¥¼ ì•ˆì „í•˜ê²Œ JSON ë¬¸ìì—´ë¡œ ë³€í™˜
                            try:
                                sample["original_data"] = json.dumps(sample["original_data"], ensure_ascii=False, default=str)
                            except (TypeError, OverflowError):
                                sample["original_data"] = "{}" # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ë¹ˆ ê°ì²´ë¡œ

                            f.write(json.dumps(
                                sample, 
                                ensure_ascii=False, 
                                default=datetime_handler
                            ) + "\n")
                            total_samples += 1
                        
                        dataset_progress.set_postfix({"ì´ ìƒ˜í”Œ": total_samples})

                    elif isinstance(result, str): # ì™„ë£Œ ë©”ì‹œì§€
                        completion_messages.append(result)
            except Exception as e:
                tqdm.write(f"âŒ {dataset_name} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
                continue

            # ë°ì´í„°ì…‹ ì²˜ë¦¬ í›„ ë©”ëª¨ë¦¬ ìµœì í™”
            with cache_lock:
                image_cache.clear()
            gc.collect()
            tqdm.write(f"ğŸ§  {dataset_name.split('/')[-1]} ì²˜ë¦¬ í›„ ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ.")

    dataset_progress.close()

    tqdm.write("\n" + "="*20 + " ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½ " + "="*20)
    for msg in completion_messages:
        tqdm.write(msg)
    tqdm.write("="*55)

    if total_samples == 0:
        print("âŒ ë³€í™˜ëœ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    tqdm.write(f"\nğŸ¯ ì´ {total_samples}ê°œ ìƒ˜í”Œ ë³€í™˜ ì™„ë£Œ ë° ì„ì‹œ ì €ì¥ ì™„ë£Œ")
    
    # 3. ë””ìŠ¤í¬ì— ì €ì¥ëœ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ íš¨ìœ¨ì ìœ¼ë¡œ ë¡œë“œ
    tqdm.write("ğŸ“¦ ì„ì‹œ íŒŒì¼ë¡œë¶€í„° Dataset ê°ì²´ ìƒì„± ì¤‘...")

    # ë°ì´í„°ì…‹ì˜ ìµœì¢… ìŠ¤í‚¤ë§ˆ(êµ¬ì¡°) ì •ì˜
    features = Features({
        'conversations': Sequence(
            Features({
                'from': Value('string'),
                'value': Value('string')
            })
        ),
        'images': Sequence(Value('string')), # ë¨¼ì € ë¬¸ìì—´ ê²½ë¡œë¡œ ë¡œë“œ
        'source_dataset': Value('string'),
        'original_data': Value('string')
    })
    
    # ë¡œì»¬ ì €ì¥
    tqdm.write("ğŸ’¾ ë¡œì»¬ ì €ì¥ ì¤‘ (ìµœì¢… Arrow í¬ë§·)...")
    final_save_path = f"{local_path}/{output_name}".replace("//", "/")

    # 1. ì œë„ˆë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ë°ì´í„° ë¡œë“œ ë° ì •ì œ
    tqdm.write("   - ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ë°ì´í„° ë¡œë“œ ë° ì •ì œ ì¤‘...")
    iterable_dataset = Dataset.from_generator(
        generate_cleaned_records,
        features=features,
        gen_kwargs={"file_path": jsonl_path},
    )
    # IterableDatasetì„ ì¼ë°˜ Datasetìœ¼ë¡œ ë³€í™˜í•˜ì—¬ .map()ê³¼ .filter() ì‚¬ìš©
    dataset = Dataset.from_list(list(tqdm(iterable_dataset, desc="Converting to standard dataset")))

    # 2. ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì‹¤ì œ ì´ë¯¸ì§€ ê°ì²´ë¡œ ë³€í™˜ (ìƒëŒ€ ê²½ë¡œ ê¸°ì¤€ ì„¤ì •)
    staging_dir_abs = os.path.abspath(staging_dir)
    def resolve_and_load_images(example):
        if example['images']:
            # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜í•˜ê³  ì´ë¯¸ì§€ ë¡œë“œ
            loaded_images = []
            for img_path in example['images']:
                full_path = os.path.join(staging_dir_abs, img_path)
                if os.path.exists(full_path):
                    try:
                        img = Image.open(full_path)
                        loaded_images.append(img.convert('RGB'))
                    except Exception as e:
                        print(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {full_path} - {e}")
                        loaded_images.append(None)
                else:
                    loaded_images.append(None)
            example['images'] = loaded_images
        # ë©”ì‹œì§€ ë‚´ image ê²½ë¡œëŠ” ê·¸ëŒ€ë¡œ ë‘ê³ (ë¬¸ìì—´), ì´í›„ ìºìŠ¤íŒ…ìœ¼ë¡œ ì²˜ë¦¬í•˜ê±°ë‚˜ ì—…ë¡œë“œì—ì„œ ImageFeatureë¡œ ì²˜ë¦¬
        return example

    # ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ë³€í™˜í•˜ê³ , Noneì¸ ì´ë¯¸ì§€ë¥¼ í•„í„°ë§ (ë‹¤ì¤‘ ì²˜ë¦¬ë¡œ ê°€ì†)
    tqdm.write(f"   - ì´ë¯¸ì§€ ë¡œë“œ ì¤‘ (ì›Œì»¤: {num_workers})...")
    dataset = dataset.map(resolve_and_load_images, num_proc=num_workers)
    dataset = dataset.filter(lambda example: not (example.get('images') and None in example['images']), num_proc=num_workers)

    # ìµœì¢…ì ìœ¼ë¡œ Image Featureë¡œ ìºìŠ¤íŒ…
    tqdm.write("   - ì´ë¯¸ì§€ ë°ì´í„° íƒ€ì… ë³€í™˜ ì¤‘...")
    unified_dataset = dataset.cast_column("images", Sequence(ImageFeature()))

    # ìºì‹œ ì •ë¦¬
    with cache_lock:
        image_cache.clear()
    
    unified_dataset.save_to_disk(final_save_path)
    tqdm.write(f"   - ìµœì¢… ë°ì´í„°ì…‹ ê²½ë¡œ: {final_save_path}")
    
    return final_save_path

def upload_dataset_to_hub(
    dataset_path: str,
    repo_id: str,
    private: bool = False,
    num_workers: Optional[int] = None,
    chunk_size: Optional[int] = None,
    single_repo: bool = False,
    start_chunk_num: int = 0
):
    """
    ë¡œì»¬ì— ì €ì¥ëœ ë°ì´í„°ì…‹ì„ í—ˆê¹…í˜ì´ìŠ¤ í—ˆë¸Œì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.
    ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ ì‚¬ìš©
    
    Args:
        single_repo: Trueë©´ í•˜ë‚˜ì˜ ë¦¬í¬ì§€í† ë¦¬ì— ìˆœì°¨ì ìœ¼ë¡œ ì¶”ê°€, Falseë©´ ì²­í¬ë³„ ë¦¬í¬ì§€í† ë¦¬ ìƒì„±
    """
    if num_workers is None:
        num_workers = min(4, os.cpu_count() or 4)  # ì›Œì»¤ ìˆ˜ ì œí•œ
    
    if chunk_size is None:
        chunk_size = min(200, num_workers * 25)  # ë” ì‘ì€ ì²­í¬ í¬ê¸°
        
    jsonl_path = os.path.join(dataset_path, "data.jsonl")
    # Fallback: ìµœì¢… í´ë”ì— JSONLì´ ì—†ë‹¤ë©´ staging ê²½ë¡œë¥¼ ìë™ ê²€ìƒ‰
    if not os.path.exists(jsonl_path):
        candidate = f"{dataset_path}_staging"
        alt_jsonl = os.path.join(candidate, "data.jsonl")
        if os.path.exists(alt_jsonl):
            print(f"â„¹ï¸ data.jsonlì´ ìµœì¢… ê²½ë¡œì— ì—†ì–´ staging ê²½ë¡œë¡œ ëŒ€ì²´: {alt_jsonl}")
            jsonl_path = alt_jsonl
        else:
            print(f"âŒ JSONL íŒŒì¼ ì—†ìŒ: {jsonl_path}")
            return False

    print(f"ğŸš€ ë°ì´í„°ì…‹ ì—…ë¡œë“œ: {repo_id}")
    print(f"ğŸ“Š ì²­í¬ í¬ê¸°: {chunk_size}, ì›Œì»¤ ìˆ˜: {num_workers}")
    
    try:
        # ì´ë¯¸ì§€ë¥¼ í¬í•¨í•œ ë°ì´í„°ì…‹ ìƒì„±
        def data_generator():
            staging_dir_abs = os.path.dirname(jsonl_path)
            with open(jsonl_path, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f):
                    try:
                        record = json.loads(line.strip())
                        
                        # conversations í•„ë“œê°€ ì´ë¯¸ ì˜¬ë°”ë¥¸ í˜•íƒœë¡œ ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                        # messages í•„ë“œê°€ ìˆë‹¤ë©´ conversationsë¡œ ë³€í™˜
                        if 'messages' in record and isinstance(record['messages'], list) and 'conversations' not in record:
                            conversations = []
                            for message in record['messages']:
                                role = message.get('role', '')
                                if role == 'system':
                                    continue  # ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” ì œì™¸
                                frm = 'human' if role == 'user' else ('gpt' if role == 'assistant' else role)
                                content_value = message.get('content', [])
                                if isinstance(content_value, list):
                                    parts = []
                                    for item in content_value:
                                        if isinstance(item, dict):
                                            if item.get('type') == 'text':
                                                txt = str(item.get('text') or '')
                                                if txt:
                                                    parts.append(txt)
                                            elif item.get('type') == 'image':
                                                img_ref = item.get('image') or ''
                                                parts.append(f"<image:{img_ref}>" if img_ref else "<image>")
                                    conversations.append({'from': frm, 'value': '\n'.join(parts)})
                                elif isinstance(content_value, str):
                                    conversations.append({'from': frm, 'value': content_value})
                            record['conversations'] = conversations

                        # ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì‹¤ì œ ì´ë¯¸ì§€ë¡œ ë³€í™˜
                        if 'images' in record and isinstance(record['images'], list):
                            loaded_images = []
                            for img_path in record['images']:
                                if img_path and isinstance(img_path, str):
                                    full_path = os.path.join(staging_dir_abs, img_path)
                                    if os.path.exists(full_path):
                                        try:
                                            img = Image.open(full_path)
                                            loaded_images.append(img.convert('RGB'))
                                        except Exception as e:
                                            print(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {full_path} - {e}")
                                            continue
                            record['images'] = loaded_images
                        
                        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë° ëª¨ë“œ ì •ë³´ ì¶”ì¶œ ë° ì¶”ê°€
                        system_prompt = ""
                        dataset_mode = "instruction"  # ê¸°ë³¸ê°’
                        
                        # messages í•„ë“œì—ì„œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¶”ì¶œ
                        if 'messages' in record and isinstance(record['messages'], list):
                            for message in record['messages']:
                                if message.get('role') == 'system':
                                    content = message.get('content', [])
                                    if isinstance(content, list) and len(content) > 0:
                                        system_prompt = str(content[0].get('text', ''))
                                        break
                        
                        # ì†ŒìŠ¤ ë°ì´í„°ì…‹ì—ì„œ ëª¨ë“œ ì •ë³´ ì¶”ì¶œ
                        if 'source_dataset' in record:
                            dataset_mode = get_dataset_mode(record['source_dataset'])
                        
                        record['system_prompt'] = system_prompt
                        record['dataset_mode'] = dataset_mode
                        
                        yield record
                        
                        # ë©”ëª¨ë¦¬ ì •ë¦¬ë¥¼ ìœ„í•´ ì£¼ê¸°ì ìœ¼ë¡œ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
                        if line_num % 500 == 0:
                            gc.collect()
                            
                    except Exception as e:
                        print(f"   ë¼ì¸ {line_num} ê±´ë„ˆë›°ê¸°: {e}")
                        continue
        
        # ì´ë¯¸ì§€ë¥¼ í¬í•¨í•œ ë°ì´í„°ì…‹ ìŠ¤í‚¤ë§ˆ (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë° ëª¨ë“œ ì •ë³´ í¬í•¨)
        from datasets import Features, Value, Sequence, Image as ImageFeature
        features = Features({
            'conversations': Sequence(
                Features({
                    'from': Value('string'),
                    'value': Value('string')
                })
            ),
            'images': Sequence(ImageFeature()),
            'source_dataset': Value('string'),
            'original_data': Value('string'),
            'system_prompt': Value('string'),  # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            'dataset_mode': Value('string')   # ë°ì´í„°ì…‹ ê¸°ë³¸ ëª¨ë“œ
        })
        
        print("ğŸ“¦ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")
        # ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ë°ì´í„°ì…‹ ìƒì„± (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
        iterable_dataset = Dataset.from_generator(
            data_generator,
            features=features
        )
        
        # ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬
        print("ğŸ“¦ ì²­í¬ ë‹¨ìœ„ë¡œ ë°ì´í„°ì…‹ ë³€í™˜ ë° ì—…ë¡œë“œ ì¤‘...")
        
        CHUNK_SIZE = 10000  # 1ë§Œ ê°œì”© ì²˜ë¦¬
        chunk_datasets = []
        current_chunk = []
        chunk_num = 0
        # ì²­í¬ ì €ì¥ ë””ë ‰í† ë¦¬ ë³´ì¥ (ì´ë¯¸ì§€ í¬í•¨ ì €ì¥ ì‹œ ê²½ë¡œ í•„ìš”)
        temp_chunk_dir = "/mnt/disks/data/tmp"
        os.makedirs(temp_chunk_dir, exist_ok=True)
        
        for record in tqdm(iterable_dataset, desc="Processing records"):
            current_chunk.append(record)
            
            if len(current_chunk) >= CHUNK_SIZE:
                if chunk_num < start_chunk_num:
                    print(f"   ê±´ë„ˆë›°ê¸°: ì²­í¬ {chunk_num} (ì‹œì‘ ë²ˆí˜¸: {start_chunk_num})")
                    current_chunk = []
                    chunk_num += 1
                    continue

                # ì²­í¬ë¥¼ Datasetìœ¼ë¡œ ë³€í™˜í•˜ê³  ì„ì‹œ ì €ì¥
                chunk_dataset = Dataset.from_list(current_chunk, features=features)
                temp_chunk_path = f"{temp_chunk_dir}/chunk_{chunk_num}"
                chunk_dataset.save_to_disk(temp_chunk_path)
                chunk_datasets.append(temp_chunk_path)
                
                print(f"   ì²­í¬ {chunk_num}: {len(current_chunk)}ê°œ ì €ì¥ ì™„ë£Œ")
                current_chunk = []
                chunk_num += 1
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                del chunk_dataset
                gc.collect()
        
        # ë§ˆì§€ë§‰ ì²­í¬ ì²˜ë¦¬
        if current_chunk:
            if chunk_num >= start_chunk_num:
                chunk_dataset = Dataset.from_list(current_chunk, features=features)
                temp_chunk_path = f"{temp_chunk_dir}/chunk_{chunk_num}"
                chunk_dataset.save_to_disk(temp_chunk_path)
                chunk_datasets.append(temp_chunk_path)
                print(f"   ì²­í¬ {chunk_num}: {len(current_chunk)}ê°œ ì €ì¥ ì™„ë£Œ")
            del chunk_dataset
            gc.collect()
        
        # í•˜ë‚˜ì˜ ë¦¬í¬ì§€í† ë¦¬ì— ì²­í¬ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì´ì–´ì„œ ì¶”ê°€
        print(f"ğŸ“¤ ì´ {len(chunk_datasets)}ê°œ ì‹ ê·œ ì²­í¬ì™€ ê¸°ì¡´ ì²­í¬ë¥¼ í•˜ë‚˜ì˜ ë¦¬í¬ì§€í† ë¦¬ì— ìˆœì°¨ ì¶”ê°€...")
        
        all_chunk_paths_to_process = []
        if start_chunk_num > 0:
            print(f"ê¸°ì¡´ ì²­í¬ (0 ~ {start_chunk_num - 1})ë¥¼ ì²˜ë¦¬ ëª©ë¡ì— ì¶”ê°€ ì¤‘...")
            for i in range(start_chunk_num):
                path = os.path.join(temp_chunk_dir, f"chunk_{i}")
                if os.path.exists(path):
                    all_chunk_paths_to_process.append(path)
                else:
                    print(f"  [ê²½ê³ ] ê¸°ì¡´ ì²­í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤: {path}")

        all_chunk_paths_to_process.extend(chunk_datasets)
        print(f"âœ… ì´ {len(all_chunk_paths_to_process)}ê°œì˜ ì²­í¬ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

        accumulated_dataset = None
        successful_chunks = 0
        failed_uploads = []
        
        for i, chunk_path in enumerate(all_chunk_paths_to_process):
            chunk_dataset = Dataset.load_from_disk(chunk_path)
            
            print(f"   ì²­í¬ {i+1}/{len(all_chunk_paths_to_process)} ì²˜ë¦¬ ì¤‘... ({os.path.basename(chunk_path)})")
            
            try:
                # ì²« ë²ˆì§¸ ì²­í¬ì´ê±°ë‚˜ accumulated_datasetì´ Noneì¸ ê²½ìš°
                if accumulated_dataset is None:
                    accumulated_dataset = chunk_dataset
                    print(f"     ì²« ë²ˆì§¸ ì²­í¬ ({len(chunk_dataset)}ê°œ ìƒ˜í”Œ) ì¤€ë¹„")
                else:
                    # ê¸°ì¡´ ë°ì´í„°ì— ìƒˆ ì²­í¬ ì¶”ê°€
                    print(f"     ê¸°ì¡´ {len(accumulated_dataset)}ê°œì— {len(chunk_dataset)}ê°œ ì¶”ê°€ ì¤‘...")
                    from datasets import concatenate_datasets
                    accumulated_dataset = concatenate_datasets([accumulated_dataset, chunk_dataset])
                    print(f"     ì´ {len(accumulated_dataset)}ê°œ ìƒ˜í”Œë¡œ í™•ì¥")
                
                successful_chunks += 1
                
                # 10ê°œ ì²­í¬ë§ˆë‹¤ ë˜ëŠ” ë§ˆì§€ë§‰ ì²­í¬ì¼ ë•Œ ì—…ë¡œë“œ
                should_upload = (i + 1) % 10 == 0 or i == len(all_chunk_paths_to_process) - 1
                
                if should_upload:
                    print(f"     ğŸ“¤ ì¤‘ê°„ ì—…ë¡œë“œ ({successful_chunks}ê°œ ì²­í¬, {len(accumulated_dataset)}ê°œ ìƒ˜í”Œ)...")
                    
                    # ì¬ì‹œë„ ë¡œì§ìœ¼ë¡œ ì—…ë¡œë“œ
                    upload_success = False
                    for attempt in range(3):
                        try:
                            if attempt > 0:
                                wait_time = 30 * (2 ** attempt)
                                print(f"       ì¬ì‹œë„ {attempt+1}/3... {wait_time}ì´ˆ ëŒ€ê¸° í›„")
                                time.sleep(wait_time)
                            
                            accumulated_dataset.push_to_hub(
                                repo_id,  # í•­ìƒ ê°™ì€ ë¦¬í¬ì§€í† ë¦¬ì— ì—…ë¡œë“œ
                                private=private,
                                max_shard_size="100MB",
                                commit_message=f"Add chunks 1-{successful_chunks}: {len(accumulated_dataset)} total samples with images",
                                embed_external_files=True  # ì´ë¯¸ì§€ í¬í•¨
                            )
                            print(f"       âœ… ì—…ë¡œë“œ ì„±ê³µ! (ì´ {len(accumulated_dataset)}ê°œ ìƒ˜í”Œ)")
                            upload_success = True
                            break
                            
                        except Exception as e:
                            print(f"       ì‹œë„ {attempt+1} ì‹¤íŒ¨: {e}")
                            if "429" in str(e) or "Too Many Requests" in str(e):
                                if attempt < 2:
                                    print(f"       429 ì—ëŸ¬ - ì¶”ê°€ ëŒ€ê¸°...")
                                    time.sleep(60 * (attempt + 1))
                                continue
                    
                    if not upload_success:
                        print(f"       âŒ ì—…ë¡œë“œ ìµœì¢… ì‹¤íŒ¨")
                        failed_uploads.append((i, f"chunks_1_to_{successful_chunks}"))
                        break  # ì—…ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì¤‘ë‹¨
                
            except Exception as e:
                print(f"   âŒ ì²­í¬ {i+1} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                failed_uploads.append((i, f"chunk_{i+1}", chunk_path))
                # ì‹¤íŒ¨í•œ ì²­í¬ëŠ” ê±´ë„ˆë›°ê³  ê³„ì† ì§„í–‰
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            del chunk_dataset
            gc.collect()
            
            # ì„±ê³µí•œ ì²­í¬ ì„ì‹œ íŒŒì¼ ì •ë¦¬
            shutil.rmtree(chunk_path, ignore_errors=True)
            
            # API ì œí•œ íšŒí”¼ë¥¼ ìœ„í•œ ëŒ€ê¸°
            if i < len(all_chunk_paths_to_process) - 1:
                wait_time = 5  # 5ì´ˆ ëŒ€ê¸°
                print(f"     ë‹¤ìŒ ì²­í¬ê¹Œì§€ {wait_time}ì´ˆ ëŒ€ê¸°...")
                time.sleep(wait_time)
        
        # ìµœì¢… ê²°ê³¼ ë¦¬í¬íŠ¸
        print(f"\nğŸ‰ ì—…ë¡œë“œ ì™„ë£Œ!")
        if accumulated_dataset:
            print(f"âœ… ìµœì¢… ë°ì´í„°ì…‹: {len(accumulated_dataset):,}ê°œ ìƒ˜í”Œ")
            print(f"ğŸ“‹ ë¦¬í¬ì§€í† ë¦¬: https://huggingface.co/datasets/{repo_id}")
        
        print(f"âœ… ì²˜ë¦¬ëœ ì²­í¬: {successful_chunks}/{len(all_chunk_paths_to_process)}ê°œ")
        print(f"âŒ ì‹¤íŒ¨: {len(failed_uploads)}ê°œ")
        
        if failed_uploads:
            print(f"\nğŸ”„ ì‹¤íŒ¨í•œ í•­ëª©ë“¤:")
            for chunk_idx, description, *extra in failed_uploads:
                print(f"   - {description}")
        
        return len(failed_uploads) == 0  # ëª¨ë“  ì²­í¬ê°€ ì„±ê³µí–ˆìœ¼ë©´ True
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        print(f"âŒ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False
    finally:
        # ìµœì¢… ë©”ëª¨ë¦¬ ì •ë¦¬
        gc.collect()

def inspect_dataset(
    dataset_path: str = "./unified-multimodal-sft"
):
    """ìƒì„±ëœ ë°ì´í„°ì…‹ ê²€ì‚¬"""
    try:
        print(f"ğŸ” ë°ì´í„°ì…‹ ê²€ì‚¬: {dataset_path}")
        
        # DatasetDictì¸ì§€ Datasetì¸ì§€ í™•ì¸
        if os.path.exists(os.path.join(dataset_path, "dataset_dict.json")):
            # DatasetDict í˜•íƒœë¡œ ì €ì¥ëœ ê²½ìš°
            from datasets import DatasetDict
            dataset_dict = DatasetDict.load_from_disk(dataset_path)
            if "train" in dataset_dict:
                dataset = cast(Dataset, dataset_dict["train"])
                print(f"ğŸ“Š DatasetDictì—ì„œ train split ë¡œë“œ - ì´ ìƒ˜í”Œ ìˆ˜: {len(dataset)}")
            else:
                # ì²« ë²ˆì§¸ split ì‚¬ìš©
                split_name = list(dataset_dict.keys())[0]
                dataset = cast(Dataset, dataset_dict[split_name])
                print(f"ğŸ“Š DatasetDictì—ì„œ '{split_name}' split ë¡œë“œ - ì´ ìƒ˜í”Œ ìˆ˜: {len(dataset)}")
        else:
            # ì¼ë°˜ Dataset í˜•íƒœë¡œ ì €ì¥ëœ ê²½ìš°
            dataset = cast(Dataset, Dataset.load_from_disk(dataset_path))
            print(f"ğŸ“Š ì´ ìƒ˜í”Œ ìˆ˜: {len(dataset)}")
        
        # êµ¬ì¡° ê²€ì‚¬
        sample_with_image = None
        sample_without_image = None
        
        for sample_any in dataset:
            sample = cast(Dict[str, Any], sample_any)
            if sample.get("images") and not sample_with_image:
                sample_with_image = sample
            elif not sample.get("images") and not sample_without_image:
                sample_without_image = sample
            
            if sample_with_image and sample_without_image:
                break
        
        # ì´ë¯¸ì§€ í¬í•¨ ìƒ˜í”Œ ì˜ˆì‹œ
        if sample_with_image:
            print(f"\nğŸ–¼ï¸ ì´ë¯¸ì§€ í¬í•¨ ìƒ˜í”Œ ì˜ˆì‹œ:")
            print(f"   ì´ë¯¸ì§€ ìˆ˜: {len(sample_with_image['images'])}")
            print(f"   ë©”ì‹œì§€ ìˆ˜: {len(sample_with_image['messages'])}")
            
            # ì²« ë²ˆì§¸ ë©”ì‹œì§€ êµ¬ì¡° í™•ì¸ (ë©€í‹°ëª¨ë‹¬ ìŠ¤í‚¤ë§ˆ)
            if sample_with_image['messages']:
                first_msg = sample_with_image['messages'][0]
                print(f"   ì²« ë²ˆì§¸ ë©”ì‹œì§€ role: {first_msg.get('role')}")
                content_list = first_msg.get('content', [])
                print(f"   ì²« ë²ˆì§¸ ë©”ì‹œì§€ content ìˆ˜: {len(content_list)}")
                for j, content in enumerate(content_list[:3]):
                    ctype = content.get('type')
                    if ctype == 'text':
                        text_preview = (content.get('text') or '')
                        if len(text_preview) > 80:
                            text_preview = text_preview[:80] + '...'
                        print(f"     Content {j+1}: text - '{text_preview}'")
                    else:
                        print(f"     Content {j+1}: {ctype}")
        
        # í†µê³„
        image_count = sum(1 for s in dataset if cast(Dict[str, Any], s).get("images"))
        print(f"\nğŸ“ˆ ì´ë¯¸ì§€ í¬í•¨ ìƒ˜í”Œ: {image_count}/{len(dataset)} ({image_count/len(dataset)*100:.1f}%)")
        
        # ì›ë³¸ ë°ì´í„°ì…‹ë³„ í†µê³„
        source_stats: Dict[str, int] = {}
        for s in dataset:
            sample = cast(Dict[str, Any], s)
            source = sample.get("source_dataset", "unknown")
            source_stats[source] = source_stats.get(source, 0) + 1
        
        print(f"\nğŸ“Š ì›ë³¸ ë°ì´í„°ì…‹ë³„ ë¶„í¬:")
        for source, count in sorted(source_stats.items()):
            print(f"   {source}: {count}ê°œ ({count/len(dataset)*100:.1f}%)")
        
        # ì›ë³¸ ë°ì´í„° ë³´ì¡´ í™•ì¸
        original_data_count = sum(1 for s in dataset if cast(Dict[str, Any], s).get("original_data"))
        print(f"\nğŸ’¾ ì›ë³¸ ë°ì´í„° ë³´ì¡´: {original_data_count}/{len(dataset)} ({original_data_count/len(dataset)*100:.1f}%)")
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë° ëª¨ë“œ í†µê³„
        system_prompt_count = sum(1 for s in dataset if cast(Dict[str, Any], s).get("system_prompt"))
        print(f"\nğŸ¤– ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í¬í•¨: {system_prompt_count}/{len(dataset)} ({system_prompt_count/len(dataset)*100:.1f}%)")
        
        # ëª¨ë“œë³„ í†µê³„
        mode_stats = {}
        for s in dataset:
            sample = cast(Dict[str, Any], s)
            mode = sample.get("dataset_mode", "unknown")
            mode_stats[mode] = mode_stats.get(mode, 0) + 1
        
        print(f"\nğŸ¯ ëª¨ë“œë³„ ë¶„í¬:")
        for mode, count in sorted(mode_stats.items()):
            print(f"   {mode.upper()} ëª¨ë“œ: {count}ê°œ ({count/len(dataset)*100:.1f}%)")
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ (ì²« ë²ˆì§¸ ìƒ˜í”Œ)
        if len(dataset) > 0:
            first_sample = cast(Dict[str, Any], dataset[0])
            if first_sample.get("system_prompt"):
                print(f"\nğŸ“ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ (ì²« ë²ˆì§¸ ìƒ˜í”Œ):")
                system_prompt = first_sample["system_prompt"]
                if len(system_prompt) > 100:
                    print(f"   {system_prompt[:100]}...")
                else:
                    print(f"   {system_prompt}")
                
                # ëª¨ë“œ ì •ë³´ë„ í‘œì‹œ
                if first_sample.get("dataset_mode"):
                    print(f"   ê¸°ë³¸ ëª¨ë“œ: {first_sample['dataset_mode'].upper()}")
        
        # ì›ë³¸ ë°ì´í„° ì˜ˆì‹œ (ì²« ë²ˆì§¸ ìƒ˜í”Œ)
        if len(dataset) > 0:
            first_sample = cast(Dict[str, Any], dataset[0])
            if first_sample.get("original_data"):
                print(f"\nğŸ” ì›ë³¸ ë°ì´í„° ì˜ˆì‹œ (ì²« ë²ˆì§¸ ìƒ˜í”Œ):")
                try:
                    original_str = first_sample["original_data"]
                    original = json.loads(original_str)
                    print(f"   ì›ë³¸ ë°ì´í„° í‚¤: {list(original.keys())}")
                    for key, value in list(original.items())[:3]:  # ì²˜ìŒ 3ê°œ í‚¤ë§Œ í‘œì‹œ
                        if isinstance(value, str) and len(value) > 50:
                            print(f"   {key}: {value[:50]}...")
                        else:
                            print(f"   {key}: {value}")
                except (json.JSONDecodeError, TypeError):
                     print(f"   ì›ë³¸ ë°ì´í„° (raw): {first_sample['original_data'][:100]}...")

        return dataset
        
    except Exception as e:
        print(f"âŒ ê²€ì‚¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="í…ìŠ¤íŠ¸ + ë©€í‹°ëª¨ë‹¬ í†µí•© ë°ì´í„°ì…‹ ì²˜ë¦¬ ë° ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸")
    subparsers = parser.add_subparsers(dest="command", required=True)

    # merge ëª…ë ¹ì–´
    parser_merge = subparsers.add_parser("merge", help="ì—¬ëŸ¬ ë°ì´í„°ì…‹ì„ ë³‘í•©í•˜ì—¬ ë¡œì»¬ì— ì €ì¥í•©ë‹ˆë‹¤.")
    parser_merge.add_argument("--output_name", type=str, help="ìƒì„±í•  ë°ì´í„°ì…‹ì˜ ë¡œì»¬ í´ë” ì´ë¦„")
    parser_merge.add_argument("--max_samples", type=int, default=None, help="ë°ì´í„°ì…‹ë³„ ìµœëŒ€ ìƒ˜í”Œ ìˆ˜")
    parser_merge.add_argument("--num_workers", type=int, default=16, help="ë°ì´í„° ì²˜ë¦¬ ì›Œì»¤ ìˆ˜")
    parser_merge.add_argument("--local_path", type=str, default="./", help="ë°ì´í„°ì…‹ì„ ì €ì¥í•  ë¡œì»¬ ê²½ë¡œ")

    # upload ëª…ë ¹ì–´
    parser_upload = subparsers.add_parser("upload", help="ë¡œì»¬ì— ì €ì¥ëœ ë°ì´í„°ì…‹ì„ í—ˆê¹…í˜ì´ìŠ¤ í—ˆë¸Œì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.")
    parser_upload.add_argument("--dataset_path", type=str, help="ì—…ë¡œë“œí•  ë¡œì»¬ ë°ì´í„°ì…‹ ê²½ë¡œ")
    parser_upload.add_argument("--repo_id", type=str, help="í—ˆê¹…í˜ì´ìŠ¤ í—ˆë¸Œ ë¦¬í¬ì§€í† ë¦¬ ID (ì˜ˆ: username/repo-name)")
    parser_upload.add_argument("--private", action="store_true", help="ë¦¬í¬ì§€í† ë¦¬ë¥¼ ë¹„ê³µê°œë¡œ ì„¤ì •")
    parser_upload.add_argument("--num_workers", type=int, default=None, help="ì²˜ë¦¬ ì›Œì»¤ ìˆ˜ (ê¸°ë³¸ê°’: CPU ì½”ì–´ ìˆ˜)")
    parser_upload.add_argument("--chunk_size", type=int, default=None, help="ë©”ëª¨ë¦¬ ì²˜ë¦¬ ì²­í¬ í¬ê¸° (ê¸°ë³¸ê°’: ë™ì  ê³„ì‚°)")
    parser_upload.add_argument("--single_repo", action="store_true", help="í•˜ë‚˜ì˜ ë¦¬í¬ì§€í† ë¦¬ì— ìˆœì°¨ì ìœ¼ë¡œ ì¶”ê°€")
    parser_upload.add_argument("--start_chunk_num", type=int, default=0, help="ì—…ë¡œë“œë¥¼ ì‹œì‘í•  ì²­í¬ ë²ˆí˜¸. ì´ ë²ˆí˜¸ ì´ì „ì˜ ì²­í¬ëŠ” ìƒì„±/ì²˜ë¦¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

    # inspect ëª…ë ¹ì–´
    parser_inspect = subparsers.add_parser("inspect", help="ë¡œì»¬ ë°ì´í„°ì…‹ì˜ ì •ë³´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.")
    parser_inspect.add_argument("dataset_path", nargs="?", default="./unified-multimodal-sft", help="ê²€ì‚¬í•  ë°ì´í„°ì…‹ ê²½ë¡œ")

    args = parser.parse_args()

    if args.command == "merge":
        print(f"ğŸ¯ íƒ€ê²Ÿ ë¡œì»¬ ê²½ë¡œ: {os.path.join(args.local_path, args.output_name)}")
        print(f"ğŸ”§ ì›Œì»¤ ìˆ˜: {args.num_workers}")
        final_path = merge_and_create_dataset(
            output_name=args.output_name,
            max_samples_per_dataset=args.max_samples,
            num_workers=args.num_workers,
            local_path=args.local_path
        )
        if final_path:
            print("\nğŸ‰ ë³‘í•© ì™„ë£Œ!")
            print(f"âœ… ë°ì´í„°ì…‹ì´ '{final_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            print(f"\nğŸ‘‰ ì´ì œ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ í—ˆë¸Œì— ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
            print(f"   python {sys.argv[0]} upload {final_path} <your_hf_username>/{args.output_name}")

    elif args.command == "upload":
        upload_dataset_to_hub(
            dataset_path=args.dataset_path,
            repo_id=args.repo_id,
            private=args.private,
            num_workers=args.num_workers,
            chunk_size=args.chunk_size,
            single_repo=args.single_repo,
            start_chunk_num=args.start_chunk_num
        )

    elif args.command == "inspect":
        inspect_dataset(args.dataset_path)

if __name__ == "__main__":
    main()
    