from datasets import load_dataset, concatenate_datasets, Dataset, Features, Value, Sequence, Image as ImageFeature
import json
from typing import List, Dict, Any
from tqdm.auto import tqdm
import os
import requests
from PIL import Image
from io import BytesIO
from huggingface_hub.utils import disable_progress_bars
import concurrent.futures
from functools import partial
import threading
import time
from urllib.parse import urlparse
import hashlib
import gc
import datetime

disable_progress_bars()  # ì§„í–‰ í‘œì‹œì¤„ ë¹„í™œì„±í™”

# ì´ë¯¸ì§€ ìºì‹œ ë° ì„¸ì…˜ ì„¤ì •
image_cache = {}
cache_lock = threading.Lock()

# ì„¸ì…˜ í’€ ìƒì„± (ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì—°ê²°)
session = requests.Session()
session.headers.update({
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
})

# ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì…‹ ëª©ë¡
dataset_configs = [
    ("HuggingFaceTB/smoltalk", "all"),
    ("R0k1e/UltraLink", None),
    ("PrincetonPLI/Instruct-SkillMix-SDD", None),
    ("allenai/WildChat-1M", None),
    ("nvidia/OpenCodeInstruct", None),
    ("microsoft/orca-agentinstruct-1M-v1", "default"),  # default config ì‚¬ìš©
    ("MaziyarPanahi/Llama-Nemotron-Post-Training-Dataset-v1-ShareGPT", "default"),  # default config ì‚¬ìš©
    ("nvidia/Llama-Nemotron-Post-Training-Dataset", "SFT"),  # SFT config ì‚¬ìš©
    ("open-r1/Mixture-of-Thoughts", "all"),
    ("Salesforce/blip3-kale", "core"),
    ("liuhaotian/LLaVA-Instruct-150K", None),
    ("Lin-Chen/ShareGPT4V", "ShareGPT4V")
]

def construct_image_url(image_path, dataset_name):
    """ë°ì´í„°ì…‹ë³„ë¡œ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì‹¤ì œ URLë¡œ ë³€í™˜"""
    if dataset_name == "Lin-Chen/ShareGPT4V":
        # ShareGPT4VëŠ” COCO ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©
        if image_path.startswith('coco/'):
            # coco/train2017/000000000009.jpg -> COCO ì´ë¯¸ì§€ URL
            filename = os.path.basename(image_path)
            return f"http://images.cocodataset.org/train2017/{filename}"
    elif dataset_name == "liuhaotian/LLaVA-Instruct-150K":
        # LLaVAë„ COCO ì´ë¯¸ì§€ë¥¼ ì£¼ë¡œ ì‚¬ìš©
        if not image_path.startswith('http'):
            # íŒŒì¼ëª…ë§Œ ìˆëŠ” ê²½ìš° COCO URL êµ¬ì„± ì‹œë„
            return f"http://images.cocodataset.org/train2017/{image_path}"
    
    return None

def get_image_cache_key(image_url):
    """ì´ë¯¸ì§€ URLì—ì„œ ìºì‹œ í‚¤ ìƒì„±"""
    return hashlib.md5(image_url.encode()).hexdigest()

def download_image_with_retry(image_url, max_retries=3, timeout=10):
    """ì¬ì‹œë„ ë¡œì§ì´ ìˆëŠ” ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ"""
    for attempt in range(max_retries):
        try:
            response = session.get(image_url, timeout=timeout)
            response.raise_for_status()
            return response.content
        except Exception as e:
            if attempt == max_retries - 1:
                return None
            time.sleep(0.5 * (2 ** attempt))  # ì§€ìˆ˜ ë°±ì˜¤í”„
    return None

def load_image_from_url_or_path(image_source, dataset_name=None):
    """
    URLì´ë‚˜ ê²½ë¡œì—ì„œ ì‹¤ì œ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤. (ìºì‹œ ë° ìµœì í™” í¬í•¨)
    """
    try:
        # ì´ë¯¸ PIL Image ê°ì²´ì¸ ê²½ìš°
        if hasattr(image_source, 'size') and hasattr(image_source, 'convert'):
            return image_source.convert('RGB')
        
        # ë¬¸ìì—´ì¸ ê²½ìš° (URL ë˜ëŠ” íŒŒì¼ëª…)
        if isinstance(image_source, str):
            # HTTP/HTTPS URLì¸ ê²½ìš°
            if image_source.startswith('http://') or image_source.startswith('https://'):
                # ìºì‹œ í™•ì¸
                cache_key = get_image_cache_key(image_source)
                with cache_lock:
                    if cache_key in image_cache:
                        return image_cache[cache_key]
                
                # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                image_data = download_image_with_retry(image_source)
                if image_data:
                    image = Image.open(BytesIO(image_data))
                    image = image.convert('RGB')
                    
                    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì œí•œì„ ìœ„í•œ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
                    max_size = (1024, 1024)
                    if image.size[0] > max_size[0] or image.size[1] > max_size[1]:
                        image.thumbnail(max_size, Image.Resampling.LANCZOS)
                    
                    # ìºì‹œì— ì €ì¥ (ìµœê·¼ 100ê°œë§Œ ìœ ì§€)
                    with cache_lock:
                        if len(image_cache) >= 100:
                            # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
                            oldest_key = next(iter(image_cache))
                            del image_cache[oldest_key]
                        image_cache[cache_key] = image
                    
                    return image
                return None
            
            # ë¡œì»¬ íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°
            elif os.path.exists(image_source):
                image = Image.open(image_source)
                image = image.convert('RGB')
                # í¬ê¸° ì¡°ì •
                max_size = (1024, 1024)
                if image.size[0] > max_size[0] or image.size[1] > max_size[1]:
                    image.thumbnail(max_size, Image.Resampling.LANCZOS)
                return image
            
            # íŒŒì¼ëª…ë§Œ ìˆëŠ” ê²½ìš° - URL êµ¬ì„± ì‹œë„
            else:
                if dataset_name:
                    constructed_url = construct_image_url(image_source, dataset_name)
                    if constructed_url:
                        return load_image_from_url_or_path(constructed_url, dataset_name)
                return None
        
        # bytes ë°ì´í„°ì¸ ê²½ìš°
        elif isinstance(image_source, bytes):
            image = Image.open(BytesIO(image_source))
            image = image.convert('RGB')
            # í¬ê¸° ì¡°ì •
            max_size = (1024, 1024)
            if image.size[0] > max_size[0] or image.size[1] > max_size[1]:
                image.thumbnail(max_size, Image.Resampling.LANCZOS)
            return image
            
        else:
            return None
        
    except Exception as e:
        return None

def process_image_batch(image_sources_with_info, max_workers=8):
    """ì´ë¯¸ì§€ ë°°ì¹˜ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬"""
    results = []
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        # ëª¨ë“  ì´ë¯¸ì§€ ë¡œë“œ ì‘ì—…ì„ ë™ì‹œì— ì‹œì‘
        future_to_info = {
            executor.submit(load_image_from_url_or_path, img_source, dataset_name): (img_source, dataset_name, idx)
            for idx, (img_source, dataset_name) in enumerate(image_sources_with_info)
        }
        
        # ê²°ê³¼ ìˆ˜ì§‘
        for future in concurrent.futures.as_completed(future_to_info):
            img_source, dataset_name, idx = future_to_info[future]
            try:
                result = future.result()
                results.append((idx, result))
            except Exception as e:
                results.append((idx, None))
    
    # ì›ë˜ ìˆœì„œëŒ€ë¡œ ì •ë ¬
    results.sort(key=lambda x: x[0])
    return [result for _, result in results]

def convert_to_target_format(sample: Dict[str, Any], dataset_name: str) -> Dict[str, Any]:
    """
    ê° ë°ì´í„°ì…‹ì˜ ìƒ˜í”Œì„ ëª©í‘œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    í…ìŠ¤íŠ¸ ì „ìš© ë°ì´í„°ì…‹ê³¼ ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì…‹ì„ ëª¨ë‘ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    ëª©í‘œ í˜•ì‹:
    {
        "messages": [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "ì§ˆë¬¸", "index": null},
                    {"type": "image", "text": null, "index": 0}  # ë©€í‹°ëª¨ë‹¬ì¸ ê²½ìš°ë§Œ
                ]
            },
            {
                "role": "assistant", 
                "content": [
                    {"type": "text", "text": "ë‹µë³€", "index": null}
                ]
            }
        ],
        "images": [actual_image_object],  # ë©€í‹°ëª¨ë‹¬ì¸ ê²½ìš°ë§Œ
        "source_dataset": "dataset_name",
        "original_data": {...}
    }
    """
    
    result = {
        "messages": [],
        "images": [],
        "source_dataset": dataset_name,
        "original_data": sample.copy()
    }
    
    try:
        # í…ìŠ¤íŠ¸ ì „ìš© ë°ì´í„°ì…‹ë“¤ ì²˜ë¦¬
        if dataset_name == "HuggingFaceTB/smoltalk":
            if "messages" in sample and isinstance(sample["messages"], list):
                for msg in sample["messages"]:
                    if isinstance(msg, dict) and "role" in msg and "content" in msg:
                        result["messages"].append({
                            "role": msg["role"],
                            "content": [{"type": "text", "text": msg["content"], "index": None}]
                        })
        
        elif dataset_name == "R0k1e/UltraLink":
            if "data" in sample and isinstance(sample["data"], list) and len(sample["data"]) >= 2:
                data = sample["data"]
                for i in range(0, len(data), 2):
                    if i + 1 < len(data):
                        result["messages"].extend([
                            {"role": "user", "content": [{"type": "text", "text": data[i], "index": None}]},
                            {"role": "assistant", "content": [{"type": "text", "text": data[i + 1], "index": None}]}
                        ])
        
        elif dataset_name == "PrincetonPLI/Instruct-SkillMix-SDD":
            if "instruction" in sample and "output" in sample:
                user_content = sample["instruction"]
                if "input" in sample and sample["input"].strip():
                    user_content += f"\n\nInput: {sample['input']}"
                
                result["messages"] = [
                    {"role": "user", "content": [{"type": "text", "text": user_content, "index": None}]},
                    {"role": "assistant", "content": [{"type": "text", "text": sample["output"], "index": None}]}
                ]
        
        elif dataset_name == "allenai/WildChat-1M":
            if "conversation" in sample and isinstance(sample["conversation"], list):
                for conv in sample["conversation"]:
                    if isinstance(conv, dict) and "role" in conv and "content" in conv:
                        result["messages"].append({
                            "role": conv["role"],
                            "content": [{"type": "text", "text": conv["content"], "index": None}]
                        })
        
        elif dataset_name == "nvidia/OpenCodeInstruct":
            if "input" in sample and "output" in sample:
                result["messages"] = [
                    {"role": "user", "content": [{"type": "text", "text": sample["input"], "index": None}]},
                    {"role": "assistant", "content": [{"type": "text", "text": sample["output"], "index": None}]}
                ]
        
        elif dataset_name == "microsoft/orca-agentinstruct-1M-v1":
            if "messages" in sample and isinstance(sample["messages"], list):
                for msg in sample["messages"]:
                    if isinstance(msg, dict) and "role" in msg and "content" in msg:
                        result["messages"].append({
                            "role": msg["role"],
                            "content": [{"type": "text", "text": msg["content"], "index": None}]
                        })
        
        elif "Nemotron" in dataset_name:
            if "conversations" in sample and isinstance(sample["conversations"], list):
                for conv in sample["conversations"]:
                    if isinstance(conv, dict) and "from" in conv and "value" in conv:
                        role = "user" if conv["from"] in ["human", "user"] else "assistant"
                        result["messages"].append({
                            "role": role,
                            "content": [{"type": "text", "text": conv["value"], "index": None}]
                        })
        
        elif dataset_name == "open-r1/Mixture-of-Thoughts":
            if "messages" in sample and isinstance(sample["messages"], list):
                for msg in sample["messages"]:
                    if isinstance(msg, dict) and "role" in msg and "content" in msg:
                        result["messages"].append({
                            "role": msg["role"],
                            "content": [{"type": "text", "text": msg["content"], "index": None}]
                        })
        
        # ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì…‹ë“¤ ì²˜ë¦¬
        elif dataset_name in ["Lin-Chen/ShareGPT4V", "liuhaotian/LLaVA-Instruct-150K"]:
            # ì´ë¯¸ì§€ ì¶”ì¶œ ë° ë¡œë“œ
            image_obj = None
            if "image" in sample and sample["image"] is not None:
                image_obj = load_image_from_url_or_path(sample["image"], dataset_name)
            elif "images" in sample and sample["images"] is not None:
                if isinstance(sample["images"], list) and len(sample["images"]) > 0:
                    image_obj = load_image_from_url_or_path(sample["images"][0], dataset_name)
                else:
                    image_obj = load_image_from_url_or_path(sample["images"], dataset_name)
            
            if image_obj is not None:
                result["images"].append(image_obj)
            
            # conversations ì²˜ë¦¬
            if "conversations" in sample and isinstance(sample["conversations"], list):
                for i, conv in enumerate(sample["conversations"]):
                    if not isinstance(conv, dict):
                        continue
                        
                    # role ê²°ì •
                    role = "assistant"
                    if "from" in conv:
                        if conv["from"] in ["human", "user"]:
                            role = "user"
                        elif conv["from"] in ["gpt", "assistant"]:
                            role = "assistant"
                    
                    # content ìƒì„±
                    content_list = []
                    text_content = conv.get("value", "")
                    
                    if text_content:
                        # <image> íƒœê·¸ ì œê±° (ì´ë¯¸ì§€ëŠ” ë³„ë„ ì²˜ë¦¬)
                        text_content = text_content.replace("<image>", "").strip()
                        
                        if text_content:  # ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš°ë§Œ
                            content_list.append({
                                "type": "text",
                                "text": text_content,
                                "index": None
                            })
                    
                    # ì²« ë²ˆì§¸ user ë©”ì‹œì§€ì— ì´ë¯¸ì§€ ì¶”ê°€
                    if role == "user" and i == 0 and result["images"]:
                        content_list.append({
                            "type": "image", 
                            "text": None,
                            "index": 0
                        })
                    
                    if content_list:  # contentê°€ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€
                        result["messages"].append({
                            "role": role,
                            "content": content_list
                        })
        
        elif dataset_name == "Salesforce/blip3-kale":
            # ì´ë¯¸ì§€ ë¡œë“œ
            image_obj = None
            if "url" in sample:
                image_obj = load_image_from_url_or_path(sample["url"], dataset_name)
            elif "image" in sample:
                image_obj = load_image_from_url_or_path(sample["image"], dataset_name)
            
            if image_obj is not None:
                result["images"].append(image_obj)
            
            # captionì„ ëŒ€í™” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            caption = sample.get("caption", "").strip()
            if not caption:
                caption = sample.get("cogvlm_caption", "").strip()
            
            if caption:
                # ì²« ë²ˆì§¸ user ë©”ì‹œì§€ì— ì´ë¯¸ì§€ í¬í•¨
                user_content = [{"type": "text", "text": "Describe this image.", "index": None}]
                if result["images"]:
                    user_content.append({"type": "image", "text": None, "index": 0})
                
                result["messages"] = [
                    {"role": "user", "content": user_content},
                    {"role": "assistant", "content": [{"type": "text", "text": caption, "index": None}]}
                ]
        
        # ë¹ˆ messagesì¸ ê²½ìš° None ë°˜í™˜
        if not result["messages"]:
            return None
            
        return result
        
    except Exception as e:
        print(f"Error converting sample from {dataset_name}: {str(e)}")
        return None

def process_samples_batch(samples_batch, dataset_name, max_workers=8):
    """ìƒ˜í”Œ ë°°ì¹˜ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬"""
    # ì´ë¯¸ì§€ê°€ ìˆëŠ” ìƒ˜í”Œë“¤ì„ ë¨¼ì € ì‹ë³„
    image_samples = []
    non_image_samples = []
    
    for i, sample in enumerate(samples_batch):
        has_image = False
        
        # ì´ë¯¸ì§€ê°€ ìˆëŠ” ë°ì´í„°ì…‹ì¸ì§€ í™•ì¸
        if dataset_name in ["Lin-Chen/ShareGPT4V", "liuhaotian/LLaVA-Instruct-150K", "Salesforce/blip3-kale"]:
            if ("image" in sample and sample["image"]) or ("images" in sample and sample["images"]) or ("url" in sample and sample["url"]):
                has_image = True
        
        if has_image:
            image_samples.append((i, sample))
        else:
            non_image_samples.append((i, sample))
    
    # ì´ë¯¸ì§€ê°€ ì—†ëŠ” ìƒ˜í”Œë“¤ì„ ë¨¼ì € ë¹ ë¥´ê²Œ ì²˜ë¦¬
    results = [None] * len(samples_batch)
    
    for i, sample in non_image_samples:
        converted = convert_to_target_format(sample, dataset_name)
        results[i] = converted
    
    # ì´ë¯¸ì§€ê°€ ìˆëŠ” ìƒ˜í”Œë“¤ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬
    if image_samples:
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_idx = {
                executor.submit(convert_to_target_format, sample, dataset_name): i
                for i, sample in image_samples
            }
            
            for future in concurrent.futures.as_completed(future_to_idx):
                idx = future_to_idx[future]
                try:
                    result = future.result()
                    results[idx] = result
                except Exception as e:
                    results[idx] = None
    
    return [r for r in results if r is not None]

def process_dataset(dataset_name: str, config_name: str = None, max_samples: int = None, num_workers: int = 8):
    """ë°ì´í„°ì…‹ì„ ì²˜ë¦¬í•˜ì—¬ ëª©í‘œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. (ë³‘ë ¬ ì²˜ë¦¬ ì¶”ê°€)"""
    try:
        # íŠ¹ì • ë°ì´í„°ì…‹ë“¤ì˜ split ì„¤ì •
        if dataset_name == "microsoft/orca-agentinstruct-1M-v1":
            split = "creative_content"
        elif dataset_name == "MaziyarPanahi/Llama-Nemotron-Post-Training-Dataset-v1-ShareGPT":
            split = "chat"
        elif dataset_name == "nvidia/Llama-Nemotron-Post-Training-Dataset":
            split = "chat"
        else:
            split = "train"
        
        # ë°ì´í„°ì…‹ ë¡œë“œ
        try:
            if config_name:
                full_dataset = load_dataset(dataset_name, config_name, split=split, streaming=True)
            else:
                full_dataset = load_dataset(dataset_name, split=split, streaming=True)
        except Exception as e:
            print(f"âŒ ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨ ({split} split): {e}")
            # train splitìœ¼ë¡œ ì¬ì‹œë„
            if split != "train":
                try:
                    print(f"ğŸ”„ train splitìœ¼ë¡œ ì¬ì‹œë„...")
                    if config_name:
                        full_dataset = load_dataset(dataset_name, config_name, split="train", streaming=True)
                    else:
                        full_dataset = load_dataset(dataset_name, split="train", streaming=True)
                except Exception as e2:
                    print(f"âŒ train splitìœ¼ë¡œë„ ì‹¤íŒ¨: {e2}")
                    return
            else:
                return

        success_count = 0
        total_count = 0
        batch_size = max(8, num_workers)  # ë°°ì¹˜ í¬ê¸°ë¥¼ ì›Œì»¤ ìˆ˜ì— ë§ì¶¤
        current_batch = []
        
        # ì§„í–‰ ìƒí™© í‘œì‹œë¥¼ ìœ„í•œ tqdm ì„¤ì •
        desc = f"{dataset_name.split('/')[-1]}"
        if config_name:
            desc += f"({config_name})"
        
        # leave=Falseë¥¼ ì¶”ê°€í•˜ì—¬ ì™„ë£Œ í›„ ì§„í–‰ ë§‰ëŒ€ê°€ ì‚¬ë¼ì§€ë„ë¡ í•¨
        progress_bar = tqdm(desc=desc, unit="samples", leave=False)
        
        # ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° ì²˜ë¦¬
        for sample in full_dataset:
            if max_samples and total_count >= max_samples:
                break
            
            current_batch.append(sample)
            total_count += 1
            
            # ë°°ì¹˜ê°€ ì°¼ê±°ë‚˜ ë§ˆì§€ë§‰ ìƒ˜í”Œì¸ ê²½ìš° ì²˜ë¦¬
            if len(current_batch) >= batch_size or (max_samples and total_count >= max_samples):
                # ë°°ì¹˜ ì²˜ë¦¬
                batch_results = process_samples_batch(current_batch, dataset_name, num_workers)
                
                if batch_results:
                    success_count += len(batch_results)
                    yield batch_results
                
                progress_bar.update(len(current_batch))
                progress_bar.set_postfix({
                    "processed": f"{success_count}/{total_count}",
                    "success_rate": f"{success_count/total_count*100:.1f}%"
                })
                
                current_batch = []
        
        # ë‚¨ì€ ë°°ì¹˜ ì²˜ë¦¬
        if current_batch:
            batch_results = process_samples_batch(current_batch, dataset_name, num_workers)
            if batch_results:
                success_count += len(batch_results)
                yield batch_results
            progress_bar.update(len(current_batch))
        
        progress_bar.close()
        
        # ì™„ë£Œ ë©”ì‹œì§€ë¥¼ ë°˜í™˜ê°’ìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ë‚˜ì¤‘ì— í•œ ë²ˆì— ì¶œë ¥í•˜ë„ë¡ í•¨
        yield f"âœ… {dataset_name}: {success_count}/{total_count} ìƒ˜í”Œ ë³€í™˜ ì™„ë£Œ (ì„±ê³µë¥ : {success_count/total_count*100:.1f}%)" if total_count > 0 else f"â„¹ï¸ {dataset_name}: ì²˜ë¦¬í•  ìƒ˜í”Œ ì—†ìŒ"

    except Exception as e:
        yield f"âŒ {dataset_name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"

def merge_and_create_dataset(
    output_name: str = "unified-multimodal-sft", 
    max_samples_per_dataset: int = None, 
    num_workers: int = 16, 
    local_path: str = "./",
    private: bool = False
):
    """
    ëª¨ë“  ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì…‹ì„ ë³‘í•©í•˜ê³  ëª©í‘œ í˜•ì‹ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
    ë©”ëª¨ë¦¬ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì¤‘ê°„ ê²°ê³¼ë¥¼ ë””ìŠ¤í¬ì— ì €ì¥í•˜ëŠ” ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    print(f"ğŸš€ ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì…‹ ë³‘í•© ì‹œì‘... (ì›Œì»¤ ìˆ˜: {num_workers})")
    
    # 1. ì„ì‹œ ì €ì¥ ê³µê°„ ì„¤ì •
    staging_dir = f"{local_path}/{output_name}_staging".replace("//", "/")
    images_dir = os.path.join(staging_dir, "images")
    os.makedirs(images_dir, exist_ok=True)
    jsonl_path = os.path.join(staging_dir, "data.jsonl")
    
    tqdm.write(f"ğŸ“‚ ì„ì‹œ ì €ì¥ ê²½ë¡œ: {staging_dir}")

    # JSON ì§ë ¬í™”ë¥¼ ìœ„í•œ datetime í•¸ë“¤ëŸ¬
    def datetime_handler(x):
        if isinstance(x, datetime.datetime):
            return x.isoformat()
        raise TypeError(f"Object of type {type(x).__name__} is not JSON serializable")

    total_samples = 0
    image_counter = 0
    completion_messages = []

    # 2. ë°ì´í„°ë¥¼ JSONLê³¼ ì´ë¯¸ì§€ íŒŒì¼ë¡œ ë””ìŠ¤í¬ì— ì €ì¥
    with open(jsonl_path, "w", encoding="utf-8") as f:
        dataset_progress = tqdm(dataset_configs, desc="ë°ì´í„°ì…‹ ì²˜ë¦¬", unit="dataset")

        for dataset_name, config_name in dataset_progress:
            dataset_progress.set_description(f"ì²˜ë¦¬ì¤‘: {dataset_name.split('/')[-1]}")
            try:
                for result in process_dataset(dataset_name, config_name, max_samples_per_dataset, num_workers):
                    if isinstance(result, list): # ë°°ì¹˜ ê²°ê³¼
                        for sample in result:
                            # ì´ë¯¸ì§€ ì²˜ë¦¬: PIL ê°ì²´ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ê²½ë¡œë¡œ ëŒ€ì²´
                            image_paths = []
                            if sample.get("images"):
                                for img in sample["images"]:
                                    if hasattr(img, 'save'):
                                        image_filename = f"{image_counter:08d}.png"
                                        # ìƒëŒ€ ê²½ë¡œë¡œ ì €ì¥
                                        img_save_path = os.path.join(images_dir, image_filename)
                                        img.save(img_save_path, "PNG")
                                        image_paths.append(os.path.join("images", image_filename))
                                        image_counter += 1
                            
                            sample["images"] = image_paths
                            # original_dataëŠ” python ê°ì²´ë¡œ ìœ ì§€í•˜ê³ , ì „ì²´ë¥¼ í•œë²ˆì— ì§ë ¬í™”
                            
                            f.write(json.dumps(
                                sample, 
                                ensure_ascii=False, 
                                default=datetime_handler
                            ) + "\n")
                            total_samples += 1
                        
                        dataset_progress.set_postfix({"ì´ ìƒ˜í”Œ": total_samples})

                    elif isinstance(result, str): # ì™„ë£Œ ë©”ì‹œì§€
                        completion_messages.append(result)
            except Exception as e:
                tqdm.write(f"âŒ {dataset_name} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
                continue

            # ë°ì´í„°ì…‹ ì²˜ë¦¬ í›„ ë©”ëª¨ë¦¬ ìµœì í™”
            with cache_lock:
                image_cache.clear()
            gc.collect()
            tqdm.write(f"ğŸ§  {dataset_name.split('/')[-1]} ì²˜ë¦¬ í›„ ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ.")

    dataset_progress.close()

    tqdm.write("\n" + "="*20 + " ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½ " + "="*20)
    for msg in completion_messages:
        tqdm.write(msg)
    tqdm.write("="*55)

    if total_samples == 0:
        print("âŒ ë³€í™˜ëœ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    tqdm.write(f"\nğŸ¯ ì´ {total_samples}ê°œ ìƒ˜í”Œ ë³€í™˜ ì™„ë£Œ ë° ì„ì‹œ ì €ì¥ ì™„ë£Œ")
    
    # 3. ë””ìŠ¤í¬ì— ì €ì¥ëœ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ íš¨ìœ¨ì ìœ¼ë¡œ ë¡œë“œ
    tqdm.write("ğŸ“¦ ì„ì‹œ íŒŒì¼ë¡œë¶€í„° Dataset ê°ì²´ ìƒì„± ì¤‘...")
    
    # ë°ì´í„°ì…‹ì˜ ìµœì¢… ìŠ¤í‚¤ë§ˆ(êµ¬ì¡°) ì •ì˜
    features = Features({
        'messages': Sequence({'role': Value('string'), 'content': Sequence({'type': Value('string'), 'text': Value('string'), 'index': Value('int64')})}),
        'images': Sequence(ImageFeature()),
        'source_dataset': Value('string'),
        'original_data': Value('string')
    })
    
    # JSONL íŒŒì¼ì„ ë¡œë“œí•˜ê³ , ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì‹¤ì œ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ë„ë¡ ì„¤ì •
    unified_dataset = load_dataset("json", data_files=jsonl_path, features=features)["train"]
    unified_dataset = unified_dataset.cast_column("images", Sequence(ImageFeature(decode=True)))
    
    # ìºì‹œ ì •ë¦¬
    with cache_lock:
        image_cache.clear()
    
    # ë¡œì»¬ ì €ì¥
    tqdm.write("ğŸ’¾ ë¡œì»¬ ì €ì¥ ì¤‘ (ìµœì¢… Arrow í¬ë§·)...")
    final_save_path = f"{local_path}/{output_name}"
    unified_dataset.save_to_disk(final_save_path)
    tqdm.write(f"   - ìµœì¢… ë°ì´í„°ì…‹ ê²½ë¡œ: {final_save_path}")
    
    # í—ˆê¹…í˜ì´ìŠ¤ ì—…ë¡œë“œ ì‹œë„
    try:
        tqdm.write("ğŸš€ í—ˆê¹…í˜ì´ìŠ¤ ì—…ë¡œë“œ ì‹œë„...")
        
        # ì—…ë¡œë“œ ì „ ë°ì´í„°ì…‹ ì •ë³´ í™•ì¸
        tqdm.write(f"   - ì´ ìƒ˜í”Œ ìˆ˜: {len(unified_dataset):,}")
        tqdm.write(f"   - ì»¬ëŸ¼: {list(unified_dataset.column_names)}")
        
        # push_to_hub í˜¸ì¶œ - ë” ë‚˜ì€ íŒŒë¼ë¯¸í„°ì™€ í•¨ê»˜
        unified_dataset.push_to_hub(
            output_name, 
            private=private,
            max_shard_size="1GB",  # ìƒ¤ë“œ í¬ê¸° ì œí•œ
            commit_message=f"Upload unified SFT dataset with {len(unified_dataset):,} samples"
        )
        
        tqdm.write(f"âœ… ì„±ê³µì ìœ¼ë¡œ {output_name}ìœ¼ë¡œ ì—…ë¡œë“œ!")
        tqdm.write(f"ğŸ”— https://huggingface.co/datasets/{output_name}")
        
    except Exception as e:
        print(f"âš ï¸ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        print("ğŸ’¾ ë¡œì»¬ ì €ì¥ì€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    return unified_dataset

def inspect_dataset(dataset_path: str = "./unified-multimodal-sft"):
    """ìƒì„±ëœ ë°ì´í„°ì…‹ ê²€ì‚¬"""
    try:
        print(f"ğŸ” ë°ì´í„°ì…‹ ê²€ì‚¬: {dataset_path}")
        
        dataset = Dataset.load_from_disk(dataset_path)
        print(f"ğŸ“Š ì´ ìƒ˜í”Œ ìˆ˜: {len(dataset)}")
        
        # êµ¬ì¡° ê²€ì‚¬
        sample_with_image = None
        sample_without_image = None
        
        for sample in dataset:
            if sample.get("images") and not sample_with_image:
                sample_with_image = sample
            elif not sample.get("images") and not sample_without_image:
                sample_without_image = sample
            
            if sample_with_image and sample_without_image:
                break
        
        # ì´ë¯¸ì§€ í¬í•¨ ìƒ˜í”Œ ì˜ˆì‹œ
        if sample_with_image:
            print(f"\nğŸ–¼ï¸ ì´ë¯¸ì§€ í¬í•¨ ìƒ˜í”Œ ì˜ˆì‹œ:")
            print(f"   ì´ë¯¸ì§€ ìˆ˜: {len(sample_with_image['images'])}")
            print(f"   ë©”ì‹œì§€ ìˆ˜: {len(sample_with_image['messages'])}")
            
            # ì²« ë²ˆì§¸ ë©”ì‹œì§€ êµ¬ì¡° í™•ì¸
            if sample_with_image['messages']:
                first_msg = sample_with_image['messages'][0]
                print(f"   ì²« ë²ˆì§¸ ë©”ì‹œì§€ role: {first_msg.get('role')}")
                print(f"   ì²« ë²ˆì§¸ ë©”ì‹œì§€ content ìˆ˜: {len(first_msg.get('content', []))}")
                
                for j, content in enumerate(first_msg.get('content', [])[:3]):
                    content_type = content.get('type', 'unknown')
                    if content_type == 'text':
                        text_preview = content.get('text', '')[:50] + "..." if len(content.get('text', '')) > 50 else content.get('text', '')
                        print(f"     Content {j+1}: {content_type} - '{text_preview}'")
                    else:
                        print(f"     Content {j+1}: {content_type} - index: {content.get('index')}")
        
        # í†µê³„
        image_count = sum(1 for sample in dataset if sample.get("images"))
        print(f"\nğŸ“ˆ ì´ë¯¸ì§€ í¬í•¨ ìƒ˜í”Œ: {image_count}/{len(dataset)} ({image_count/len(dataset)*100:.1f}%)")
        
        # ì›ë³¸ ë°ì´í„°ì…‹ë³„ í†µê³„
        source_stats = {}
        for sample in dataset:
            source = sample.get("source_dataset", "unknown")
            source_stats[source] = source_stats.get(source, 0) + 1
        
        print(f"\nğŸ“Š ì›ë³¸ ë°ì´í„°ì…‹ë³„ ë¶„í¬:")
        for source, count in sorted(source_stats.items()):
            print(f"   {source}: {count}ê°œ ({count/len(dataset)*100:.1f}%)")
        
        # ì›ë³¸ ë°ì´í„° ë³´ì¡´ í™•ì¸
        original_data_count = sum(1 for sample in dataset if sample.get("original_data"))
        print(f"\nğŸ’¾ ì›ë³¸ ë°ì´í„° ë³´ì¡´: {original_data_count}/{len(dataset)} ({original_data_count/len(dataset)*100:.1f}%)")
        
        # ì›ë³¸ ë°ì´í„° ì˜ˆì‹œ (ì²« ë²ˆì§¸ ìƒ˜í”Œ)
        if dataset[0].get("original_data"):
            print(f"\nğŸ” ì›ë³¸ ë°ì´í„° ì˜ˆì‹œ (ì²« ë²ˆì§¸ ìƒ˜í”Œ):")
            original = dataset[0]["original_data"]
            print(f"   ì›ë³¸ ë°ì´í„° í‚¤: {list(original.keys())}")
            for key, value in list(original.items())[:3]:  # ì²˜ìŒ 3ê°œ í‚¤ë§Œ í‘œì‹œ
                if isinstance(value, str) and len(value) > 50:
                    print(f"   {key}: {value[:50]}...")
                else:
                    print(f"   {key}: {value}")
        
        return dataset
        
    except Exception as e:
        print(f"âŒ ê²€ì‚¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import sys
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "merge":
            if len(sys.argv) < 3:
                print("âŒ ë¦¬í¬ì§€í† ë¦¬ ì´ë¦„ì´ í•„ìš”í•©ë‹ˆë‹¤!")
                print("ì‚¬ìš©ë²•: python upload_sft_dataset.py merge <repository_name> [max_samples_per_dataset] [num_workers]")
                return
            
            repository_name = sys.argv[2]
            max_samples = int(sys.argv[3]) if len(sys.argv) > 3 else None
            num_workers = int(sys.argv[4]) if len(sys.argv) > 4 else 16
            local_path = sys.argv[5] if len(sys.argv) > 5 else "./"
            private = bool(sys.argv[6]) if len(sys.argv) > 6 else False
            
            
            print(f"ğŸ¯ íƒ€ê²Ÿ ë¦¬í¬ì§€í† ë¦¬: {repository_name}")
            print(f"ğŸ”§ ì›Œì»¤ ìˆ˜: {num_workers}")
            dataset = merge_and_create_dataset(
                output_name=repository_name,
                max_samples_per_dataset=max_samples,
                num_workers=num_workers,
                private=private,
                local_path=local_path
            )
            if dataset:
                print("ğŸ‰ ë³‘í•© ì™„ë£Œ!")
                
        elif sys.argv[1] == "inspect":
            dataset_path = sys.argv[2] if len(sys.argv) > 2 else "./unified-multimodal-sft"
            inspect_dataset(dataset_path)
            
    else:
        print("ì‚¬ìš©ë²•:")
        print("  python upload_sft_dataset.py merge <repository_name> [max_samples_per_dataset] [num_workers]")
        print("  python upload_sft_dataset.py inspect [dataset_path]")
        print("")
        print("ğŸ“ í…ìŠ¤íŠ¸ + ë©€í‹°ëª¨ë‹¬ í†µí•© ë°ì´í„°ì…‹ ì²˜ë¦¬ (ë³‘ë ¬ ì²˜ë¦¬ ì§€ì›)")
        print("í¬í•¨ëœ ë°ì´í„°ì…‹:")
        for dataset_name, config_name in dataset_configs:
            if config_name:
                print(f"  - {dataset_name} ({config_name})")
            else:
                print(f"  - {dataset_name}")
        print("")
        print("ì˜ˆì‹œ:")
        print("  python upload_sft_dataset.py merge my-unified-dataset 1000 32  # 32ê°œ ì›Œì»¤ ì‚¬ìš©")
        print("  python upload_sft_dataset.py merge my-unified-dataset 1000     # ê¸°ë³¸ 16ê°œ ì›Œì»¤")
        print("  python upload_sft_dataset.py merge my-unified-dataset          # ì „ì²´ ë°ì´í„°, ê¸°ë³¸ ì›Œì»¤")
        print("  python upload_sft_dataset.py inspect ./my-unified-dataset")

if __name__ == "__main__":
    main()
    