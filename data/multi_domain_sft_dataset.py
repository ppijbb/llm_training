import logging
from tqdm import tqdm
from datasets import load_dataset, get_dataset_config_names, get_dataset_split_names, concatenate_datasets
from transformers import AutoProcessor
import torch
from typing import Dict, Any, List, Optional, Tuple
import traceback
import gc
import os
import sys
import random
import tempfile
import pathlib
import shutil
import json
from PIL import Image
from datasets import Dataset, DatasetDict, load_dataset, Image as DatasetImage, Sequence, Features
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed, CancelledError
import threading

# simple_sft_datasetì˜ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ import
from data.simple_sft_dataset import (
    validate_image_data,
    validate_messages,
    safe_flatten_images,
    get_memory_usage,
    log_memory_usage
)

def ensure_string(value: Any) -> str:
    """
    ê°’ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. Noneì´ë©´ ë¹ˆ ë¬¸ìì—´ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if value is None:
        return ""
    return str(value)

def ensure_messages_text_strings(messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    messagesì˜ ëª¨ë“  í…ìŠ¤íŠ¸ í•„ë“œë¥¼ ë¬¸ìì—´ë¡œ ë³´ì¥í•©ë‹ˆë‹¤.
    contentëŠ” í•­ìƒ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ê°ì²´ ë°°ì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
    """
    result = []
    for msg in messages:
        if not isinstance(msg, dict) or "content" not in msg:
            continue
        
        new_msg = msg.copy()
        content = msg.get("content", [])
        
        # contentê°€ ë¬¸ìì—´ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        if isinstance(content, str):
            content = [{"type": "text", "text": content}]
        # contentê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        elif not isinstance(content, list):
            content = [content] if content else []
        
        new_content = []
        for content_item in content:
            if isinstance(content_item, dict):
                new_item = content_item.copy()
                if "text" in new_item:
                    new_item["text"] = ensure_string(new_item["text"])
                new_content.append(new_item)
            elif isinstance(content_item, str):
                # ë¬¸ìì—´ì¸ ê²½ìš° ê°ì²´ë¡œ ë³€í™˜
                new_content.append({"type": "text", "text": ensure_string(content_item)})
            else:
                # ê¸°íƒ€ íƒ€ì…ì€ ë¬¸ìì—´ë¡œ ë³€í™˜
                new_content.append({"type": "text", "text": ensure_string(content_item)})
        
        new_msg["content"] = new_content
        result.append(new_msg)
    
    return result

def dataset_exists(dataset_name: str) -> bool:
    """
    ì£¼ì–´ì§„ ë°ì´í„°ì…‹ì´ Hugging Face Hubì— ì¡´ì¬í•˜ëŠ”ì§€ ê°„ë‹¨íˆ í™•ì¸í•©ë‹ˆë‹¤.
    ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ì ‘ê·¼ ë¶ˆê°€í•˜ë©´ Falseë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        _ = get_dataset_config_names(dataset_name)
        return True
    except Exception:
        logger.warning(f"âš ï¸ ë°ì´í„°ì…‹ì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {dataset_name} (ê±´ë„ˆëœ€)")
        return False

# ============================================================
# ë°ì´í„°ì…‹ë³„ ì „ìš© ë³€í™˜ í”„ë¡œì„¸ì„œ í•¨ìˆ˜ë“¤
# ============================================================

def process_rstar_coder(dataset, dataset_name: str, max_samples: int, log_detail: bool = False) -> List[Dict[str, Any]]:
    """
    microsoft/rStar-Coder ë°ì´í„°ì…‹ ì „ìš© í”„ë¡œì„¸ì„œ
    ë°ì´í„°ì…‹ ì „ì²´ë¥¼ ì²˜ë¦¬í•˜ì—¬ messages í˜•ì‹ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    """
    results = []
    sample_count = 0
    failed_count = 0
    
    logger.debug(f"   ğŸ”§ rStar-Coder ì „ìš© í”„ë¡œì„¸ì„œ ì‹œì‘ (ìµœëŒ€ {max_samples}ê°œ ìƒ˜í”Œ)")
    
    for idx, sample in enumerate(dataset):
        if sample_count >= max_samples:
            break
        
        try:
            # rStar-Coderì˜ ì‹¤ì œ ì»¬ëŸ¼: question, seed_question, seed_source, response, code
            question = sample.get("question", "")
            seed_question = sample.get("seed_question", "")
            response = sample.get("response", "")
            code = sample.get("code", "")
            
            # ë””ë²„ê¹…: ì²˜ìŒ ëª‡ ê°œ ìƒ˜í”Œ ë¡œê¹… (DEBUG ë ˆë²¨)
            if log_detail and idx < 2:
                logger.debug(f"   ğŸ” rStar-Coder ìƒ˜í”Œ {idx}: keys={list(sample.keys())}")
            
            # question ë˜ëŠ” seed_question ì¤‘ í•˜ë‚˜ëŠ” ìˆì–´ì•¼ í•¨
            user_prompt = question.strip() if question and question.strip() else (seed_question.strip() if seed_question and seed_question.strip() else "")
            if not user_prompt:
                failed_count += 1
                continue
            
            # responseì™€ code ì¤‘ í•˜ë‚˜ëŠ” ìˆì–´ì•¼ í•¨
            assistant_content_parts = []
            if response and response.strip():
                assistant_content_parts.append(response.strip())
            if code and code.strip():
                if assistant_content_parts:
                    assistant_content_parts.append(f"\n\n```python\n{code.strip()}\n```")
                else:
                    assistant_content_parts.append(code.strip())
            
            if not assistant_content_parts:
                failed_count += 1
                continue
            
            assistant_text = "\n".join(assistant_content_parts)
            
            messages = [
                {"role": "user", "content": [{"type": "text", "text": user_prompt}]},
                {"role": "assistant", "content": [{"type": "text", "text": assistant_text}]}
            ]
            
            results.append({"messages": messages, "images": []})
            sample_count += 1
            
        except Exception as e:
            logger.error(f"   âŒ rStar-Coder ìƒ˜í”Œ {idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            failed_count += 1
            continue
    
    logger.info(f"   âœ… rStar-Coder í”„ë¡œì„¸ì„œ ì™„ë£Œ: ì„±ê³µ {sample_count}ê°œ, ì‹¤íŒ¨ {failed_count}ê°œ")
    return results

def process_metamath(dataset, dataset_name: str, max_samples: int, log_detail: bool = False) -> List[Dict[str, Any]]:
    """
    meta-math/MetaMathQA ë°ì´í„°ì…‹ ì „ìš© í”„ë¡œì„¸ì„œ
    """
    results = []
    sample_count = 0
    failed_count = 0
    
    logger.debug(f"   ğŸ”§ MetaMath ì „ìš© í”„ë¡œì„¸ì„œ ì‹œì‘ (ìµœëŒ€ {max_samples}ê°œ ìƒ˜í”Œ)")
    
    for idx, sample in enumerate(dataset):
        if sample_count >= max_samples:
            break
        
        try:
            query = sample.get("query", "")
            response = sample.get("response", "")
            
            if not query or not response:
                failed_count += 1
                continue
            
            messages = [
                {"role": "user", "content": [{"type": "text", "text": query}]},
                {"role": "assistant", "content": [{"type": "text", "text": response}]}
            ]
            
            results.append({"messages": messages, "images": []})
            sample_count += 1
            
        except Exception as e:
            logger.error(f"   âŒ MetaMath ìƒ˜í”Œ {idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            failed_count += 1
            continue
    
    logger.info(f"   âœ… MetaMath í”„ë¡œì„¸ì„œ ì™„ë£Œ: ì„±ê³µ {sample_count}ê°œ, ì‹¤íŒ¨ {failed_count}ê°œ")
    return results

def process_math_python_reasoning(dataset, dataset_name: str, max_samples: int, log_detail: bool = False) -> List[Dict[str, Any]]:
    """
    sdiazlor/math-python-reasoning-dataset ì „ìš© í”„ë¡œì„¸ì„œ
    """
    results = []
    sample_count = 0
    failed_count = 0
    
    logger.debug(f"   ğŸ”§ Math-Python-Reasoning ì „ìš© í”„ë¡œì„¸ì„œ ì‹œì‘ (ìµœëŒ€ {max_samples}ê°œ ìƒ˜í”Œ)")
    
    for idx, sample in enumerate(dataset):
        if sample_count >= max_samples:
            break
        
        try:
            prompt = sample.get("prompt", "")
            completion = sample.get("completion", "")
            system_prompt = sample.get("system_prompt", "")
            
            # instruction/output í˜•ì‹ë„ ì§€ì› (í•˜ìœ„ í˜¸í™˜ì„±)
            if not prompt:
                prompt = sample.get("instruction", "")
            if not completion:
                completion = sample.get("output", "")
            
            if not prompt or not completion:
                failed_count += 1
                continue
            
            messages = []
            
            # system_promptê°€ ìˆìœ¼ë©´ system ë©”ì‹œì§€ë¡œ ì¶”ê°€
            if system_prompt:
                messages.append({"role": "system", "content": [{"type": "text", "text": system_prompt}]})
            
            messages.extend([
                {"role": "user", "content": [{"type": "text", "text": prompt}]},
                {"role": "assistant", "content": [{"type": "text", "text": completion}]}
            ])
            
            results.append({"messages": messages, "images": []})
            sample_count += 1
            
        except Exception as e:
            logger.error(f"   âŒ Math-Python-Reasoning ìƒ˜í”Œ {idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            failed_count += 1
            continue
    
    logger.info(f"   âœ… Math-Python-Reasoning í”„ë¡œì„¸ì„œ ì™„ë£Œ: ì„±ê³µ {sample_count}ê°œ, ì‹¤íŒ¨ {failed_count}ê°œ")
    return results

def process_llava_onevision(dataset, dataset_name: str, max_samples: int, log_detail: bool = False) -> List[Dict[str, Any]]:
    """
    lmms-lab/LLaVA-OneVision-Data ì „ìš© í”„ë¡œì„¸ì„œ (multimodal)
    """
    results = []
    sample_count = 0
    failed_count = 0
    
    logger.debug(f"   ğŸ”§ LLaVA-OneVision ì „ìš© í”„ë¡œì„¸ì„œ ì‹œì‘ (ìµœëŒ€ {max_samples}ê°œ ìƒ˜í”Œ)")
    
    for idx, sample in enumerate(dataset):
        if sample_count >= max_samples:
            break
        
        try:
            # conversations + images í˜•ì‹
            conversations = sample.get("conversations", [])
            images = sample.get("images", [])
            
            if not conversations:
                failed_count += 1
                continue
            
            messages = []
            for conv in conversations:
                role = conv.get("from", "")
                value = conv.get("value", "")
                
                if role == "human":
                    messages.append({"role": "user", "content": [{"type": "text", "text": value}]})
                elif role == "gpt":
                    messages.append({"role": "assistant", "content": [{"type": "text", "text": value}]})
            
            if not messages:
                failed_count += 1
                continue
            
            # ì´ë¯¸ì§€ ì²˜ë¦¬
            image_list = []
            if images:
                flattened_images = validate_image_data(images)
                image_list = flattened_images if flattened_images else []
            
            results.append({"messages": messages, "images": image_list})
            sample_count += 1
            
        except Exception as e:
            logger.error(f"   âŒ LLaVA-OneVision ìƒ˜í”Œ {idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            failed_count += 1
            continue
    
    logger.info(f"   âœ… LLaVA-OneVision í”„ë¡œì„¸ì„œ ì™„ë£Œ: ì„±ê³µ {sample_count}ê°œ, ì‹¤íŒ¨ {failed_count}ê°œ")
    return results

def process_olmocr(dataset, dataset_name: str, max_samples: int, log_detail: bool = False) -> List[Dict[str, Any]]:
    """
    allenai/olmOCR-mix-1025 ì „ìš© í”„ë¡œì„¸ì„œ (OCR, multimodal)
    
    ë°ì´í„° êµ¬ì¡°:
    - natural_text: OCRëœ í…ìŠ¤íŠ¸ (ground truth)
    - pdf_relpath: PDF íŒŒì¼ ê²½ë¡œ (tar.gz ë‚´ë¶€)
    - url: ì›ë³¸ PDF URL
    - image: PDF í˜ì´ì§€ ì´ë¯¸ì§€ (ìˆëŠ” ê²½ìš°)
    
    VLMìš© instruction: "ì´ ë¬¸ì„œ í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”"
    """
    results = []
    sample_count = 0
    failed_count = 0
    
    logger.debug(f"   ğŸ”§ olmOCR ì „ìš© í”„ë¡œì„¸ì„œ ì‹œì‘ (ìµœëŒ€ {max_samples}ê°œ ìƒ˜í”Œ)")
    
    for idx, sample in enumerate(dataset):
        if sample_count >= max_samples:
            break
        
        try:
            # OCRëœ í…ìŠ¤íŠ¸ (ground truth)
            natural_text = sample.get("natural_text", "")
            if not natural_text or not natural_text.strip():
                if log_detail and idx < 5:
                    logger.warning(f"   âš ï¸ olmOCR ìƒ˜í”Œ {idx}: natural_textê°€ ë¹„ì–´ìˆìŒ")
                failed_count += 1
                continue
            
            # ì´ë¯¸ì§€ ì²˜ë¦¬ (PDF í˜ì´ì§€ ì´ë¯¸ì§€)
            image_list = []
            
            # 1. image í•„ë“œ í™•ì¸ (DatasetImage íƒ€ì…)
            if "image" in sample:
                img = sample["image"]
                if img is not None:
                    flattened_images = validate_image_data([img])
                    if flattened_images:
                        image_list = flattened_images
            
            # 2. images í•„ë“œ í™•ì¸ (ë¦¬ìŠ¤íŠ¸)
            if not image_list and "images" in sample:
                images = sample["images"]
                if images:
                    flattened_images = validate_image_data(images)
                    if flattened_images:
                        image_list = flattened_images
            
            # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ OCR íƒœìŠ¤í¬ê°€ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ ê±´ë„ˆë›°ê¸°
            if not image_list:
                failed_count += 1
                continue
            
            # Instruction: OCR íƒœìŠ¤í¬
            instruction = "ì´ ë¬¸ì„œ í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”. ì´ë¯¸ì§€ì—ì„œ ë³´ì´ëŠ” ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì •í™•í•˜ê²Œ ì½ì–´ì£¼ì„¸ìš”."
            
            # Messages êµ¬ì„± (ì´ë¯¸ì§€ í•„ìˆ˜)
            messages = [
                {
                    "role": "user",
                    "content": [
                        {"type": "image"},
                        {"type": "text", "text": instruction}
                    ]
                },
                {
                    "role": "assistant",
                    "content": [{"type": "text", "text": natural_text.strip()}]
                }
            ]
            
            results.append({"messages": messages, "images": image_list})
            sample_count += 1
            
        except Exception as e:
            logger.debug(f"   âŒ olmOCR ìƒ˜í”Œ {idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            failed_count += 1
            continue
    
    logger.info(f"   âœ… olmOCR í”„ë¡œì„¸ì„œ ì™„ë£Œ: ì„±ê³µ {sample_count}ê°œ, ì‹¤íŒ¨ {failed_count}ê°œ")
    
    return results

def process_cord(dataset, dataset_name: str, max_samples: int, log_detail: bool = False) -> List[Dict[str, Any]]:
    """
    naver-clova-ix/cord-v2 ì „ìš© í”„ë¡œì„¸ì„œ (OCR, multimodal)
    
    ë°ì´í„° êµ¬ì¡° (ì›¹ì‚¬ì´íŠ¸ ì°¸ê³ ):
    - image: ì˜ìˆ˜ì¦ ì´ë¯¸ì§€ (DatasetImage íƒ€ì…)
    - ground_truth: OCRëœ í…ìŠ¤íŠ¸ (ground truth, JSON í˜•ì‹ì¼ ìˆ˜ ìˆìŒ)
    
    VLMìš© instruction: "ì´ ì˜ìˆ˜ì¦ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”"
    """
    results = []
    sample_count = 0
    failed_count = 0
    
    logger.debug(f"   ğŸ”§ CORD-v2 ì „ìš© í”„ë¡œì„¸ì„œ ì‹œì‘ (ìµœëŒ€ {max_samples}ê°œ ìƒ˜í”Œ)")
    
    for idx, sample in enumerate(dataset):
        if sample_count >= max_samples:
            break
        
        try:
            # OCRëœ í…ìŠ¤íŠ¸ (ground truth)
            ground_truth = sample.get("ground_truth", "")
            if not ground_truth or not str(ground_truth).strip():
                if log_detail and idx < 5:
                    logger.warning(f"   âš ï¸ CORD-v2 ìƒ˜í”Œ {idx}: ground_truthê°€ ë¹„ì–´ìˆìŒ")
                failed_count += 1
                continue
            
            # ground_truthê°€ JSON í˜•ì‹ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë¬¸ìì—´ë¡œ ë³€í™˜
            if isinstance(ground_truth, dict):
                import json
                ground_truth = json.dumps(ground_truth, ensure_ascii=False)
            else:
                ground_truth = str(ground_truth).strip()
            
            # ì´ë¯¸ì§€ ì²˜ë¦¬
            image_list = []
            
            # image í•„ë“œ í™•ì¸ (DatasetImage íƒ€ì…)
            if "image" in sample:
                img = sample["image"]
                if img is not None:
                    flattened_images = validate_image_data([img])
                    if flattened_images:
                        image_list = flattened_images
            
            # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ OCR íƒœìŠ¤í¬ê°€ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ ê±´ë„ˆë›°ê¸°
            if not image_list:
                failed_count += 1
                continue
            
            # Instruction: OCR íƒœìŠ¤í¬ (ì˜ìˆ˜ì¦ íŠ¹í™”)
            instruction = "ì´ ì˜ìˆ˜ì¦ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”. ì´ë¯¸ì§€ì—ì„œ ë³´ì´ëŠ” ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì •í™•í•˜ê²Œ ì½ì–´ì£¼ì„¸ìš”."
            
            # Messages êµ¬ì„± (ì´ë¯¸ì§€ í•„ìˆ˜)
            messages = [
                {
                    "role": "user",
                    "content": [
                        {"type": "image"},
                        {"type": "text", "text": instruction}
                    ]
                },
                {
                    "role": "assistant",
                    "content": [{"type": "text", "text": ground_truth}]
                }
            ]
            
            results.append({"messages": messages, "images": image_list})
            sample_count += 1
            
        except Exception as e:
            logger.debug(f"   âŒ CORD-v2 ìƒ˜í”Œ {idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            failed_count += 1
            continue
    
    logger.info(f"   âœ… CORD-v2 í”„ë¡œì„¸ì„œ ì™„ë£Œ: ì„±ê³µ {sample_count}ê°œ, ì‹¤íŒ¨ {failed_count}ê°œ")
    
    return results

def process_ask_science_qg(dataset, dataset_name: str, max_samples: int, log_detail: bool = False) -> List[Dict[str, Any]]:
    """
    dhmeltzer/ask-science-qg ì „ìš© í”„ë¡œì„¸ì„œ (Science Q&A, í…ìŠ¤íŠ¸ ì „ìš©)
    
    ë°ì´í„° êµ¬ì¡° (ì›¹ì‚¬ì´íŠ¸ ì°¸ê³ ):
    - title: ì§ˆë¬¸ ì œëª©
    - selftext: ì§ˆë¬¸ ë³¸ë¬¸ (ì„ íƒì , ë¹„ì–´ìˆì„ ìˆ˜ ìˆìŒ)
    - answers.text: ë‹µë³€ í…ìŠ¤íŠ¸ (sequence/ë¦¬ìŠ¤íŠ¸)
    - answers.score: ë‹µë³€ ì ìˆ˜ (sequence/ë¦¬ìŠ¤íŠ¸)
    
    VLMìš© instruction: title + selftextë¥¼ ì§ˆë¬¸ìœ¼ë¡œ, answers.textë¥¼ ë‹µë³€ìœ¼ë¡œ
    """
    results = []
    sample_count = 0
    failed_count = 0
    
    logger.debug(f"   ğŸ”§ ask-science-qg ì „ìš© í”„ë¡œì„¸ì„œ ì‹œì‘ (ìµœëŒ€ {max_samples}ê°œ ìƒ˜í”Œ)")
    
    # ì²˜ìŒ ëª‡ ê°œ ìƒ˜í”Œì˜ ì‹¤ì œ êµ¬ì¡°ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•œ ë””ë²„ê¹… (DEBUG ë ˆë²¨)
    debug_samples_checked = 0
    max_debug_samples = 3  # 10 -> 3ìœ¼ë¡œ ê°ì†Œ
    
    for idx, sample in enumerate(dataset):
        if sample_count >= max_samples:
            break
        
        try:
            # ì²˜ìŒ ëª‡ ê°œ ìƒ˜í”Œì˜ ì „ì²´ êµ¬ì¡° ë¡œê¹… (DEBUG ë ˆë²¨)
            if debug_samples_checked < max_debug_samples and log_detail:
                logger.debug(f"   ğŸ” ask-science-qg ìƒ˜í”Œ {idx} êµ¬ì¡°: keys={list(sample.keys())}")
                debug_samples_checked += 1
            
            # ì§ˆë¬¸ êµ¬ì„±: title + selftext
            title = sample.get("title", "")
            selftext = sample.get("selftext", "")
            
            # titleì€ í•„ìˆ˜
            if not title or not str(title).strip():
                failed_count += 1
                continue
            
            # ì§ˆë¬¸ í…ìŠ¤íŠ¸ êµ¬ì„±
            question_parts = [str(title).strip()]
            if selftext and str(selftext).strip():
                question_parts.append(str(selftext).strip())
            question = "\n\n".join(question_parts)
            
            # ë‹µë³€ ì¶”ì¶œ - ì›¹ì‚¬ì´íŠ¸ êµ¬ì¡°: answers.text (sequence), answers.score (sequence)
            # HuggingFace datasetsì—ì„œ sequenceëŠ” í‰íƒ„í™”ë  ìˆ˜ ìˆìŒ: answers.text -> ìµœìƒìœ„ ë ˆë²¨
            answer_text = ""
            
            # Case 1: answers.textê°€ í‰íƒ„í™”ë˜ì–´ ìµœìƒìœ„ ë ˆë²¨ì— ìˆëŠ” ê²½ìš°
            answer_texts = sample.get("answers.text", None)
            answer_scores = sample.get("answers.score", None)
            
            # Case 2: answersê°€ dictì´ê³  answers.textê°€ ìˆëŠ” ê²½ìš°
            if answer_texts is None:
                answers = sample.get("answers", {})
                if isinstance(answers, dict) and len(answers) > 0:
                    answer_texts = answers.get("text", None)
                    answer_scores = answers.get("score", None)
            
            # Case 3: answersê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
            if answer_texts is None:
                answers = sample.get("answers", {})
                if isinstance(answers, (list, tuple)) and len(answers) > 0:
                    first_answer = answers[0]
                    if isinstance(first_answer, dict):
                        answer_texts = first_answer.get("text", None)
                    else:
                        answer_texts = first_answer
            
            # Case 4: answersê°€ ì§ì ‘ ë¬¸ìì—´ì¸ ê²½ìš°
            if answer_texts is None:
                answers = sample.get("answers", "")
                if isinstance(answers, str):
                    answer_texts = answers
            
            # answer_texts ì²˜ë¦¬
            if answer_texts is not None:
                # sequenceë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ì´ë¯¸ ë¦¬ìŠ¤íŠ¸ì¼ ìˆ˜ë„ ìˆìŒ)
                if not isinstance(answer_texts, (list, tuple)):
                    # ë‹¨ì¼ ê°’ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    answer_texts = [answer_texts]
                
                if len(answer_texts) > 0:
                    # scoresê°€ ìˆê³  ê¸¸ì´ê°€ ê°™ìœ¼ë©´ ê°€ì¥ ë†’ì€ ì ìˆ˜ ì„ íƒ
                    if answer_scores is not None:
                        if not isinstance(answer_scores, (list, tuple)):
                            answer_scores = [answer_scores]
                        
                        if len(answer_scores) == len(answer_texts) and len(answer_scores) > 0:
                            try:
                                # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ë‹µë³€ ì„ íƒ
                                best_idx = max(range(len(answer_scores)), key=lambda i: answer_scores[i] if isinstance(answer_scores[i], (int, float)) else 0)
                                answer_text = str(answer_texts[best_idx]).strip()
                            except Exception as e:
                                # ì ìˆ˜ ì„ íƒ ì‹¤íŒ¨ ì‹œ ì²« ë²ˆì§¸ ë‹µë³€ ì‚¬ìš©
                                answer_text = str(answer_texts[0]).strip()
                        else:
                            # scores ê¸¸ì´ê°€ ë‹¤ë¥´ë©´ ì²« ë²ˆì§¸ ë‹µë³€ ì‚¬ìš©
                            answer_text = str(answer_texts[0]).strip()
                    else:
                        # scoresê°€ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ë‹µë³€ ì‚¬ìš©
                        answer_text = str(answer_texts[0]).strip()
            
            # ë‹µë³€ì´ ë¹„ì–´ìˆìœ¼ë©´ ê±´ë„ˆë›°ê¸°
            if not answer_text:
                failed_count += 1
                continue
            
            # Messages êµ¬ì„±
            messages = [
                {
                    "role": "user",
                    "content": [{"type": "text", "text": question}]
                },
                {
                    "role": "assistant",
                    "content": [{"type": "text", "text": answer_text}]
                }
            ]
            
            results.append({"messages": messages, "images": []})
            sample_count += 1
            
        except Exception as e:
            logger.debug(f"   âŒ ask-science-qg ìƒ˜í”Œ {idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            failed_count += 1
            continue
    
    logger.info(f"   âœ… ask-science-qg í”„ë¡œì„¸ì„œ ì™„ë£Œ: ì„±ê³µ {sample_count}ê°œ, ì‹¤íŒ¨ {failed_count}ê°œ")
    
    return results

def process_ocr_vqa(dataset, dataset_name: str, max_samples: int, log_detail: bool = False) -> List[Dict[str, Any]]:
    """
    howard-hou/OCR-VQA ì „ìš© í”„ë¡œì„¸ì„œ (OCR VQA, multimodal)
    
    ë°ì´í„° êµ¬ì¡° (ì›¹ì‚¬ì´íŠ¸ ì°¸ê³ ):
    - image: ì´ë¯¸ì§€ (DatasetImage íƒ€ì…)
    - questions: ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ (sequence)
    - answers: ë‹µë³€ ë¦¬ìŠ¤íŠ¸ (sequence)
    - ocr_tokens: OCR í† í° (sequence, ì„ íƒì )
    - ocr_info: OCR ì •ë³´ (list, ì„ íƒì )
    
    í•˜ë‚˜ì˜ ì´ë¯¸ì§€ì— ì—¬ëŸ¬ ì§ˆë¬¸-ë‹µë³€ ìŒì´ ìˆìœ¼ë¯€ë¡œ, ê° ìŒì„ ë³„ë„ ìƒ˜í”Œë¡œ ìƒì„±
    """
    results = []
    sample_count = 0
    failed_count = 0
    
    logger.debug(f"   ğŸ”§ OCR-VQA ì „ìš© í”„ë¡œì„¸ì„œ ì‹œì‘ (ìµœëŒ€ {max_samples}ê°œ ìƒ˜í”Œ)")
    
    debug_samples_checked = 0
    max_debug_samples = 2  # 5 -> 2ë¡œ ê°ì†Œ
    
    for idx, sample in enumerate(dataset):
        if sample_count >= max_samples:
            break
        
        try:
            # ì²˜ìŒ ëª‡ ê°œ ìƒ˜í”Œì˜ êµ¬ì¡° í™•ì¸ (DEBUG ë ˆë²¨)
            if debug_samples_checked < max_debug_samples and log_detail:
                logger.debug(f"   ğŸ” OCR-VQA ìƒ˜í”Œ {idx} êµ¬ì¡°: keys={list(sample.keys())}")
                debug_samples_checked += 1
            
            # ì´ë¯¸ì§€ ì²˜ë¦¬
            image = sample.get("image", None)
            if image is None:
                failed_count += 1
                continue
            
            # ì´ë¯¸ì§€ ê²€ì¦
            image_list = validate_image_data([image])
            if not image_list:
                failed_count += 1
                continue
            
            # questionsì™€ answers ì¶”ì¶œ
            questions = sample.get("questions", None)
            answers = sample.get("answers", None)
            
            # questionsì™€ answersê°€ ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸
            if not isinstance(questions, (list, tuple)) or not isinstance(answers, (list, tuple)):
                failed_count += 1
                continue
            
            if len(questions) == 0 or len(answers) == 0:
                failed_count += 1
                continue
            
            # ì§ˆë¬¸ê³¼ ë‹µë³€ì˜ ê°œìˆ˜ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ìµœì†Œ ê°œìˆ˜ë§Œí¼ë§Œ ì²˜ë¦¬
            num_pairs = min(len(questions), len(answers))
            
            # ê° ì§ˆë¬¸-ë‹µë³€ ìŒì„ ë³„ë„ ìƒ˜í”Œë¡œ ìƒì„±
            for qa_idx in range(num_pairs):
                if sample_count >= max_samples:
                    break
                
                question = str(questions[qa_idx]).strip()
                answer = str(answers[qa_idx]).strip()
                
                if not question or not answer:
                    continue
                
                # Messages êµ¬ì„±
                messages = [
                    {
                        "role": "user",
                        "content": [
                            {"type": "image"},
                            {"type": "text", "text": question}
                        ]
                    },
                    {
                        "role": "assistant",
                        "content": [{"type": "text", "text": answer}]
                    }
                ]
                
                results.append({"messages": messages, "images": image_list})
                sample_count += 1
            
        except Exception as e:
            logger.debug(f"   âŒ OCR-VQA ìƒ˜í”Œ {idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            failed_count += 1
            continue
    
    logger.info(f"   âœ… OCR-VQA í”„ë¡œì„¸ì„œ ì™„ë£Œ: ì„±ê³µ {sample_count}ê°œ ìƒ˜í”Œ ìƒì„±, ì‹¤íŒ¨ {failed_count}ê°œ ì›ë³¸ ìƒ˜í”Œ")
    
    return results

def process_generic_instruction(dataset, dataset_name: str, max_samples: int, log_detail: bool = False) -> List[Dict[str, Any]]:
    """
    ë²”ìš© instruction-output í˜•ì‹ í”„ë¡œì„¸ì„œ
    """
    results = []
    sample_count = 0
    failed_count = 0
    
    logger.debug(f"   ğŸ”§ ë²”ìš© Instruction í”„ë¡œì„¸ì„œ ì‹œì‘ ({dataset_name}, ìµœëŒ€ {max_samples}ê°œ ìƒ˜í”Œ)")
    
    for idx, sample in enumerate(dataset):
        if sample_count >= max_samples:
            break
        
        try:
            # messages í˜•ì‹ì´ ì´ë¯¸ ìˆëŠ” ê²½ìš°
            if "messages" in sample:
                messages = validate_messages(sample["messages"])
                images = sample.get("images", [])
                results.append({"messages": messages, "images": images if images else []})
                sample_count += 1
                continue
            
            # conversations í˜•ì‹
            if "conversations" in sample:
                conversations = sample["conversations"]
                messages = []
                for conv in conversations:
                    role = conv.get("from", conv.get("role", ""))
                    value = conv.get("value", conv.get("content", ""))
                    
                    if role in ["human", "user"]:
                        messages.append({"role": "user", "content": [{"type": "text", "text": value}]})
                    elif role in ["gpt", "assistant"]:
                        messages.append({"role": "assistant", "content": [{"type": "text", "text": value}]})
                
                if messages:
                    results.append({"messages": messages, "images": []})
                    sample_count += 1
                    continue
            
            # instruction-output í˜•ì‹
            if "instruction" in sample:
                instruction = sample.get("instruction", "")
                output = sample.get("output", sample.get("response", ""))
                
                if instruction and output:
                    messages = [
                        {"role": "user", "content": [{"type": "text", "text": instruction}]},
                        {"role": "assistant", "content": [{"type": "text", "text": output}]}
                    ]
                    results.append({"messages": messages, "images": []})
                    sample_count += 1
                    continue
            
            # question-answer í˜•ì‹
            if "question" in sample:
                question = sample.get("question", "")
                answer = sample.get("answer", sample.get("response", ""))
                
                if question and answer:
                    messages = [
                        {"role": "user", "content": [{"type": "text", "text": question}]},
                        {"role": "assistant", "content": [{"type": "text", "text": answer}]}
                    ]
                    results.append({"messages": messages, "images": []})
                    sample_count += 1
                    continue
            
            # ë³€í™˜ ì‹¤íŒ¨
            failed_count += 1
            
        except Exception as e:
            logger.warning(f"   âŒ ë²”ìš© í”„ë¡œì„¸ì„œ ìƒ˜í”Œ {idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            failed_count += 1
            continue
    
    logger.info(f"   âœ… ë²”ìš© í”„ë¡œì„¸ì„œ ì™„ë£Œ: ì„±ê³µ {sample_count}ê°œ, ì‹¤íŒ¨ {failed_count}ê°œ")
    return results

# ë°ì´í„°ì…‹ë³„ í”„ë¡œì„¸ì„œ ë§¤í•‘
DATASET_PROCESSORS = {
    "microsoft/rStar-Coder": process_rstar_coder,
    "meta-math/MetaMathQA": process_metamath,
    "sdiazlor/math-python-reasoning-dataset": process_math_python_reasoning,
    "lmms-lab/LLaVA-OneVision-Data": process_llava_onevision,
    "allenai/olmOCR-mix-1025": process_olmocr,
    "naver-clova-ix/cord-v2": process_cord,
    "dhmeltzer/ask-science-qg": process_ask_science_qg,
    "howard-hou/OCR-VQA": process_ocr_vqa,
}

def get_processor_for_dataset(dataset_name: str):
    """
    ë°ì´í„°ì…‹ ì´ë¦„ì— ë”°ë¼ ì ì ˆí•œ í”„ë¡œì„¸ì„œ ë°˜í™˜
    """
    # ì •í™•í•œ ì´ë¦„ ë§¤ì¹­
    if dataset_name in DATASET_PROCESSORS:
        return DATASET_PROCESSORS[dataset_name]
    
    # ë¶€ë¶„ ë§¤ì¹­ (ì†Œë¬¸ì ë³€í™˜)
    dataset_name_lower = dataset_name.lower()
    for key, processor in DATASET_PROCESSORS.items():
        if key.lower() in dataset_name_lower:
            return processor
    
    # ê¸°ë³¸ í”„ë¡œì„¸ì„œ
    return process_generic_instruction


# ============================================================
# í•˜ìœ„ í˜¸í™˜ì„±: ê¸°ì¡´ convert_sample_to_messages í•¨ìˆ˜ (deprecated)
# ============================================================

def convert_sample_to_messages(sample: Dict[str, Any], dataset_name: str, log_failure: bool = False) -> Optional[Dict[str, Any]]:
    """
    ìƒ˜í”Œì„ messages í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (í•˜ìœ„ í˜¸í™˜ì„±ìš© - deprecated)
    
    ì´ í•¨ìˆ˜ëŠ” í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ë‚¨ê²¨ë‘¡ë‹ˆë‹¤.
    ìƒˆë¡œìš´ ì½”ë“œì—ì„œëŠ” ë°ì´í„°ì…‹ë³„ í”„ë¡œì„¸ì„œë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì„¸ìš”.
    
    Args:
        sample: ë³€í™˜í•  ìƒ˜í”Œ
        dataset_name: ë°ì´í„°ì…‹ ì´ë¦„
        log_failure: ë³€í™˜ ì‹¤íŒ¨ ì‹œ ë¡œê·¸ë¥¼ ë‚¨ê¸¸ì§€ ì—¬ë¶€
    """
    # rStar-Coder í˜•ì‹ ì²˜ë¦¬ (ê°€ì¥ ë¨¼ì € ì²´í¬ - êµ¬ì²´ì ì¸ ë°ì´í„°ì…‹)
    if "rstar-coder" in dataset_name.lower() or "rstar_coder" in dataset_name.lower():
        # ì‹¤ì œ keys í™•ì¸ ë° ì²˜ë¦¬
        sample_keys = list(sample.keys()) if isinstance(sample, dict) else []
        
        # rStar-Coderì˜ ì‹¤ì œ ì»¬ëŸ¼: question, seed_question, seed_source, response, code
        question = sample.get("question", "")
        seed_question = sample.get("seed_question", "")
        seed_source = sample.get("seed_source", "")
        response = sample.get("response", "")
        code = sample.get("code", "")
        
        # ë””ë²„ê¹…: ì²˜ìŒ ëª‡ ê°œ ìƒ˜í”Œì˜ keys ë¡œê¹…
        if log_failure:
            logger.info(f"   ğŸ” rStar-Coder ìƒ˜í”Œ keys: {sample_keys}")
            logger.info(f"   ğŸ” question: {bool(question)}, seed_question: {bool(seed_question)}, response: {bool(response)}, code: {bool(code)}")
            if question:
                logger.info(f"   ğŸ” question preview: {question[:100]}")
            if seed_question:
                logger.info(f"   ğŸ” seed_question preview: {seed_question[:100]}")
            if response:
                logger.info(f"   ğŸ” response preview: {response[:100]}")
            if code:
                logger.info(f"   ğŸ” code preview: {code[:100]}")
        
        # question ë˜ëŠ” seed_question ì¤‘ í•˜ë‚˜ëŠ” ìˆì–´ì•¼ í•¨
        user_prompt = question.strip() if question and question.strip() else (seed_question.strip() if seed_question and seed_question.strip() else "")
        if not user_prompt:
            if log_failure:
                logger.warning(f"   âš ï¸ rStar-Coder: questionê³¼ seed_questionì´ ëª¨ë‘ ë¹„ì–´ìˆìŒ. keys: {sample_keys}")
            return None
        
        # responseì™€ code ì¤‘ í•˜ë‚˜ëŠ” ìˆì–´ì•¼ í•¨
        assistant_content_parts = []
        if response and response.strip():
            assistant_content_parts.append(response.strip())
        if code and code.strip():
            if assistant_content_parts:
                assistant_content_parts.append(f"\n\n```python\n{code.strip()}\n```")
            else:
                assistant_content_parts.append(code.strip())
        
        if not assistant_content_parts:
            if log_failure:
                logger.warning(f"   âš ï¸ rStar-Coder: responseì™€ codeê°€ ëª¨ë‘ ë¹„ì–´ìˆìŒ. keys: {sample_keys}")
            return None
        
        assistant_text = "\n".join(assistant_content_parts)
        
        messages = [
            {"role": "user", "content": [{"type": "text", "text": user_prompt}]},
            {"role": "assistant", "content": [{"type": "text", "text": assistant_text}]}
        ]
        return {"messages": messages, "images": []}
    
    # ask-science-qg í˜•ì‹ ì²˜ë¦¬ (answers.text ì‚¬ìš©)
    if "ask-science-qg" in dataset_name.lower():
        question = sample.get("question", "")
        answers = sample.get("answers", {})
        
        # answers.text í•„ë“œ ì¶”ì¶œ (ìˆ«ìì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë¬¸ìì—´ë¡œ ë³€í™˜)
        if isinstance(answers, dict):
            answer_text = answers.get("text", "")
        elif isinstance(answers, list) and len(answers) > 0:
            # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²« ë²ˆì§¸ í•­ëª©ì˜ text ì‚¬ìš©
            if isinstance(answers[0], dict):
                answer_text = answers[0].get("text", "")
            else:
                answer_text = str(answers[0]) if answers[0] else ""
        else:
            answer_text = ""
        
        # ë¬¸ìì—´ë¡œ ë³€í™˜ ë³´ì¥
        question = ensure_string(question)
        answer_text = ensure_string(answer_text)
        
        if not question or not answer_text:
            if log_failure:
                sample_keys_str = list(sample.keys()) if isinstance(sample, dict) else 'N/A'
                logger.debug(f"[{dataset_name}] ask-science-qg: ë¹ˆ ì§ˆë¬¸ ë˜ëŠ” ë‹µë³€ - question: {bool(question)}, answer: {bool(answer_text)}, sample_keys: {sample_keys_str}")
            return None
        
        messages = [
            {"role": "user", "content": [{"type": "text", "text": question}]},
            {"role": "assistant", "content": [{"type": "text", "text": answer_text}]}
        ]
        
        # í…ìŠ¤íŠ¸ í•„ë“œ ë¬¸ìì—´ ë³´ì¥
        messages = ensure_messages_text_strings(messages)
        
        return {"messages": messages, "images": []}
    
    # ScienceQA í˜•ì‹ ì²˜ë¦¬
    if "ScienceQA" in dataset_name or "scienceqa" in dataset_name.lower():
        question = sample.get("question", "")
        choices = sample.get("choices", [])
        answer = sample.get("answer", "")
        explanation = sample.get("explanation", "")
        
        # ì§ˆë¬¸ê³¼ ì„ íƒì§€ êµ¬ì„±
        question_text = question
        if choices:
            choices_text = "\n".join([f"{chr(65+i)}. {choice}" for i, choice in enumerate(choices)])
            question_text = f"{question}\n\n{choices_text}"
        
        # ë‹µë³€ êµ¬ì„±
        answer_text = answer
        if explanation:
            answer_text = f"{answer}\n\nExplanation: {explanation}"
        
        # ì´ë¯¸ì§€ ì²˜ë¦¬
        img = sample.get("image", [])
        if not isinstance(img, list):
            img = [img] if img is not None else []
        img = validate_image_data(img)
        
        # ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ë©€í‹°ëª¨ë‹¬, ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ì „ìš©
        if img:
            messages = [
                {"role": "user", "content": [{"type": "image"}, {"type": "text", "text": question_text}]},
                {"role": "assistant", "content": [{"type": "text", "text": answer_text}]}
            ]
        else:
            messages = [
                {"role": "user", "content": [{"type": "text", "text": question_text}]},
                {"role": "assistant", "content": [{"type": "text", "text": answer_text}]}
            ]
        
        return {"messages": messages, "images": img if img else []}
    
    # LLaVA-OneVision-Data í˜•ì‹ ì²˜ë¦¬
    if "llava-onevision" in dataset_name.lower() or "onevision" in dataset_name.lower():
        # LLaVA í˜•ì‹: conversations ë˜ëŠ” messages í•„ë“œ ì‚¬ìš©
        if "conversations" in sample:
            messages = []
            img = sample.get("image", [])
            if not isinstance(img, list):
                img = [img] if img is not None else []
            img = validate_image_data(img)
            
            first_user = True
            for conv in sample["conversations"]:
                if isinstance(conv, dict):
                    role = conv.get("from", "").lower()
                    value = conv.get("value", "")
                    
                    if role in ["human", "user"]:
                        content = []
                        if first_user and img:
                            content.append({"type": "image"})
                            first_user = False
                        if value:
                            content.append({"type": "text", "text": str(value)})
                        if content:
                            messages.append({"role": "user", "content": content})
                    elif role in ["gpt", "assistant"]:
                        if value:
                            messages.append({"role": "assistant", "content": [{"type": "text", "text": str(value)}]})
            
            if messages and img:
                return {"messages": messages, "images": img}
            elif messages:
                # ì´ë¯¸ì§€ê°€ ì—†ì–´ë„ ì²˜ë¦¬
                return {"messages": messages, "images": []}
        
        # messages í˜•ì‹ ì§ì ‘ ì§€ì›
        if "messages" in sample and isinstance(sample["messages"], list):
            img = sample.get("image", [])
            if not isinstance(img, list):
                img = [img] if img is not None else []
            img = validate_image_data(img)
            
            messages = validate_messages(sample["messages"])
            return {"messages": messages, "images": img if img else []}
        
        # instruction-output í˜•ì‹
        if "instruction" in sample and "output" in sample:
            img = sample.get("image", [])
            if not isinstance(img, list):
                img = [img] if img is not None else []
            img = validate_image_data(img)
            
            if img:
                messages = [
                    {"role": "user", "content": [{"type": "image"}, {"type": "text", "text": sample["instruction"]}]},
                    {"role": "assistant", "content": [{"type": "text", "text": sample["output"]}]}
                ]
            else:
                messages = [
                    {"role": "user", "content": [{"type": "text", "text": sample["instruction"]}]},
                    {"role": "assistant", "content": [{"type": "text", "text": sample["output"]}]}
                ]
            
            return {"messages": messages, "images": img if img else []}
    
    # VQA í˜•ì‹ ì²˜ë¦¬ (VQAv2) - í•˜ìœ„ í˜¸í™˜ì„±
    if "VQA" in dataset_name or "vqa" in dataset_name.lower():
        question = sample.get("question", "")
        answers = sample.get("answers", [])
        if isinstance(answers, list) and len(answers) > 0:
            if isinstance(answers[0], dict):
                answer = answers[0].get("answer", "")
            else:
                answer = str(answers[0])
        else:
            answer = sample.get("answer", "")
        
        messages = [
            {"role": "user", "content": [{"type": "image"}, {"type": "text", "text": question}]},
            {"role": "assistant", "content": [{"type": "text", "text": answer}]}
        ]
        
        img = sample.get("image", [])
        if not isinstance(img, list):
            img = [img] if img is not None else []
        img = validate_image_data(img)
        if not img:
            return None
        
        return {"messages": messages, "images": img}
    
    # Flickr30k í˜•ì‹ ì²˜ë¦¬ - í•˜ìœ„ í˜¸í™˜ì„±
    if "flickr30k" in dataset_name.lower():
        captions = sample.get("caption", [])
        if not isinstance(captions, list):
            captions = [captions] if captions else []
        
        if not captions:
            return None
        
        caption = str(captions[0])
        
        messages = [
            {"role": "user", "content": [{"type": "image"}, {"type": "text", "text": "Describe this image."}]},
            {"role": "assistant", "content": [{"type": "text", "text": caption}]}
        ]
        
        img = sample.get("image", [])
        if not isinstance(img, list):
            img = [img] if img is not None else []
        img = validate_image_data(img)
        if not img:
            return None
        
        return {"messages": messages, "images": img}
    
    # CORD (OCR) í˜•ì‹ ì²˜ë¦¬
    if "cord" in dataset_name.lower():
        # CORDëŠ” ë¬¸ì„œ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨
        text = sample.get("text", "")
        if not text:
            return None
        
        messages = [
            {"role": "user", "content": [{"type": "image"}, {"type": "text", "text": "Extract and read the text from this document."}]},
            {"role": "assistant", "content": [{"type": "text", "text": text}]}
        ]
        
        img = sample.get("image", [])
        if not isinstance(img, list):
            img = [img] if img is not None else []
        img = validate_image_data(img)
        if not img:
            return None
        
        return {"messages": messages, "images": img}
    
    # FUNSD (OCR) í˜•ì‹ ì²˜ë¦¬
    if "funsd" in dataset_name.lower() or "layoutlmv3" in dataset_name.lower():
        words = sample.get("words", [])
        bboxes = sample.get("bboxes", [])
        
        # ë‹¨ì–´ë“¤ì„ í…ìŠ¤íŠ¸ë¡œ ê²°í•©
        text = " ".join([str(word) for word in words]) if words else ""
        if not text:
            return None
        
        messages = [
            {"role": "user", "content": [{"type": "image"}, {"type": "text", "text": "Extract and read the text from this document."}]},
            {"role": "assistant", "content": [{"type": "text", "text": text}]}
        ]
        
        img = sample.get("image", [])
        if not isinstance(img, list):
            img = [img] if img is not None else []
        img = validate_image_data(img)
        if not img:
            return None
        
        return {"messages": messages, "images": img}
    
    # SciAlpaca / Camel-AI Science í˜•ì‹ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì „ìš©)
    if "scialpaca" in dataset_name.lower() or "camel-ai/science" in dataset_name.lower():
        # ë‘ ë°ì´í„°ì…‹ ëª¨ë‘ instruction-output í˜•ì‹ì„ ë”°ë¦„
        instruction = sample.get("instruction", "")
        output = sample.get("output", "")
        
        # Camel-AI ScienceëŠ” message_1, message_2 í˜•ì‹ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ
        if not instruction and "message_1" in sample and "message_2" in sample:
            instruction = sample["message_1"]
            output = sample["message_2"]

        if not instruction or not output:
            return None
        
        messages = [
            {"role": "user", "content": [{"type": "text", "text": instruction}]},
            {"role": "assistant", "content": [{"type": "text", "text": output}]}
        ]
        return {"messages": messages, "images": []}

    # SciTLDR í˜•ì‹ ì²˜ë¦¬
    if "scitldr" in dataset_name.lower():
        # source (abstract) -> target (summary)
        source_text = " ".join(sample.get("source", []))
        target_text = " ".join(sample.get("target", []))
        
        if not source_text or not target_text:
            return None

        instruction = f"Summarize the following scientific text in one or two sentences:\n\n{source_text}"
        
        messages = [
            {"role": "user", "content": [{"type": "text", "text": instruction}]},
            {"role": "assistant", "content": [{"type": "text", "text": target_text}]}
        ]
        return {"messages": messages, "images": []}

    # SROIE (OCR) í˜•ì‹ ì²˜ë¦¬
    if "sroie" in dataset_name.lower():
        text = sample.get("text", "")
        if not text:
            return None
        
        messages = [
            {"role": "user", "content": [{"type": "image"}, {"type": "text", "text": "Extract and read the text from this document."}]},
            {"role": "assistant", "content": [{"type": "text", "text": text}]}
        ]
        
        img = sample.get("image", [])
        if not isinstance(img, list):
            img = [img] if img is not None else []
        img = validate_image_data(img)
        if not img:
            return None
        
        return {"messages": messages, "images": img}
    
    # Evol-CodeAlpaca í˜•ì‹ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì „ìš©)
    if "evol-codealpaca" in dataset_name.lower():
        instruction = sample.get("instruction", "")
        output = sample.get("output", "")
        _input = sample.get("input", "")
        if not instruction or not output:
            return None
        user_text = instruction if not _input else f"{instruction}\n\nInput:\n{_input}"
        messages = [
            {"role": "user", "content": [{"type": "text", "text": user_text}]},
            {"role": "assistant", "content": [{"type": "text", "text": output}]}
        ]
        return {"messages": messages, "images": []}
    
    # OCR-VQA ê³„ì—´ (í•˜ìœ„ í˜¸í™˜ì„±ìš© - ì‹¤ì œë¡œëŠ” process_ocr_vqa ì‚¬ìš©)
    if "ocr-vqa" in dataset_name.lower() or "ocrvqa" in dataset_name.lower():
        # OCR-VQAëŠ” questions (ë³µìˆ˜, ë¦¬ìŠ¤íŠ¸)ì™€ answers (ë³µìˆ˜, ë¦¬ìŠ¤íŠ¸)ë¥¼ ì‚¬ìš©
        # í•˜ë‚˜ì˜ ì´ë¯¸ì§€ì— ì—¬ëŸ¬ ì§ˆë¬¸-ë‹µë³€ ìŒì´ ìˆìœ¼ë¯€ë¡œ ì²« ë²ˆì§¸ ìŒë§Œ ì‚¬ìš© (í•˜ìœ„ í˜¸í™˜ì„±)
        questions = sample.get("questions", [])
        answers = sample.get("answers", [])
        
        # questions/answersê°€ ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸
        if not isinstance(questions, (list, tuple)) or not isinstance(answers, (list, tuple)):
            return None
        
        if len(questions) == 0 or len(answers) == 0:
            return None
        
        # ì²« ë²ˆì§¸ ì§ˆë¬¸-ë‹µë³€ ìŒ ì‚¬ìš©
        question = str(questions[0]).strip()
        answer = str(answers[0]).strip()
        
        if not question or not answer:
            return None
        
        messages = [
            {"role": "user", "content": [{"type": "image"}, {"type": "text", "text": question}]},
            {"role": "assistant", "content": [{"type": "text", "text": answer}]}
        ]
        
        img = sample.get("image", None)
        if img is None:
            return None
        
        img_list = validate_image_data([img])
        if not img_list:
            return None
        
        return {"messages": messages, "images": img_list}
    
    # MetaMathQA í˜•ì‹ ì²˜ë¦¬ (í•™ìŠµìš© ìˆ˜í•™ instruction)
    if "metamathqa" in dataset_name.lower() or "meta-math" in dataset_name.lower():
        query = sample.get("query", "")
        response = sample.get("response", "")
        if not query or not response:
            return None
        
        messages = [
            {"role": "user", "content": [{"type": "text", "text": query}]},
            {"role": "assistant", "content": [{"type": "text", "text": response}]}
        ]
        return {"messages": messages, "images": []}
    
    # Math-Python-Reasoning í˜•ì‹ ì²˜ë¦¬ (í•™ìŠµìš© ìˆ˜í•™ Python ì¶”ë¡ )
    if "math-python-reasoning" in dataset_name.lower():
        # prompt/completion/system_prompt í˜•ì‹ ì§€ì›
        prompt = sample.get("prompt", "")
        completion = sample.get("completion", "")
        system_prompt = sample.get("system_prompt", "")
        
        # instruction/output í˜•ì‹ë„ ì§€ì› (í•˜ìœ„ í˜¸í™˜ì„±)
        if not prompt:
            prompt = sample.get("instruction", "")
        if not completion:
            completion = sample.get("output", "")
        
        if not prompt or not completion:
            return None
        
        messages = []
        
        # system_promptê°€ ìˆìœ¼ë©´ system ë©”ì‹œì§€ë¡œ ì¶”ê°€
        if system_prompt:
            messages.append({"role": "system", "content": [{"type": "text", "text": system_prompt}]})
        
        messages.extend([
            {"role": "user", "content": [{"type": "text", "text": prompt}]},
            {"role": "assistant", "content": [{"type": "text", "text": completion}]}
        ])
        
        return {"messages": messages, "images": []}
    
    # UltraInteract í˜•ì‹ ì²˜ë¦¬ (í•™ìŠµìš© ë…¼ë¦¬ ì¶”ë¡  instruction)
    if "ultrainteract" in dataset_name.lower() or "ultra-interact" in dataset_name.lower():
        # UltraInteractëŠ” ë‹¤ì–‘í•œ í˜•ì‹ì´ ìˆì„ ìˆ˜ ìˆìŒ
        if "messages" in sample:
            messages = validate_messages(sample["messages"])
            return {"messages": messages, "images": []}
        elif "instruction" in sample and "output" in sample:
            messages = [
                {"role": "user", "content": [{"type": "text", "text": sample["instruction"]}]},
                {"role": "assistant", "content": [{"type": "text", "text": sample["output"]}]}
            ]
            return {"messages": messages, "images": []}
        elif "question" in sample and "answer" in sample:
            messages = [
                {"role": "user", "content": [{"type": "text", "text": sample["question"]}]},
                {"role": "assistant", "content": [{"type": "text", "text": sample["answer"]}]}
            ]
            return {"messages": messages, "images": []}
    
    # UltraFeedback í˜•ì‹ ì²˜ë¦¬ (í•™ìŠµìš© ì¶”ë¡  instruction)
    if "ultrafeedback" in dataset_name.lower():
        # UltraFeedbackì€ ë‹¤ì–‘í•œ í˜•ì‹ì´ ìˆì„ ìˆ˜ ìˆìŒ
        if "messages" in sample:
            messages = validate_messages(sample["messages"])
            return {"messages": messages, "images": []}
        elif "instruction" in sample and "output" in sample:
            messages = [
                {"role": "user", "content": [{"type": "text", "text": sample["instruction"]}]},
                {"role": "assistant", "content": [{"type": "text", "text": sample["output"]}]}
            ]
            return {"messages": messages, "images": []}
        elif "prompt" in sample and "response" in sample:
            messages = [
                {"role": "user", "content": [{"type": "text", "text": sample["prompt"]}]},
                {"role": "assistant", "content": [{"type": "text", "text": sample["response"]}]}
            ]
            return {"messages": messages, "images": []}
    
    # GSM8K í˜•ì‹ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì „ìš©) - ë²¤ì¹˜ë§ˆí¬ìš©, í•˜ìœ„ í˜¸í™˜ì„±
    if "gsm8k" in dataset_name.lower():
        question = sample.get("question", "")
        answer = sample.get("answer", "")
        if not question or not answer:
            return None
        
        messages = [
            {"role": "user", "content": [{"type": "text", "text": question}]},
            {"role": "assistant", "content": [{"type": "text", "text": answer}]}
        ]
        return {"messages": messages, "images": []}
    
    # MATH í˜•ì‹ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì „ìš©) - ë²¤ì¹˜ë§ˆí¬ìš©, í•˜ìœ„ í˜¸í™˜ì„±
    if "competition_math" in dataset_name.lower() or "hendrycks/math" in dataset_name.lower():
        problem = sample.get("problem", "")
        solution = sample.get("solution", "")
        if not problem or not solution:
            return None
        
        messages = [
            {"role": "user", "content": [{"type": "text", "text": problem}]},
            {"role": "assistant", "content": [{"type": "text", "text": solution}]}
        ]
        return {"messages": messages, "images": []}
    
    # PubMedQA í˜•ì‹ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì „ìš©) - ì œê±°ë¨, í•˜ìœ„ í˜¸í™˜ì„±
    if "pubmed_qa" in dataset_name.lower():
        question = sample.get("question", "")
        long_answer = sample.get("long_answer", "")
        final_decision = sample.get("final_decision", "")
        
        if not question:
            return None
        
        answer_text = long_answer if long_answer else final_decision
        if not answer_text:
            return None
        
        messages = [
            {"role": "user", "content": [{"type": "text", "text": question}]},
            {"role": "assistant", "content": [{"type": "text", "text": answer_text}]}
        ]
        return {"messages": messages, "images": []}
    
    # CodeSearchNet í˜•ì‹ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì „ìš©)
    if "code_search_net" in dataset_name.lower() or "codesearchnet" in dataset_name.lower():
        code = sample.get("code", "")
        docstring = sample.get("docstring", "")
        func_name = sample.get("func_name", "")
        
        if not code:
            return None
        
        # ì½”ë“œì™€ ì„¤ëª…ì„ instruction-output í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        instruction = f"Write code for: {docstring}" if docstring else f"Write code for function: {func_name}" if func_name else "Write the following code:"
        
        messages = [
            {"role": "user", "content": [{"type": "text", "text": instruction}]},
            {"role": "assistant", "content": [{"type": "text", "text": code}]}
        ]
        return {"messages": messages, "images": []}
    
    # CoNaLa í˜•ì‹ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì „ìš©)
    if "conala" in dataset_name.lower():
        intent = sample.get("intent", "")
        snippet = sample.get("snippet", "")
        
        if not intent or not snippet:
            return None
        
        messages = [
            {"role": "user", "content": [{"type": "text", "text": intent}]},
            {"role": "assistant", "content": [{"type": "text", "text": snippet}]}
        ]
        return {"messages": messages, "images": []}
    
    # rStar-Coder í˜•ì‹ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì „ìš©)
    if "rstar-coder" in dataset_name.lower() or "rstar_coder" in dataset_name.lower():
        # ì‹¤ì œ keys í™•ì¸ ë° ì²˜ë¦¬
        sample_keys = list(sample.keys()) if isinstance(sample, dict) else []
        
        # rStar-Coderì˜ ì‹¤ì œ ì»¬ëŸ¼: question, seed_question, seed_source, response, code
        question = sample.get("question", "")
        seed_question = sample.get("seed_question", "")
        seed_source = sample.get("seed_source", "")
        response = sample.get("response", "")
        code = sample.get("code", "")
        
        # ë””ë²„ê¹…: ì²˜ìŒ ëª‡ ê°œ ìƒ˜í”Œì˜ keys ë¡œê¹…
        if log_failure:
            logger.debug(f"   ğŸ” rStar-Coder ìƒ˜í”Œ keys: {sample_keys}")
            logger.debug(f"   ğŸ” question: {bool(question)}, seed_question: {bool(seed_question)}, response: {bool(response)}, code: {bool(code)}")
        
        # question ë˜ëŠ” seed_question ì¤‘ í•˜ë‚˜ëŠ” ìˆì–´ì•¼ í•¨
        user_prompt = question if question else seed_question
        if not user_prompt:
            if log_failure:
                logger.warning(f"   âš ï¸ rStar-Coder: questionê³¼ seed_questionì´ ëª¨ë‘ ë¹„ì–´ìˆìŒ. keys: {sample_keys}")
            return None
        
        # responseì™€ code ì¤‘ í•˜ë‚˜ëŠ” ìˆì–´ì•¼ í•¨
        assistant_content_parts = []
        if response and response.strip():
            assistant_content_parts.append(response.strip())
        if code and code.strip():
            if assistant_content_parts:
                assistant_content_parts.append(f"\n\n```python\n{code.strip()}\n```")
            else:
                assistant_content_parts.append(code.strip())
        
        if not assistant_content_parts:
            if log_failure:
                logger.warning(f"   âš ï¸ rStar-Coder: responseì™€ codeê°€ ëª¨ë‘ ë¹„ì–´ìˆìŒ. keys: {sample_keys}")
            return None
        
        assistant_text = "\n".join(assistant_content_parts)
        
        messages = [
            {"role": "user", "content": [{"type": "text", "text": user_prompt}]},
            {"role": "assistant", "content": [{"type": "text", "text": assistant_text}]}
        ]
        return {"messages": messages, "images": []}
    
    # The Stack / StarCoderData í˜•ì‹ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì „ìš©) - í•˜ìœ„ í˜¸í™˜ì„±
    if "the-stack" in dataset_name.lower() or "starcoderdata" in dataset_name.lower():
        content = sample.get("content", "")
        if not content:
            return None
        
        # ì½”ë“œ ë°ì´í„°ì…‹ì€ instruction-output í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        messages = [
            {"role": "user", "content": [{"type": "text", "text": "Write the following code:"}]},
            {"role": "assistant", "content": [{"type": "text", "text": content}]}
        ]
        return {"messages": messages, "images": []}
    
    # LogiQA í˜•ì‹ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì „ìš©) - ë²¤ì¹˜ë§ˆí¬ìš©, í•˜ìœ„ í˜¸í™˜ì„±
    if "logiqa" in dataset_name.lower():
        question = sample.get("question", "")
        options = sample.get("options", [])
        answer = sample.get("answer", "")
        
        if not question or not answer:
            return None
        
        question_text = question
        if options:
            options_text = "\n".join([f"{chr(65+i)}. {opt}" for i, opt in enumerate(options)])
            question_text = f"{question}\n\n{options_text}"
        
        messages = [
            {"role": "user", "content": [{"type": "text", "text": question_text}]},
            {"role": "assistant", "content": [{"type": "text", "text": answer}]}
        ]
        return {"messages": messages, "images": []}
    
    # ReClor í˜•ì‹ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì „ìš©) - ë²¤ì¹˜ë§ˆí¬ìš©, í•˜ìœ„ í˜¸í™˜ì„±
    if "reclor" in dataset_name.lower():
        question = sample.get("question", "")
        answers = sample.get("answers", [])
        label = sample.get("label", -1)
        
        if not question:
            return None
        
        question_text = question
        if answers and isinstance(answers, list):
            options_text = "\n".join([f"{chr(65+i)}. {ans}" for i, ans in enumerate(answers)])
            question_text = f"{question}\n\n{options_text}"
        
        answer_text = answers[label] if label >= 0 and label < len(answers) else (answers[0] if answers else "")
        if not answer_text:
            return None
        
        messages = [
            {"role": "user", "content": [{"type": "text", "text": question_text}]},
            {"role": "assistant", "content": [{"type": "text", "text": answer_text}]}
        ]
        return {"messages": messages, "images": []}
    
    # OpenOrca í˜•ì‹ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì „ìš©)
    if "openorca" in dataset_name.lower() or "open-orca" in dataset_name.lower():
        # OpenOrcaëŠ” conversations í˜•ì‹ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
        if "conversations" in sample:
            messages = []
            for conv in sample["conversations"]:
                if isinstance(conv, dict):
                    role = conv.get("from", "user")
                    value = conv.get("value", "")
                    if value:
                        role_mapped = "user" if role in ["human", "user"] else "assistant"
                        messages.append({
                            "role": role_mapped,
                            "content": [{"type": "text", "text": value}]
                        })
            if messages:
                return {"messages": messages, "images": []}
        
        # instruction-output í˜•ì‹
        if "instruction" in sample and "response" in sample:
            messages = [
                {"role": "user", "content": [{"type": "text", "text": sample["instruction"]}]},
                {"role": "assistant", "content": [{"type": "text", "text": sample["response"]}]}
            ]
            return {"messages": messages, "images": []}
    
    # smoltalk ë°ì´í„°ì…‹ ì²˜ë¦¬
    if "smoltalk" in dataset_name.lower():
        if "messages" in sample and isinstance(sample["messages"], list):
            # messagesê°€ ì´ë¯¸ ì˜¬ë°”ë¥¸ í˜•ì‹ì¸ ê²½ìš°
            messages = validate_messages(sample["messages"])
            # content í•„ë“œ ì •ê·œí™”
            messages = ensure_messages_text_strings(messages)
            img = sample.get("image", [])
            if not isinstance(img, list):
                img = [img] if img is not None else []
            img = validate_image_data(img)
            # smoltalkì€ ì´ë¯¸ì§€ê°€ ì—†ì–´ë„ í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œ ì²˜ë¦¬ ê°€ëŠ¥
            return {"messages": messages, "images": img if img else []}
    
    # simple_sft_datasetì˜ ê¸°ë³¸ ë³€í™˜ ë¡œì§ ì‚¬ìš©
    from data.simple_sft_dataset import convert_sample_to_messages as base_convert
    result = base_convert(sample, dataset_name)
    
    # base_convertê°€ Noneì„ ë°˜í™˜í•˜ê±°ë‚˜ ì´ë¯¸ì§€ê°€ ì—†ëŠ” ê²½ìš°, í…ìŠ¤íŠ¸ ì „ìš©ìœ¼ë¡œ ì²˜ë¦¬ ì‹œë„
    if result is None:
        # instruction-output í˜•ì‹ ì¬ì‹œë„
        if "instruction" in sample and "output" in sample:
            messages = [
                {"role": "user", "content": [{"type": "text", "text": sample["instruction"]}]},
                {"role": "assistant", "content": [{"type": "text", "text": sample["output"]}]}
            ]
            messages = ensure_messages_text_strings(messages)
            return {"messages": messages, "images": []}
        
        # ëª¨ë“  ë³€í™˜ ì‹œë„ ì‹¤íŒ¨
        if log_failure:
            sample_keys = list(sample.keys()) if isinstance(sample, dict) else "N/A"
            sample_preview = str(sample)[:200] if isinstance(sample, dict) else str(sample)[:200]
            logger.debug(f"[{dataset_name}] ìƒ˜í”Œ ë³€í™˜ ì‹¤íŒ¨ - ì§€ì›ë˜ì§€ ì•ŠëŠ” í˜•ì‹. ìƒ˜í”Œ í‚¤: {sample_keys}, ë¯¸ë¦¬ë³´ê¸°: {sample_preview}...")
    
    # base_convert ê²°ê³¼ ì •ê·œí™”
    if result:
        # messages ì •ê·œí™”
        if "messages" in result:
            result["messages"] = ensure_messages_text_strings(result["messages"])
        # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì„¤ì •
        if "images" in result:
            if not result["images"]:
                result["images"] = []
    
    return result

# Configure logger
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
handler = logging.StreamHandler()
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)

# ë„ë©”ì¸ë³„ ë°ì´í„°ì…‹ ì„¤ì •
# ê° ë„ë©”ì¸ë³„ë¡œ í…ìŠ¤íŠ¸ ì „ìš© ë˜ëŠ” ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì…‹ì„ ì§€ì •í•©ë‹ˆë‹¤.
# í…ìŠ¤íŠ¸ ì „ìš© ë°ì´í„°ì…‹ë„ í—ˆìš©í•˜ë©°, ìµœì¢…ì ìœ¼ë¡œ messages í˜•ì‹ìœ¼ë¡œ í†µí•©ë©ë‹ˆë‹¤.
DOMAIN_DATASETS = {
    "math": [
        "meta-math/MetaMathQA",  # MetaMathQA: ìˆ˜í•™ instruction ë°ì´í„°ì…‹ (í•™ìŠµìš©)
        "sdiazlor/math-python-reasoning-dataset",  # Math-Python-Reasoning: ìˆ˜í•™ Python ì¶”ë¡  (í•™ìŠµìš©)
    ],
    "science": [
        "derek-thomas/ScienceQA",  # SciTLDR: ê³¼í•™ ë…¼ë¬¸ ìš”ì•½ (í•™ìŠµìš©)
        "dhmeltzer/ask-science-qg"
    ],
    "code": [
        "theblackcat102/evol-codealpaca-v1", # Evol-CodeAlpaca: ì½”ë“œ instruction (í•™ìŠµìš©)
        "microsoft/rStar-Coder",  # rStar-Coder: ì½”ë“œ ë°ì´í„°ì…‹
    ],
    "puzzle": [
        "openbmb/UltraInteract_sft",  # UltraInteract_sft: ë…¼ë¦¬ ì¶”ë¡  instruction ë°ì´í„°ì…‹ (í•™ìŠµìš©)
        "HuggingFaceH4/ultrafeedback_binarized",  # UltraFeedback: ì¡´ì¬í•˜ì§€ ì•ŠìŒ, ëŒ€ì²´ í•„ìš”
    ],
    "vision": [
        "lmms-lab/LLaVA-OneVision-Data",  # LLaVA-OneVision-Data: ë‹¤ì–‘í•œ ë¹„ì „ íƒœìŠ¤í¬ (ë©€í‹°ëª¨ë‹¬)
        # "textvqa",  # TextVQA: ì¡´ì¬í•˜ì§€ ì•ŠìŒ, ëŒ€ì²´ í•„ìš”
    ],
    "ocr": [
        "howard-hou/OCR-VQA",  # OCR-VQA: OCR ì§ˆì˜ì‘ë‹µ ë°ì´í„°ì…‹
        "naver-clova-ix/cord-v2",  # CORD-v2: ì˜ìˆ˜ì¦ OCR ë°ì´í„°ì…‹ (ì´ë¯¸ì§€ + ground_truth)
        # "allenai/olmOCR-mix-1025",  # olmOCR-mix: ë³„ë„ ì „ì²˜ë¦¬ í•„ìš” (olmocr íˆ´í‚·), HFì—ì„œ ì§ì ‘ ë¡œë“œ ì‹œ ì´ë¯¸ì§€ ë¯¸ì œê³µ
    ],
    "chat": [
        "HuggingFaceTB/smoltalk",  # SmolTalk: ì¼ë°˜ ì±„íŒ… (ë©€í‹°ëª¨ë‹¬ ê°€ëŠ¥)
        "Open-Orca/OpenOrca",  # OpenOrca: ì¼ë°˜ ëŒ€í™” (í…ìŠ¤íŠ¸ ì „ìš©)
    ]
}

def get_domain_from_config(config_name: str, dataset_name: str) -> Optional[str]:
    """
    Config ì´ë¦„ê³¼ ë°ì´í„°ì…‹ ì´ë¦„ì„ ê¸°ë°˜ìœ¼ë¡œ ë„ë©”ì¸ì„ ì¶”ë¡ í•©ë‹ˆë‹¤.
    
    Args:
        config_name: ë°ì´í„°ì…‹ config ì´ë¦„
        dataset_name: ë°ì´í„°ì…‹ ì´ë¦„
    
    Returns:
        ì¶”ë¡ ëœ ë„ë©”ì¸ ì´ë¦„ ë˜ëŠ” None
    """
    config_lower = config_name.lower()
    dataset_lower = dataset_name.lower()
    
    # í‚¤ì›Œë“œ ê¸°ë°˜ ë„ë©”ì¸ ë§¤ì¹­ (ìš°ì„ ìˆœìœ„ ìˆœ)
    math_keywords = ["math", "mathematical", "algebra", "geometry", "calculus", "arithmetic", "equation"]
    science_keywords = ["science", "physics", "chemistry", "biology", "scientific", "astronomy", "geology"]
    code_keywords = ["code", "programming", "python", "javascript", "coding", "software", "algorithm", "function"]
    puzzle_keywords = ["puzzle", "logic", "reasoning", "riddle", "brain", "challenge", "problem"]
    vision_keywords = ["vision", "visual", "image", "photo", "picture", "camera", "see", "look"]
    ocr_keywords = ["ocr", "text", "document", "scan", "recognition", "read", "extract", "textual"]
    
    if any(keyword in config_lower for keyword in math_keywords):
        return "math"
    elif any(keyword in config_lower for keyword in science_keywords):
        return "science"
    elif any(keyword in config_lower for keyword in code_keywords):
        return "code"
    elif any(keyword in config_lower for keyword in puzzle_keywords):
        return "puzzle"
    elif any(keyword in config_lower for keyword in vision_keywords):
        return "vision"
    elif any(keyword in config_lower for keyword in ocr_keywords):
        return "ocr"
    
    # ë°ì´í„°ì…‹ ì´ë¦„ ê¸°ë°˜ ë§¤ì¹­
    if any(keyword in dataset_lower for keyword in math_keywords):
        return "math"
    elif any(keyword in dataset_lower for keyword in science_keywords):
        return "science"
    elif any(keyword in dataset_lower for keyword in code_keywords):
        return "code"
    elif any(keyword in dataset_lower for keyword in puzzle_keywords):
        return "puzzle"
    elif any(keyword in dataset_lower for keyword in vision_keywords):
        return "vision"
    elif any(keyword in dataset_lower for keyword in ocr_keywords):
        return "ocr"
    
    return None

def _process_dataset_config_split(
    domain: str,
    dataset_name: str,
    config: str,
    train_split: str,
    test_split: Optional[str],
    train_path: str,
    test_path: str,
    image_counter_lock: threading.Lock,
    shared_counters: Dict[str, Any],
    images_dir: str,
    samples_per_config: int,
    test_size: float,
    use_streaming: bool,
    domain_processed_lock: threading.Lock,
    domain_processed_dict: Dict[str, int],
    max_samples_per_domain: int
) -> Dict[str, Any]:
    """
    ë‹¨ì¼ ë°ì´í„°ì…‹ì˜ ë‹¨ì¼ configì™€ splitì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ (ë³‘ë ¬ ì²˜ë¦¬ìš©)
    ë°ì´í„°ì…‹ë³„ ì „ìš© í”„ë¡œì„¸ì„œë¥¼ ì‚¬ìš©í•˜ì—¬ messages í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    """
    result = {
        "train_count": 0,
        "test_count": 0,
    }
    
    try:
        # ë°ì´í„°ì…‹ì— ë§ëŠ” í”„ë¡œì„¸ì„œ ì„ íƒ
        processor = get_processor_for_dataset(dataset_name)
        logger.debug(f"   ğŸ¯ [{dataset_name}] í”„ë¡œì„¸ì„œ ì„ íƒ: {processor.__name__}")
        
        # Train split ì²˜ë¦¬
        try:
            logger.debug(f"   ğŸ” [{dataset_name}] Config {config} Train split {train_split} ë¡œë”©...")
            
            if config == "default":
                train_dataset = load_dataset(
                    path=dataset_name,
                    split=train_split,
                    streaming=use_streaming
                )
            else:
                train_dataset = load_dataset(
                    path=dataset_name,
                    name=config,
                    split=train_split,
                    streaming=use_streaming
                )
            
            # ë°ì´í„°ì…‹ ì •ë³´ í™•ì¸
            dataset_size = None
            if not use_streaming:
                dataset_size = len(train_dataset) if hasattr(train_dataset, '__len__') else None
                if dataset_size == 0:
                    error_msg = f"âŒ [{dataset_name}] Config {config} Train split {train_split}ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."
                    logger.error(error_msg)
                    raise RuntimeError(error_msg)
            
            train_samples_per_config = samples_per_config
            if test_split:
                train_samples_per_config = int(samples_per_config * (1 - test_size))
            
            # ë„ë©”ì¸ë³„ ì²˜ë¦¬ëŸ‰ ì²´í¬
            with domain_processed_lock:
                current_domain_processed = domain_processed_dict.get(domain, 0)
                remaining_domain_capacity = max_samples_per_domain - current_domain_processed
                effective_max_samples = min(train_samples_per_config, remaining_domain_capacity)
            
            if effective_max_samples <= 0:
                logger.debug(f"   âš ï¸ [{dataset_name}] Config {config}: ë„ë©”ì¸ ì²˜ë¦¬ëŸ‰ í•œê³„ ë„ë‹¬, ê±´ë„ˆëœ€")
                return result
            
            # ============================================================
            # ë°ì´í„°ì…‹ë³„ í”„ë¡œì„¸ì„œ í˜¸ì¶œ (ì „ì²´ ë°ì´í„°ì…‹ ì²˜ë¦¬)
            # ============================================================
            # ë””ë²„ê¹…ì´ í•„ìš”í•œ ë°ì´í„°ì…‹ì€ í•­ìƒ ìƒì„¸ ë¡œê·¸ ì¶œë ¥
            log_detail = any(keyword in dataset_name.lower() for keyword in ["rstar", "ask-science"])
            converted_results = processor(train_dataset, dataset_name, effective_max_samples, log_detail=log_detail)
            
            logger.debug(f"   âœ… [{dataset_name}] Config {config} í”„ë¡œì„¸ì„œ ì™„ë£Œ: {len(converted_results)}ê°œ ìƒ˜í”Œ ë³€í™˜ë¨")
            
            # ë³€í™˜ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì—ëŸ¬
            if not converted_results:
                error_msg = f"âŒ [{dataset_name}] Config {config}: í”„ë¡œì„¸ì„œì—ì„œ ë³€í™˜ëœ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤."
                logger.error(error_msg)
                raise RuntimeError(error_msg)
            
            # ============================================================
            # ë³€í™˜ëœ ê²°ê³¼ë¥¼ íŒŒì¼ì— ì €ì¥
            # ============================================================
            train_processed = 0
            for idx, converted in enumerate(converted_results):
                try:
                    # messages í…ìŠ¤íŠ¸ ë¬¸ìì—´ ë³´ì¥
                    if "messages" in converted:
                        converted["messages"] = ensure_messages_text_strings(converted["messages"])
                    
                    # ì´ë¯¸ì§€ ì²˜ë¦¬ (PIL Image ê°ì²´ë¥¼ íŒŒì¼ë¡œ ì €ì¥)
                    image_paths = []
                    if "images" in converted and converted["images"]:
                        for img_obj in converted["images"]:
                            if isinstance(img_obj, Image.Image):
                                try:
                                    with image_counter_lock:
                                        current_counter = shared_counters["image_counter"]
                                        img_path = os.path.join(images_dir, f"{current_counter}.png")
                                        img_obj.save(img_path, "PNG")
                                        image_paths.append(img_path)
                                        shared_counters["image_counter"] += 1
                                except Exception as img_e:
                                    error_msg = f"âŒ [{dataset_name}] ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {img_e}"
                                    logger.error(error_msg)
                                    raise RuntimeError(error_msg) from img_e
                    
                    # ìµœì¢… ë°ì´í„° êµ¬ì„±
                    converted["images"] = image_paths
                    converted["domain"] = domain
                    
                    # íŒŒì¼ ì“°ê¸° (ë„ë©”ì¸ë³„ íŒŒì¼ì— append)
                    try:
                        json_str = json.dumps(converted, ensure_ascii=False)
                        with open(train_path, "a", encoding="utf-8") as f:
                            f.write(json_str + "\n")
                        
                        # ì¹´ìš´í„° ì—…ë°ì´íŠ¸ (thread-safe)
                        with domain_processed_lock:
                            shared_counters["domain_counts"][domain]["train"] += 1
                            shared_counters["total_processed"] += 1
                            domain_processed_dict[domain] = domain_processed_dict.get(domain, 0) + 1
                        
                        result["train_count"] += 1
                        train_processed += 1
                        
                    except (TypeError, ValueError) as json_e:
                        error_msg = f"âŒ [{dataset_name}] JSON ì§ë ¬í™” ì‹¤íŒ¨: {json_e}"
                        logger.error(error_msg)
                        raise RuntimeError(error_msg) from json_e
                
                except Exception as sample_e:
                    logger.error(f"âŒ [{dataset_name}] Train ìƒ˜í”Œ {idx} ì €ì¥ ì‹¤íŒ¨: {sample_e}")
                    # ì €ì¥ ì‹¤íŒ¨ ì‹œì—ë„ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì¤‘ë‹¨
                    raise RuntimeError(f"Train ìƒ˜í”Œ ì €ì¥ ì‹¤íŒ¨") from sample_e
            
            logger.debug(f"   âœ… [{dataset_name}] Config {config} Train split ì €ì¥ ì™„ë£Œ: {train_processed}ê°œ")
            
            del train_dataset
            gc.collect()
            
        except Exception as e:
            error_msg = f"âŒ [{dataset_name}] Config {config} Train split {train_split} ë¡œë“œ ì‹¤íŒ¨: {e}"
            logger.error(error_msg)
            traceback.print_exc()
            raise RuntimeError(error_msg) from e
        
        # Test split ì²˜ë¦¬ (ìˆëŠ” ê²½ìš°)
        if test_split:
            try:
                logger.debug(f"   ğŸ” [{dataset_name}] Config {config} Test split {test_split} ë¡œë”©...")
                
                if config == "default":
                    test_dataset = load_dataset(
                        path=dataset_name,
                        split=test_split,
                        streaming=use_streaming
                    )
                else:
                    test_dataset = load_dataset(
                        path=dataset_name,
                        name=config,
                        split=test_split,
                        streaming=use_streaming
                    )
                
                test_samples_per_config = int(samples_per_config * test_size)
                
                # í”„ë¡œì„¸ì„œ í˜¸ì¶œ (ì „ì²´ ë°ì´í„°ì…‹ ì²˜ë¦¬)
                log_detail = "rstar" in dataset_name.lower()
                test_converted_results = processor(test_dataset, dataset_name, test_samples_per_config, log_detail=log_detail)
                
                logger.debug(f"   âœ… [{dataset_name}] Config {config} Test í”„ë¡œì„¸ì„œ ì™„ë£Œ: {len(test_converted_results)}ê°œ ìƒ˜í”Œ ë³€í™˜ë¨")
                
                # ë³€í™˜ëœ ê²°ê³¼ë¥¼ íŒŒì¼ì— ì €ì¥
                test_processed = 0
                for idx, converted in enumerate(test_converted_results):
                    try:
                        # messages í…ìŠ¤íŠ¸ ë¬¸ìì—´ ë³´ì¥
                        if "messages" in converted:
                            converted["messages"] = ensure_messages_text_strings(converted["messages"])
                        
                        # ì´ë¯¸ì§€ ì²˜ë¦¬
                        image_paths = []
                        if "images" in converted and converted["images"]:
                            for img_obj in converted["images"]:
                                if isinstance(img_obj, Image.Image):
                                    try:
                                        with image_counter_lock:
                                            current_counter = shared_counters["image_counter"]
                                            img_path = os.path.join(images_dir, f"{current_counter}.png")
                                            img_obj.save(img_path, "PNG")
                                            image_paths.append(img_path)
                                            shared_counters["image_counter"] += 1
                                    except Exception as img_e:
                                        error_msg = f"âŒ [{dataset_name}] ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {img_e}"
                                        logger.error(error_msg)
                                        raise RuntimeError(error_msg) from img_e
                        
                        # ìµœì¢… ë°ì´í„° êµ¬ì„±
                        converted["images"] = image_paths
                        converted["domain"] = domain
                        
                        # íŒŒì¼ ì“°ê¸° (ë„ë©”ì¸ë³„ íŒŒì¼ì— append)
                        try:
                            json_str = json.dumps(converted, ensure_ascii=False)
                            with open(test_path, "a", encoding="utf-8") as f:
                                f.write(json_str + "\n")
                            
                            # ì¹´ìš´í„° ì—…ë°ì´íŠ¸ (thread-safe)
                            with domain_processed_lock:
                                shared_counters["domain_counts"][domain]["test"] += 1
                                shared_counters["total_processed"] += 1
                            
                            result["test_count"] += 1
                            test_processed += 1
                            
                        except (TypeError, ValueError) as json_e:
                            error_msg = f"âŒ [{dataset_name}] JSON ì§ë ¬í™” ì‹¤íŒ¨: {json_e}"
                            logger.error(error_msg)
                            raise RuntimeError(error_msg) from json_e
                    
                    except Exception as sample_e:
                        logger.error(f"âŒ [{dataset_name}] Test ìƒ˜í”Œ {idx} ì €ì¥ ì‹¤íŒ¨: {sample_e}")
                        raise RuntimeError(f"Test ìƒ˜í”Œ ì €ì¥ ì‹¤íŒ¨") from sample_e
                
                logger.debug(f"   âœ… [{dataset_name}] Config {config} Test split ì €ì¥ ì™„ë£Œ: {test_processed}ê°œ")
                
                del test_dataset
                gc.collect()
                
            except Exception as e:
                error_msg = f"âŒ [{dataset_name}] Config {config} Test split {test_split} ì²˜ë¦¬ ì‹¤íŒ¨: {e}"
                logger.error(error_msg)
                traceback.print_exc()
                raise RuntimeError(error_msg) from e
    
    except Exception as e:
        error_msg = f"âŒ [{dataset_name}] Config {config} ì²˜ë¦¬ ì‹¤íŒ¨: {e}"
        logger.error(error_msg)
        traceback.print_exc()
        raise RuntimeError(error_msg) from e
    
    # ìµœì†Œí•œ í•˜ë‚˜ì˜ ìƒ˜í”Œì€ ì²˜ë¦¬ë˜ì–´ì•¼ í•¨
    # (í”„ë¡œì„¸ì„œì—ì„œ ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì´ë¯¸ RuntimeErrorë¥¼ ë°œìƒì‹œí‚¤ë¯€ë¡œ, ì—¬ê¸°ëŠ” ìµœì¢… ì²´í¬ë§Œ)
    if result["train_count"] == 0 and result["test_count"] == 0:
        error_msg = f"âŒ [{dataset_name}] Config {config}: ì²˜ë¦¬ëœ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤."
        logger.error(error_msg)
        logger.error(f"   ğŸ“‹ í™•ì¸ ì‚¬í•­:")
        logger.error(f"      - Config: {config}")
        logger.error(f"      - Train split: {train_split}")
        logger.error(f"      - Test split: {test_split}")
        logger.error(f"      - Streaming: {use_streaming}")
        logger.error(f"      - Samples per config: {samples_per_config}")
        
        raise RuntimeError(error_msg)
    
    return result

def _process_domain_datasets(
    domain: str,
    dataset_names: List[str],
    temp_dir: str,
    image_counter_lock: threading.Lock,
    shared_counters: Dict[str, Any],
    images_dir: str,
    max_samples_per_domain: int,
    test_size: float,
    use_streaming: bool,
    max_workers: int = 4
) -> Dict[str, Any]:
    """
    ë‹¨ì¼ ë„ë©”ì¸ì˜ ë°ì´í„°ì…‹ë“¤ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ (ë³‘ë ¬ ì²˜ë¦¬ìš©)
    ê° ë°ì´í„°ì…‹, config, splitì„ ìˆœì°¨ ì²˜ë¦¬ (ë„ë©”ì¸ë³„ ë³‘ë ¬ì€ ìƒìœ„ ë ˆë²¨ì—ì„œ)
    """
    # ë„ë©”ì¸ë³„ ì„ì‹œ íŒŒì¼ ìƒì„±
    domain_train_path = os.path.join(temp_dir, f"{domain}_train.jsonl")
    domain_test_path = os.path.join(temp_dir, f"{domain}_test.jsonl")
    
    # ë„ë©”ì¸ë³„ ì²˜ë¦¬ í†µê³„
    domain_stats = {
        "total_processed": 0,  # train_count + test_count í•©ê³„
    }
    
    # ScienceQA ë¯¸ëŸ¬ ì¤‘ë³µ ë°©ì§€ í”Œë˜ê·¸
    scienceqa_taken = False
    
    # ë„ë©”ì¸ë³„ ì²˜ë¦¬ëŸ‰ ì¶”ì  (thread-safe)
    domain_processed_lock = threading.Lock()
    domain_processed_dict = {domain: 0}
    
    # ëª¨ë“  ë°ì´í„°ì…‹/config/split ì‘ì—… ìˆ˜ì§‘
    tasks = []
    
    for dataset_name in dataset_names:
        try:
            logger.info(f"   ğŸ“‹ {domain} ë„ë©”ì¸ - ë°ì´í„°ì…‹: {dataset_name}")
            
            # ë°ì´í„°ì…‹ ì¡´ì¬ í™•ì¸
            if not dataset_exists(dataset_name):
                error_msg = f"âŒ [{domain}] ë°ì´í„°ì…‹ì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {dataset_name}"
                logger.error(error_msg)
                raise RuntimeError(error_msg)
            
            # ë°ì´í„°ì…‹ì˜ config ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            try:
                available_configs = get_dataset_config_names(dataset_name)
                if not available_configs:
                    available_configs = ["default"]
            except Exception as e:
                error_msg = f"âŒ [{domain}] ë°ì´í„°ì…‹ {dataset_name}ì˜ Config ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}"
                logger.error(error_msg)
                traceback.print_exc()
                raise RuntimeError(error_msg) from e
            
            # LLaVA-OneVision-DataëŠ” onevision ì„œë¸Œì…‹ë§Œ ì‚¬ìš©
            if "llava-onevision" in dataset_name.lower() or "llava-onevision-data" in dataset_name.lower():
                filtered = [c for c in available_configs if "onevision" in str(c).lower()]
                if filtered:
                    available_configs = filtered
                else:
                    available_configs = available_configs[:5]
            
            # rStar-Coderì— í•œí•´ì„œë§Œ RL ê´€ë ¨ config ì œì™¸, SFTìš©ë§Œ ì‚¬ìš©
            if "rstar-coder" in dataset_name.lower() or "rstar_coder" in dataset_name.lower():
                rl_keywords = ["rl", "reinforcement", "synthetic_rl", "dpo", "ppo", "reward"]
                test_keywords = ["test_case", "test"]  # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìƒì„±ìš©ì€ ì œì™¸
                original_count = len(available_configs)
                
                # SFT í•™ìŠµìš© configë§Œ ì‚¬ìš© (test_case ì œì™¸)
                sft_configs = [
                    c for c in available_configs 
                    if str(c).lower() in ["seed_sft", "synthetic_sft"] 
                    and not any(test_kw in str(c).lower() for test_kw in test_keywords)
                ]
                if sft_configs:
                    available_configs = sft_configs
                else:
                    # RL ë° test ê´€ë ¨ config ì œì™¸
                    filtered_configs = [
                        c for c in available_configs 
                        if not any(keyword in str(c).lower() for keyword in rl_keywords)
                        and not any(test_kw in str(c).lower() for test_kw in test_keywords)
                    ]
                    if filtered_configs:
                        available_configs = filtered_configs
                    else:
                        # í•„í„°ë§ í›„ ë‚¨ì€ configê°€ ì—†ìœ¼ë©´ ì˜¤ë¥˜
                        error_msg = f"âŒ [{domain}] ë°ì´í„°ì…‹ {dataset_name}: ëª¨ë“  configê°€ RL ë˜ëŠ” test ê´€ë ¨ì…ë‹ˆë‹¤. SFT í•™ìŠµìš© configê°€ ì—†ìŠµë‹ˆë‹¤."
                        logger.error(error_msg)
                        raise RuntimeError(error_msg)
            
            # ScienceQA ë¯¸ëŸ¬ ì¤‘ë³µ ë°©ì§€
            if domain == "science" and ("scienceqa" in dataset_name.lower()):
                if scienceqa_taken:
                    continue
                scienceqa_taken = True
            
            # Configë³„ë¡œ ìƒ˜í”Œ ìˆ˜ ê³„ì‚°
            samples_per_config = max(1, max_samples_per_domain // max(len(available_configs), 1))
            
            # ê° configì— ëŒ€í•´ ì‘ì—… ìƒì„±
            for config in available_configs:
                try:
                    # ì‚¬ìš© ê°€ëŠ¥í•œ split í™•ì¸
                    try:
                        if config == "default":
                            available_splits = get_dataset_split_names(dataset_name)
                        else:
                            available_splits = get_dataset_split_names(dataset_name, config_name=config)
                        
                        # Train split ì„ íƒ: train_sft > train
                        train_split = None
                        if "train_sft" in available_splits:
                            train_split = "train_sft"
                        elif "train" in available_splits:
                            train_split = "train"
                        else:
                            error_msg = f"âŒ [{domain}] ë°ì´í„°ì…‹ {dataset_name} Config {config}ì— train ë˜ëŠ” train_sft splitì´ ì—†ìŠµë‹ˆë‹¤."
                            logger.error(error_msg)
                            raise RuntimeError(error_msg)
                        
                        # Test split ì„ íƒ: test_sft > test
                        test_split = None
                        if "test_sft" in available_splits:
                            test_split = "test_sft"
                        elif "test" in available_splits:
                            test_split = "test"
                    except Exception as e:
                        error_msg = f"âŒ [{domain}] ë°ì´í„°ì…‹ {dataset_name} Config {config}ì˜ Split ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}"
                        logger.error(error_msg)
                        traceback.print_exc()
                        raise RuntimeError(error_msg) from e
                    
                    # ì‘ì—… ì¶”ê°€
                    tasks.append({
                        "domain": domain,
                        "dataset_name": dataset_name,
                        "config": config,
                        "train_split": train_split,
                        "test_split": test_split,
                        "samples_per_config": samples_per_config
                    })
                
                except Exception as e:
                    error_msg = f"âŒ [{domain}] ë°ì´í„°ì…‹ {dataset_name} Config {config} ì¤€ë¹„ ì‹¤íŒ¨: {e}"
                    logger.error(error_msg)
                    traceback.print_exc()
                    raise RuntimeError(error_msg) from e
        
        except Exception as e:
            error_msg = f"âŒ [{domain}] ë°ì´í„°ì…‹ {dataset_name} ì¤€ë¹„ ì‹¤íŒ¨: {e}"
            logger.error(error_msg)
            traceback.print_exc()
            raise RuntimeError(error_msg) from e
    
    # ëª¨ë“  ì‘ì—…ì„ ìˆœì°¨ë¡œ ì‹¤í–‰ (ë„ë©”ì¸ë³„ ë³‘ë ¬ ì²˜ë¦¬ëŠ” ìƒìœ„ ë ˆë²¨ì—ì„œ ìˆ˜í–‰)
    if not tasks:
        error_msg = f"âŒ [{domain}] ë„ë©”ì¸ì— ì²˜ë¦¬í•  ì‘ì—…ì´ ì—†ìŠµë‹ˆë‹¤."
        logger.error(error_msg)
        raise RuntimeError(error_msg)
    
    logger.debug(f"   ğŸ“‹ {domain} ë„ë©”ì¸: {len(tasks)}ê°œ ì‘ì—…ì„ ìˆœì°¨ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
    
    # ë„ë©”ì¸ ë‚´ë¶€ëŠ” ìˆœì°¨ ì²˜ë¦¬ (ë„ë©”ì¸ë³„ ë³‘ë ¬ì€ ìƒìœ„ ë ˆë²¨ì—ì„œ ì²˜ë¦¬)
    for task in tasks:
        try:
            result = _process_dataset_config_split(
                domain=task["domain"],
                dataset_name=task["dataset_name"],
                config=task["config"],
                train_split=task["train_split"],
                test_split=task["test_split"],
                train_path=domain_train_path,
                test_path=domain_test_path,
                image_counter_lock=image_counter_lock,
                shared_counters=shared_counters,
                images_dir=images_dir,
                samples_per_config=task["samples_per_config"],
                test_size=test_size,
                use_streaming=use_streaming,
                domain_processed_lock=domain_processed_lock,
                domain_processed_dict=domain_processed_dict,
                max_samples_per_domain=max_samples_per_domain
            )
            # train_count + test_count í•©ê³„
            total_count = result.get("train_count", 0) + result.get("test_count", 0)
            domain_stats["total_processed"] += total_count
        except Exception as e:
            error_msg = f"âŒ [{domain}] ë°ì´í„°ì…‹ {task['dataset_name']} Config {task['config']} ì²˜ë¦¬ ì‹¤íŒ¨: {e}"
            logger.error(error_msg)
            logger.error("ğŸ›‘ ì˜¤ë¥˜ ë°œìƒìœ¼ë¡œ ì¸í•´ ëª¨ë“  ì‘ì—…ì„ ì·¨ì†Œí•˜ê³  í”„ë¡œì„¸ìŠ¤ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            traceback.print_exc()
            raise RuntimeError(error_msg) from e
    
    # ë„ë©”ì¸ë³„ ì²˜ë¦¬ í†µê³„ ë¡œê¹… ë° ê²€ì¦
    if domain_stats["total_processed"] == 0:
        error_msg = f"âŒ [{domain}] ë„ë©”ì¸: ì²˜ë¦¬ëœ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤."
        logger.error(error_msg)
        raise RuntimeError(error_msg)
    
    logger.info(f"   ğŸ“Š {domain} ë„ë©”ì¸ ì²˜ë¦¬ í†µê³„: ì´ {domain_stats['total_processed']}ê°œ ìƒ˜í”Œ ì²˜ë¦¬ ì™„ë£Œ")
    
    return {
        "domain": domain,
        "domain_stats": domain_stats,
        "domain_processed": domain_processed_dict.get(domain, 0),
        "train_path": domain_train_path,
        "test_path": domain_test_path
    }

def get_multi_domain_sft_dataset(
    domain_configs: Optional[Dict[str, List[str]]] = None,
    tokenizer=None,
    max_length: int = 2048,
    max_samples_per_domain: int = 200,
    test_size: float = 0.1,
    use_streaming: bool = True,
    chunk_size: int = 1000,
    max_workers: int = 4
):
    """
    ë©€í‹° ë„ë©”ì¸ SFT ë°ì´í„°ì…‹ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        domain_configs: ë„ë©”ì¸ë³„ ë°ì´í„°ì…‹ ì„¤ì • ë”•ì…”ë„ˆë¦¬
            ì˜ˆ: {"math": ["dataset1", "dataset2"], "science": ["dataset3"]}
        tokenizer: í† í¬ë‚˜ì´ì €
        max_length: ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´
        max_samples_per_domain: ë„ë©”ì¸ë‹¹ ìµœëŒ€ ìƒ˜í”Œ ìˆ˜
        test_size: í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë¹„ìœ¨
        use_streaming: ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ ì‚¬ìš© ì—¬ë¶€
        chunk_size: ì²­í¬ í¬ê¸°
    
    Returns:
        DatasetDict with train/test splits, ê° ìƒ˜í”Œì— 'domain' í•„ë“œ í¬í•¨
    """
    if tokenizer is None:
        raise ValueError("Tokenizer must be provided")
    
    if domain_configs is None:
        domain_configs = DOMAIN_DATASETS
    
    logger.info(f"ğŸ“¦ ë©€í‹° ë„ë©”ì¸ ë°ì´í„°ì…‹ ë¡œë”© ì‹œì‘")
    logger.info(f"   - ë„ë©”ì¸ ìˆ˜: {len(domain_configs)}ê°œ")
    logger.info(f"   - ë„ë©”ì¸ë‹¹ ìµœëŒ€ ìƒ˜í”Œ: {max_samples_per_domain}ê°œ")
    logger.info(f"   - ì´ ìµœëŒ€ ìƒ˜í”Œ: {max_samples_per_domain * len(domain_configs)}ê°œ")
    logger.info(f"   - streaming: {use_streaming}")
    logger.info(f"   - ë³‘ë ¬ ì²˜ë¦¬: {max_workers}ê°œ ì›Œì»¤")
    
    log_memory_usage("ë©€í‹° ë„ë©”ì¸ ë°ì´í„°ì…‹ ë¡œë”© ì‹œì‘")
    
    base_temp_dir = "/mls/conan/tmp"
    os.makedirs(base_temp_dir, exist_ok=True)
    temp_dir = tempfile.mkdtemp(dir=base_temp_dir)
    logger.info(f"ğŸ“‚ ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±: {temp_dir}")
    images_dir = os.path.join(temp_dir, "images")
    os.makedirs(images_dir, exist_ok=True)

    try:
        train_jsonl_path = os.path.join(temp_dir, "train.jsonl")
        test_jsonl_path = os.path.join(temp_dir, "test.jsonl")
        
        # ì´ë¯¸ì§€ ì¹´ìš´í„° lock (ë³‘ë ¬ ì²˜ë¦¬ ì‹œ thread-safe)
        image_counter_lock = threading.Lock()
        
        # ê³µìœ  ì¹´ìš´í„° (thread-safe)
        shared_counters = {
            "total_processed": 0,
            "image_counter": 0,
            "domain_counts": defaultdict(lambda: {"train": 0, "test": 0})
        }

        # ê° ë„ë©”ì¸ë³„ë¡œ ì²˜ë¦¬ (ë³‘ë ¬í™”)
        domain_pbar = tqdm(domain_configs.items(), desc="ë„ë©”ì¸ ì²˜ë¦¬", unit="domain")
        
        # ë„ë©”ì¸ë³„ ë³‘ë ¬ ì²˜ë¦¬
        executor = ThreadPoolExecutor(max_workers=max_workers)
        future_to_domain = {}
        domain_file_paths = {}  # ë„ë©”ì¸ë³„ íŒŒì¼ ê²½ë¡œ ì €ì¥
        
        try:
            for domain, dataset_names in domain_configs.items():
                if not dataset_names:
                    error_msg = f"âŒ {domain} ë„ë©”ì¸ì— ë°ì´í„°ì…‹ì´ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                    logger.error(error_msg)
                    raise ValueError(error_msg)
                
                # ê° ë„ë©”ì¸ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬
                future = executor.submit(
                    _process_domain_datasets,
                    domain=domain,
                    dataset_names=dataset_names,
                    temp_dir=temp_dir,
                    image_counter_lock=image_counter_lock,
                    shared_counters=shared_counters,
                    images_dir=images_dir,
                    max_samples_per_domain=max_samples_per_domain,
                    test_size=test_size,
                    use_streaming=use_streaming,
                    max_workers=max_workers
                )
                future_to_domain[future] = domain
            
            # ì™„ë£Œëœ ì‘ì—… ì²˜ë¦¬
            for future in as_completed(future_to_domain):
                domain = future_to_domain[future]
                try:
                    result = future.result()
                    domain_file_paths[domain] = {
                        "train": result["train_path"],
                        "test": result["test_path"]
                    }
                    domain_pbar.update(1)
                    domain_pbar.set_description(f"ë„ë©”ì¸: {domain} ì™„ë£Œ")
                except Exception as e:
                    error_msg = f"âŒ {domain} ë„ë©”ì¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}"
                    logger.error(error_msg)
                    logger.error("ğŸ›‘ ì˜¤ë¥˜ ë°œìƒìœ¼ë¡œ ì¸í•´ ëª¨ë“  ì‘ì—…ì„ ì·¨ì†Œí•˜ê³  í”„ë¡œì„¸ìŠ¤ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                    traceback.print_exc()
                    domain_pbar.update(1)
                    
                    # ëª¨ë“  ë¯¸ì™„ë£Œ ì‘ì—… ì·¨ì†Œ
                    for f in future_to_domain:
                        if not f.done():
                            f.cancel()
                    
                    # Executor ì¢…ë£Œ (ê¸°ë‹¤ë¦¬ì§€ ì•Šê³  ì¦‰ì‹œ ì·¨ì†Œ)
                    executor.shutdown(wait=False, cancel_futures=True)
                    
                    # í”„ë¡œì„¸ìŠ¤ ê°•ì œ ì¢…ë£Œ
                    logger.error("ğŸ’€ í”„ë¡œì„¸ìŠ¤ë¥¼ ê°•ì œ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    os._exit(1)
        finally:
            # ì •ìƒ ì™„ë£Œ ì‹œì—ë§Œ ì •ìƒ ì¢…ë£Œ
            try:
                executor.shutdown(wait=True)
            except:
                pass  # ì´ë¯¸ ì¢…ë£Œëœ ê²½ìš° ë¬´ì‹œ
        
        # ìµœì¢… ì¹´ìš´í„° ì—…ë°ì´íŠ¸
        domain_counts = shared_counters["domain_counts"]
        total_processed = shared_counters["total_processed"]
        image_counter = shared_counters["image_counter"]
        
        # ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ
        domain_pbar.close()
        
        # ë„ë©”ì¸ë³„ íŒŒì¼ì„ ìµœì¢… íŒŒì¼ë¡œ í•©ì¹˜ê¸°
        logger.info("ğŸ”„ ë„ë©”ì¸ë³„ íŒŒì¼ì„ ìµœì¢… íŒŒì¼ë¡œ í•©ì¹˜ëŠ” ì¤‘...")
        with open(train_jsonl_path, "w", encoding="utf-8") as train_f, \
             open(test_jsonl_path, "w", encoding="utf-8") as test_f:
            
            for domain in domain_configs.keys():
                if domain not in domain_file_paths:
                    continue
                
                # Train íŒŒì¼ í•©ì¹˜ê¸°
                domain_train_path = domain_file_paths[domain]["train"]
                if os.path.exists(domain_train_path):
                    with open(domain_train_path, "r", encoding="utf-8") as f:
                        for line in f:
                            if line.strip():
                                train_f.write(line)
                
                # Test íŒŒì¼ í•©ì¹˜ê¸°
                domain_test_path = domain_file_paths[domain]["test"]
                if os.path.exists(domain_test_path):
                    with open(domain_test_path, "r", encoding="utf-8") as f:
                        for line in f:
                            if line.strip():
                                test_f.write(line)

        # ë„ë©”ì¸ë³„ í†µê³„ ì¶œë ¥ ë° ê²€ì¦
        if not domain_counts:
            error_msg = "âŒ ì²˜ë¦¬ëœ ë„ë©”ì¸ì´ ì—†ìŠµë‹ˆë‹¤."
            logger.error(error_msg)
            raise RuntimeError(error_msg)
        
        total_train_samples = sum(c["train"] for c in domain_counts.values())
        total_test_samples = sum(c["test"] for c in domain_counts.values())
        
        if total_train_samples == 0 and total_test_samples == 0:
            error_msg = "âŒ ì²˜ë¦¬ëœ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤."
            logger.error(error_msg)
            raise RuntimeError(error_msg)
        
        logger.info("ğŸ“Š ë„ë©”ì¸ë³„ ìƒ˜í”Œ í†µê³„ (ê· ë“±í™” ì „):")
        for domain, counts in domain_counts.items():
            logger.info(f"   - {domain}: Train {counts['train']}ê°œ, Test {counts['test']}ê°œ")
        
        # ë„ë©”ì¸ë³„ ìƒ˜í”Œ ìˆ˜ ê· ë“±í™”
        # ê° ë„ë©”ì¸ì—ì„œ ë™ì¼í•œ ìˆ˜ì˜ ìƒ˜í”Œì„ ì‚¬ìš©í•˜ë„ë¡ ì¡°ì •
        balanced_train_count = 0
        balanced_test_count = 0
        
        if domain_counts:
            min_train = min([c["train"] for c in domain_counts.values()] + [max_samples_per_domain])
            min_test = min([c["test"] for c in domain_counts.values()] + [int(max_samples_per_domain * test_size)])
            
            logger.info(f"âš–ï¸ ë„ë©”ì¸ë³„ ìƒ˜í”Œ ìˆ˜ ê· ë“±í™”:")
            logger.info(f"   - ìµœì†Œ Train ìƒ˜í”Œ ìˆ˜: {min_train}ê°œ")
            logger.info(f"   - ìµœì†Œ Test ìƒ˜í”Œ ìˆ˜: {min_test}ê°œ")
            
            # JSONL íŒŒì¼ì„ ë‹¤ì‹œ ì½ì–´ì„œ ê· ë“±í™”
            if min_train > 0 or min_test > 0:
                logger.info("ğŸ”„ ìƒ˜í”Œ ìˆ˜ ê· ë“±í™”ë¥¼ ìœ„í•´ JSONL íŒŒì¼ ì¬ì²˜ë¦¬...")
                
                # ì„ì‹œ íŒŒì¼ë¡œ ì¬ì‘ì„±
                balanced_train_path = os.path.join(temp_dir, "train_balanced.jsonl")
                balanced_test_path = os.path.join(temp_dir, "test_balanced.jsonl")
            
                domain_train_samples = defaultdict(list)
                domain_test_samples = defaultdict(list)
                
                # ê¸°ì¡´ JSONL íŒŒì¼ ì½ê¸°
                with open(train_jsonl_path, "r", encoding="utf-8") as f:
                    for line in f:
                        if line.strip():
                            sample = json.loads(line)
                            domain = sample.get("domain", "unknown")
                            domain_train_samples[domain].append(sample)
                
                with open(test_jsonl_path, "r", encoding="utf-8") as f:
                    for line in f:
                        if line.strip():
                            sample = json.loads(line)
                            domain = sample.get("domain", "unknown")
                            domain_test_samples[domain].append(sample)
                
                # ê° ë„ë©”ì¸ë³„ë¡œ ìµœì†Œ ìƒ˜í”Œ ìˆ˜ë§Œí¼ë§Œ ì‚¬ìš©
                balanced_domain_counts = defaultdict(lambda: {"train": 0, "test": 0})
                
                with open(balanced_train_path, "w", encoding="utf-8") as train_f, \
                     open(balanced_test_path, "w", encoding="utf-8") as test_f:
                    
                    for domain in domain_configs.keys():
                        # Train ìƒ˜í”Œ ê· ë“±í™”
                        train_samples = domain_train_samples[domain]
                        if len(train_samples) > min_train:
                            random.shuffle(train_samples)
                            train_samples = train_samples[:min_train]
                        
                        for sample in train_samples:
                            train_f.write(json.dumps(sample) + "\n")
                            balanced_domain_counts[domain]["train"] += 1
                            balanced_train_count += 1
                        
                        # Test ìƒ˜í”Œ ê· ë“±í™”
                        test_samples = domain_test_samples[domain]
                        if len(test_samples) > min_test:
                            random.shuffle(test_samples)
                            test_samples = test_samples[:min_test]
                        
                        for sample in test_samples:
                            test_f.write(json.dumps(sample) + "\n")
                            balanced_domain_counts[domain]["test"] += 1
                            balanced_test_count += 1
                
                # ê· ë“±í™”ëœ íŒŒì¼ë¡œ êµì²´
                train_jsonl_path = balanced_train_path
                test_jsonl_path = balanced_test_path
                
                logger.info("ğŸ“Š ë„ë©”ì¸ë³„ ìƒ˜í”Œ í†µê³„ (ê· ë“±í™” í›„):")
                for domain, counts in balanced_domain_counts.items():
                    logger.info(f"   - {domain}: Train {counts['train']}ê°œ, Test {counts['test']}ê°œ")
                
                logger.debug(f"âœ… ê· ë“±í™” ì™„ë£Œ: Train {balanced_train_count}ê°œ, Test {balanced_test_count}ê°œ")
            else:
                total_train = sum(c["train"] for c in domain_counts.values())
                total_test = sum(c["test"] for c in domain_counts.values())
                balanced_train_count = total_train
                balanced_test_count = total_test
                logger.debug(f"âœ… ì´ ìƒ˜í”Œ ìˆ˜ì§‘ ì™„ë£Œ: Train {total_train}ê°œ, Test {total_test}ê°œ")
        else:
            balanced_train_count = 0
            balanced_test_count = 0
        
        # JSONL íŒŒì¼ë¡œë¶€í„° ë°ì´í„°ì…‹ ë¡œë“œ
        data_files = {}
        final_train_count = balanced_train_count
        final_test_count = balanced_test_count
        
        if final_train_count > 0:
            data_files["train"] = train_jsonl_path
        if final_test_count > 0:
            data_files["test"] = test_jsonl_path

        if not data_files:
            error_msg = "âŒ ë³€í™˜ëœ í›ˆë ¨ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ì…‹ í˜•ì‹ì„ í™•ì¸í•˜ì„¸ìš”."
            logger.error(error_msg)
            raise RuntimeError(error_msg)
        
        if final_train_count == 0:
            error_msg = "âŒ Train ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤."
            logger.error(error_msg)
            raise RuntimeError(error_msg)
        
        logger.info("ğŸ§  JSONL íŒŒì¼ë¡œë¶€í„° ë°ì´í„°ì…‹ ë¡œë”©...")
        logger.info(f"   - Train íŒŒì¼: {data_files.get('train', 'N/A')}")
        logger.info(f"   - Test íŒŒì¼: {data_files.get('test', 'N/A')}")
        
        # JSONL íŒŒì¼ ê²€ì¦ (ì²« ëª‡ ì¤„ í™•ì¸)
        for split_name, file_path in data_files.items():
            try:
                logger.debug(f"   ğŸ“‹ {split_name} íŒŒì¼ ê²€ì¦ ì¤‘...")
                with open(file_path, "r", encoding="utf-8") as f:
                    line_count = 0
                    for i, line in enumerate(f):
                        if i >= 3:  # ì²˜ìŒ 3ì¤„ë§Œ í™•ì¸
                            break
                        if line.strip():
                            try:
                                sample = json.loads(line)
                                # ë©”ì‹œì§€ í…ìŠ¤íŠ¸ í•„ë“œ ê²€ì¦
                                if "messages" in sample:
                                    for msg in sample["messages"]:
                                        if "content" in msg:
                                            for content_item in msg["content"]:
                                                if isinstance(content_item, dict) and "text" in content_item:
                                                    text_value = content_item["text"]
                                                    if not isinstance(text_value, str):
                                                        logger.warning(f"   âš ï¸ {split_name} íŒŒì¼ {i+1}ë²ˆì§¸ ì¤„: text í•„ë“œê°€ ë¬¸ìì—´ì´ ì•„ë‹˜ (íƒ€ì…: {type(text_value)}, ê°’: {text_value})")
                                line_count += 1
                            except json.JSONDecodeError as e:
                                logger.error(f"   âŒ {split_name} íŒŒì¼ {i+1}ë²ˆì§¸ ì¤„ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                                logger.error(f"   ì¤„ ë‚´ìš©: {line[:200]}...")
                            except Exception as e:
                                logger.warning(f"   âš ï¸ {split_name} íŒŒì¼ {i+1}ë²ˆì§¸ ì¤„ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
                
                # íŒŒì¼ í¬ê¸° í™•ì¸
                file_size = os.path.getsize(file_path)
                logger.info(f"   âœ… {split_name} íŒŒì¼ ê²€ì¦ ì™„ë£Œ (í¬ê¸°: {file_size / 1024 / 1024:.2f} MB)")
            except Exception as e:
                logger.warning(f"   âš ï¸ {split_name} íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {e}")
        
        try:
            dataset_dict = load_dataset("json", data_files=data_files)
        except Exception as load_e:
            logger.error(f"âŒ JSONL íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {load_e}")
            logger.error(f"   - Train íŒŒì¼: {data_files.get('train', 'N/A')}")
            logger.error(f"   - Test íŒŒì¼: {data_files.get('test', 'N/A')}")
            
            # ë¬¸ì œê°€ ìˆëŠ” ìƒ˜í”Œ ì°¾ê¸° (58ë²ˆì§¸ ì¤„ ì£¼ë³€ í¬í•¨)
            for split_name, file_path in data_files.items():
                logger.info(f"   ğŸ” {split_name} íŒŒì¼ì—ì„œ ë¬¸ì œ ìƒ˜í”Œ ê²€ìƒ‰ ì¤‘...")
                try:
                    with open(file_path, "r", encoding="utf-8") as f:
                        for line_num, line in enumerate(f, 1):
                            # 58ë²ˆì§¸ ì¤„ ì£¼ë³€ê³¼ ì²˜ìŒ 100ì¤„ í™•ì¸
                            if line_num > 100 and (line_num < 50 or line_num > 70):
                                continue
                            if line.strip():
                                try:
                                    sample = json.loads(line)
                                    # messages êµ¬ì¡° í™•ì¸
                                    if "messages" in sample:
                                        for msg_idx, msg in enumerate(sample["messages"]):
                                            if "content" in msg:
                                                content = msg["content"]
                                                # contentê°€ ë¬¸ìì—´ì¸ ê²½ìš°
                                                if isinstance(content, str):
                                                    logger.error(f"   âŒ {split_name} íŒŒì¼ {line_num}ë²ˆì§¸ ì¤„, ë©”ì‹œì§€ {msg_idx}: contentê°€ ë¬¸ìì—´ì„ (ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•¨)")
                                                    logger.error(f"      content íƒ€ì…: {type(content)}, ê°’: {repr(content)[:200]}")
                                                    logger.error(f"      ì „ì²´ ë©”ì‹œì§€: {json.dumps(msg, ensure_ascii=False, indent=2)[:500]}")
                                                # contentê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
                                                elif isinstance(content, list):
                                                    for content_idx, content_item in enumerate(content):
                                                        # content_itemì´ ë¬¸ìì—´ì¸ ê²½ìš°
                                                        if isinstance(content_item, str):
                                                            logger.error(f"   âŒ {split_name} íŒŒì¼ {line_num}ë²ˆì§¸ ì¤„, ë©”ì‹œì§€ {msg_idx}, content[{content_idx}]: ë¬¸ìì—´ì„ (ê°ì²´ì—¬ì•¼ í•¨)")
                                                            logger.error(f"      content_item íƒ€ì…: {type(content_item)}, ê°’: {repr(content_item)[:200]}")
                                                        # content_itemì´ dictì¸ ê²½ìš°
                                                        elif isinstance(content_item, dict):
                                                            if "text" in content_item:
                                                                text_value = content_item["text"]
                                                                if not isinstance(text_value, str):
                                                                    logger.error(f"   âŒ {split_name} íŒŒì¼ {line_num}ë²ˆì§¸ ì¤„, ë©”ì‹œì§€ {msg_idx}, content[{content_idx}]: textê°€ ë¬¸ìì—´ì´ ì•„ë‹˜")
                                                                    logger.error(f"      íƒ€ì…: {type(text_value)}, ê°’: {repr(text_value)[:100]}")
                                                else:
                                                    logger.error(f"   âŒ {split_name} íŒŒì¼ {line_num}ë²ˆì§¸ ì¤„, ë©”ì‹œì§€ {msg_idx}: contentê°€ ì˜ˆìƒì¹˜ ëª»í•œ íƒ€ì…")
                                                    logger.error(f"      content íƒ€ì…: {type(content)}, ê°’: {repr(content)[:200]}")
                                except json.JSONDecodeError as e:
                                    logger.error(f"   âŒ {split_name} íŒŒì¼ {line_num}ë²ˆì§¸ ì¤„: JSON íŒŒì‹± ì‹¤íŒ¨ - {e}")
                                    logger.error(f"      ì¤„ ë‚´ìš©: {line[:300]}")
                except Exception as e:
                    logger.error(f"   âŒ {split_name} íŒŒì¼ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
                    traceback.print_exc()
            
            raise
        
        logger.info("ğŸ–¼ï¸ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì´ë¯¸ì§€ ê°ì²´ë¡œ ìºìŠ¤íŒ… (lazy loading)...")
        for split in dataset_dict:
            current_features = dataset_dict[split].features
            new_features = current_features.copy()
            if 'images' in new_features:
                def preprocess_images(example):
                    """ì´ë¯¸ì§€ ë°ì´í„° ì „ì²˜ë¦¬ - ì¤‘ì²© ë¦¬ìŠ¤íŠ¸ í‰ë©´í™”"""
                    if 'images' in example and example['images']:
                        example['images'] = validate_image_data(example['images'])
                    # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ìœ ì§€
                    elif 'images' not in example:
                        example['images'] = []
                    return example
                
                dataset_dict[split] = dataset_dict[split].map(preprocess_images)
                # ì´ë¯¸ì§€ê°€ ìˆëŠ” ìƒ˜í”Œë§Œ Sequence(DatasetImage)ë¡œ ìºìŠ¤íŒ…
                # ë¹ˆ ë¦¬ìŠ¤íŠ¸ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
                if isinstance(new_features['images'], Sequence):
                    new_features['images'] = Sequence(DatasetImage(decode=True))
                    dataset_dict[split] = dataset_dict[split].cast(new_features)

        logger.info("âœ… ë©€í‹° ë„ë©”ì¸ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ")
        
        return dataset_dict

    except Exception as e:
        logger.error(f"âŒ ë©€í‹° ë„ë©”ì¸ ë°ì´í„°ì…‹ ë¡œë”© ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        shutil.rmtree(temp_dir, ignore_errors=True)
        raise Exception(f"ğŸ˜¢ ë©€í‹° ë„ë©”ì¸ ë°ì´í„°ì…‹ ë¡œë”© ì‹œë„ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.") from e


def create_simple_collate_fn(processor, max_length: int = 2048, allow_text_only: bool = True):
    """
    SFTTrainerìš© ì»¤ìŠ¤í…€ data collator - ë©€í‹° ë„ë©”ì¸ ì§€ì›
    
    Args:
        processor: AutoProcessor
        max_length: ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´
        allow_text_only: Trueë©´ ì´ë¯¸ì§€ê°€ ì—†ëŠ” í…ìŠ¤íŠ¸ ì „ìš© ìƒ˜í”Œë„ í—ˆìš© (multi-domainìš©, ê¸°ë³¸ê°’ True)
    """
    from trl.trainer.sft_trainer import DataCollatorForVisionLanguageModeling
    
    class CustomSFTDataCollator(DataCollatorForVisionLanguageModeling):
        def __init__(self, processor, max_length: int = 2048, allow_text_only: bool = True):
            super().__init__(processor=processor, max_length=max_length)
            self.processor = processor
            self.max_length = max_length
            self.allow_text_only = allow_text_only
        
        def _collate_language_modeling(self, examples):
            """messagesë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ processorì— ì „ë‹¬"""
            texts = []
            images_list = []
            
            for example in examples:
                # messagesë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
                if "messages" in example:
                    messages = validate_messages(example["messages"])
                    try:
                        # processorì˜ tokenizerë¥¼ ì‚¬ìš©í•˜ì—¬ chat template ì ìš©
                        if hasattr(self.processor, 'tokenizer'):
                            tokenizer = self.processor.tokenizer
                        else:
                            tokenizer = self.processor
                        
                        text = tokenizer.apply_chat_template(
                            messages,
                            tokenize=False,
                            add_generation_prompt=False
                        )
                        texts.append(text)
                    except Exception as e:
                        logger.warning(f"âš ï¸ Chat template ì ìš© ì‹¤íŒ¨, messagesë¥¼ ì§ì ‘ ì‚¬ìš©: {e}")
                        # ì‹¤íŒ¨ ì‹œ messagesë¥¼ ê·¸ëŒ€ë¡œ ì „ë‹¬ (processorê°€ ì²˜ë¦¬í•  ìˆ˜ ìˆìœ¼ë©´)
                        texts.append(messages)
                else:
                    # messagesê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´
                    texts.append("")
                
                # ì´ë¯¸ì§€ ì²˜ë¦¬
                if 'images' in example and example['images']:
                    images = validate_image_data(example['images'])
                    images_list.append(images if images else [])
                else:
                    images_list.append([])
            
            # processor í˜¸ì¶œ
            try:
                # ì´ë¯¸ì§€ê°€ ìˆëŠ” ìƒ˜í”Œê³¼ ì—†ëŠ” ìƒ˜í”Œ ë¶„ë¦¬
                has_images = any(imgs for imgs in images_list)
                
                if has_images:
                    # ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš°
                    output = self.processor(
                        text=texts,
                        images=images_list if has_images else None,
                        return_tensors="pt",
                        padding=True,
                        truncation=True,
                        max_length=self.max_length
                    )
                else:
                    # ì´ë¯¸ì§€ê°€ ì—†ëŠ” ê²½ìš° (í…ìŠ¤íŠ¸ ì „ìš©)
                    if not self.allow_text_only:
                        raise ValueError("ì´ë¯¸ì§€ê°€ ì—†ëŠ” ìƒ˜í”Œì´ ìˆì§€ë§Œ allow_text_only=Falseì…ë‹ˆë‹¤.")
                    
                    # í…ìŠ¤íŠ¸ë§Œ ì²˜ë¦¬
                    if hasattr(self.processor, 'tokenizer'):
                        tokenizer = self.processor.tokenizer
                    else:
                        tokenizer = self.processor
                    
                    output = tokenizer(
                        text=texts,
                        return_tensors="pt",
                        padding=True,
                        truncation=True,
                        max_length=self.max_length
                    )
                
                # labels ìƒì„± (input_idsì™€ ë™ì¼)
                labels = output["input_ids"].clone()
                
                # padding í† í° ë§ˆìŠ¤í‚¹
                pad_token_id = self.processor.tokenizer.pad_token_id if hasattr(self.processor, 'tokenizer') else self.processor.pad_token_id
                if pad_token_id is not None:
                    labels[labels == pad_token_id] = -100
                
                output["labels"] = labels
                return output
                
            except Exception as e:
                logger.error(f"âš ï¸ Processor ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                import traceback
                traceback.print_exc()
                raise
            
        def torch_call(self, examples):
            """torch_call ì˜¤ë²„ë¼ì´ë“œ - _collate_language_modeling ì§ì ‘ í˜¸ì¶œ"""
            return self._collate_language_modeling(examples)
        
        def __call__(self, features):
            assert features is not None, "features is None"

            for i, feature in enumerate(features):
                if "messages" in feature:
                    feature["messages"] = validate_messages(feature["messages"])
                
                # ì´ë¯¸ì§€ ì²˜ë¦¬
                if 'images' in feature and feature['images']:
                    # ì¤‘ì²© ë¦¬ìŠ¤íŠ¸ ë¬¸ì œ í•´ê²°
                    feature['images'] = validate_image_data(feature['images'])
                    if not feature['images']:
                        # ì´ë¯¸ì§€ê°€ ìˆì§€ë§Œ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš°
                        if not self.allow_text_only:
                            raise ValueError(f"ìƒ˜í”Œ {i}ì˜ ì´ë¯¸ì§€ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
                        # í…ìŠ¤íŠ¸ ì „ìš© í—ˆìš© ëª¨ë“œë©´ ì´ë¯¸ì§€ë¥¼ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì„¤ì •
                        feature['images'] = []
                else:
                    # ì´ë¯¸ì§€ê°€ ì—†ëŠ” ê²½ìš°
                    if not self.allow_text_only:
                        raise ValueError(f"ìƒ˜í”Œ {i}ì— ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤! ëª¨ë“  ìƒ˜í”Œì€ ì´ë¯¸ì§€ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.")
                    # í…ìŠ¤íŠ¸ ì „ìš© í—ˆìš© ëª¨ë“œë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì„¤ì •
                    feature['images'] = []
            
            try:
                return self._collate_language_modeling(features)
            except Exception as e:
                import traceback
                traceback.print_exc()
                logger.error(f"âš ï¸ Processor ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                raise
    
    return CustomSFTDataCollator(processor, max_length=max_length, allow_text_only=allow_text_only)


# ë„ë©”ì¸ë³„ ë°ì´í„°ì…‹ ë¹Œë” í•¨ìˆ˜ë“¤
def math_domain_dataset(tokenizer, max_samples: int = 200, use_streaming: bool = True, max_workers: int = 4):
    """ìˆ˜í•™ ë„ë©”ì¸ ë°ì´í„°ì…‹"""
    log_memory_usage("ìˆ˜í•™ ë„ë©”ì¸ ë°ì´í„°ì…‹ ì‹œì‘")
    dataset = get_multi_domain_sft_dataset(
        domain_configs={"math": DOMAIN_DATASETS["math"]},
        tokenizer=tokenizer,
        max_samples_per_domain=max_samples,
        use_streaming=use_streaming,
        max_workers=max_workers
    )
    log_memory_usage("ìˆ˜í•™ ë„ë©”ì¸ ë°ì´í„°ì…‹ ì™„ë£Œ")
    return dataset

def science_domain_dataset(tokenizer, max_samples: int = 200, use_streaming: bool = True, max_workers: int = 4):
    """ê³¼í•™ ë„ë©”ì¸ ë°ì´í„°ì…‹"""
    log_memory_usage("ê³¼í•™ ë„ë©”ì¸ ë°ì´í„°ì…‹ ì‹œì‘")
    dataset = get_multi_domain_sft_dataset(
        domain_configs={"science": DOMAIN_DATASETS["science"]},
        tokenizer=tokenizer,
        max_samples_per_domain=max_samples,
        use_streaming=use_streaming,
        max_workers=max_workers
    )
    log_memory_usage("ê³¼í•™ ë„ë©”ì¸ ë°ì´í„°ì…‹ ì™„ë£Œ")
    return dataset

def code_domain_dataset(tokenizer, max_samples: int = 200, use_streaming: bool = True, max_workers: int = 4):
    """ì½”ë“œ ë„ë©”ì¸ ë°ì´í„°ì…‹"""
    log_memory_usage("ì½”ë“œ ë„ë©”ì¸ ë°ì´í„°ì…‹ ì‹œì‘")
    dataset = get_multi_domain_sft_dataset(
        domain_configs={"code": DOMAIN_DATASETS["code"]},
        tokenizer=tokenizer,
        max_samples_per_domain=max_samples,
        use_streaming=use_streaming,
        max_workers=max_workers
    )
    log_memory_usage("ì½”ë“œ ë„ë©”ì¸ ë°ì´í„°ì…‹ ì™„ë£Œ")
    return dataset

def puzzle_domain_dataset(tokenizer, max_samples: int = 200, use_streaming: bool = True, max_workers: int = 4):
    """í¼ì¦ ë„ë©”ì¸ ë°ì´í„°ì…‹"""
    log_memory_usage("í¼ì¦ ë„ë©”ì¸ ë°ì´í„°ì…‹ ì‹œì‘")
    dataset = get_multi_domain_sft_dataset(
        domain_configs={"puzzle": DOMAIN_DATASETS["puzzle"]},
        tokenizer=tokenizer,
        max_samples_per_domain=max_samples,
        use_streaming=use_streaming,
        max_workers=max_workers
    )
    log_memory_usage("í¼ì¦ ë„ë©”ì¸ ë°ì´í„°ì…‹ ì™„ë£Œ")
    return dataset

def vision_domain_dataset(tokenizer, max_samples: int = 200, use_streaming: bool = True, max_workers: int = 4):
    """ë¹„ì „ ë„ë©”ì¸ ë°ì´í„°ì…‹"""
    log_memory_usage("ë¹„ì „ ë„ë©”ì¸ ë°ì´í„°ì…‹ ì‹œì‘")
    dataset = get_multi_domain_sft_dataset(
        domain_configs={"vision": DOMAIN_DATASETS["vision"]},
        tokenizer=tokenizer,
        max_samples_per_domain=max_samples,
        use_streaming=use_streaming,
        max_workers=max_workers
    )
    log_memory_usage("ë¹„ì „ ë„ë©”ì¸ ë°ì´í„°ì…‹ ì™„ë£Œ")
    return dataset

def ocr_domain_dataset(tokenizer, max_samples: int = 200, use_streaming: bool = True, max_workers: int = 4):
    """OCR ë„ë©”ì¸ ë°ì´í„°ì…‹"""
    log_memory_usage("OCR ë„ë©”ì¸ ë°ì´í„°ì…‹ ì‹œì‘")
    dataset = get_multi_domain_sft_dataset(
        domain_configs={"ocr": DOMAIN_DATASETS["ocr"]},
        tokenizer=tokenizer,
        max_samples_per_domain=max_samples,
        use_streaming=use_streaming,
        max_workers=max_workers
    )
    log_memory_usage("OCR ë„ë©”ì¸ ë°ì´í„°ì…‹ ì™„ë£Œ")
    return dataset

def all_domains_dataset(tokenizer, max_samples_per_domain: int = 200, use_streaming: bool = True, max_workers: int = 4):
    """ëª¨ë“  ë„ë©”ì¸ í†µí•© ë°ì´í„°ì…‹"""
    log_memory_usage("ì „ì²´ ë„ë©”ì¸ ë°ì´í„°ì…‹ ì‹œì‘")
    dataset = get_multi_domain_sft_dataset(
        domain_configs=DOMAIN_DATASETS,
        tokenizer=tokenizer,
        max_samples_per_domain=max_samples_per_domain,
        use_streaming=use_streaming,
        max_workers=max_workers
    )
    log_memory_usage("ì „ì²´ ë„ë©”ì¸ ë°ì´í„°ì…‹ ì™„ë£Œ")
    return dataset


if __name__ == "__main__":
    from transformers import AutoTokenizer
    
    logger.info("ğŸš€ ë©€í‹° ë„ë©”ì¸ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    log_memory_usage("í”„ë¡œê·¸ë¨ ì‹œì‘")
    
    tokenizer = AutoTokenizer.from_pretrained("google/gemma-2b-it")
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
    
    log_memory_usage("í† í¬ë‚˜ì´ì € ë¡œë“œ í›„")
    
    # ì „ì²´ ë„ë©”ì¸ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸
    try:
        logger.info("ğŸ“¦ ì „ì²´ ë„ë©”ì¸ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸")
        dataset = all_domains_dataset(tokenizer, max_samples_per_domain=50, use_streaming=True)
        log_memory_usage("ì „ì²´ ë„ë©”ì¸ ë°ì´í„°ì…‹ ìƒì„± í›„")
        
        logger.info(f"ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ: {dataset}")
        
        # ë„ë©”ì¸ë³„ ìƒ˜í”Œ í™•ì¸
        if 'train' in dataset:
            train_domains = {}
            for i in range(min(100, len(dataset['train']))):
                sample = dataset['train'][i]
                domain = sample.get('domain', 'unknown')
                train_domains[domain] = train_domains.get(domain, 0) + 1
            
            logger.info(f"Train ì„¸íŠ¸ ë„ë©”ì¸ ë¶„í¬: {train_domains}")
        
    except Exception as e:
        logger.error(f"ì „ì²´ ë„ë©”ì¸ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
    
    log_memory_usage("í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    logger.info("âœ… ë©€í‹° ë„ë©”ì¸ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

