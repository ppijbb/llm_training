import logging
from tqdm import tqdm
from datasets import load_dataset, get_dataset_config_names, get_dataset_split_names, concatenate_datasets, load_dataset_builder, Features, Sequence, Value
from transformers import AutoProcessor
import torch
from typing import Dict, Any, List, Optional, Tuple
import traceback
import gc
import os
import sys
import random
import tempfile
import pathlib
import shutil
import json
import hashlib
from datetime import datetime
from PIL import Image
from datasets import Dataset, DatasetDict, load_dataset, Image as DatasetImage, Sequence, Features, Value
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed, CancelledError
import threading

# simple_sft_datasetì˜ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ import
from data.simple_sft_dataset import (
    validate_image_data,
    validate_messages,
    safe_flatten_images,
    get_memory_usage,
    log_memory_usage
)

# ============================================================
# Monkey Patch for datasets library compatibility
# ============================================================
try:
    import datasets.features.features
    # Check if 'List' type is missing (datasets < 4.0.0)
    if "List" not in datasets.features.features._FEATURE_TYPES:
        print("ğŸ› ï¸ Monkey-patching: Registering 'List' feature type as alias for 'Sequence'")
        datasets.features.features._FEATURE_TYPES["List"] = datasets.features.features.Sequence
except Exception as e:
    print(f"âš ï¸ Failed to apply monkey patch for datasets library: {e}")

def ensure_string(value: Any) -> str:
    """
    ê°’ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. Noneì´ë©´ ë¹ˆ ë¬¸ìì—´ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if value is None:
        return ""
    return str(value)

SFT_JSON_FEATURES = Features({
    "messages": [
        {
            "role": Value("string"),
            "content": [
                {
                    "type": Value("string"),
                    "text": Value("string")
                }
            ]
        }
    ],
    "images": [Value("string")],
    "domain": Value("string"),
    "source": Value("string")
})

def _preprocess_images_for_mapping(example, cache_images_dir=None):
    """
    Dataset.map()ì—ì„œ ì‚¬ìš©í•  ì „ì—­ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜.
    picklableí•´ì•¼ í•˜ë¯€ë¡œ ìµœìƒìœ„ ë ˆë²¨ì— ì •ì˜í•©ë‹ˆë‹¤.
    """
    if 'images' in example and example['images']:
        image_paths = example['images']
        if isinstance(image_paths, list):
            fixed_paths = []
            for img_path in image_paths:
                if isinstance(img_path, str) and img_path.strip():
                    if not os.path.isabs(img_path) and cache_images_dir:
                        img_path = os.path.join(cache_images_dir, os.path.basename(img_path))
                    if os.path.exists(img_path):
                        fixed_paths.append(img_path)
            example['images'] = validate_image_data(fixed_paths)
        else:
            example['images'] = validate_image_data(example['images']) if example['images'] else []
    elif 'images' not in example:
        example['images'] = []
    
    # í…ìŠ¤íŠ¸ ì •ê·œí™” ì¶”ê°€ (ImportError ë°©ì§€ë¥¼ ìœ„í•´ ë¡œë”© ì‹œ ìˆ˜í–‰í•˜ë˜ ë¡œì§ì„ ì—¬ê¸°ë¡œ ì´ì „)
    if 'messages' in example and isinstance(example['messages'], list):
        for message in example['messages']:
            if not isinstance(message, dict):
                continue
            if 'content' in message and isinstance(message['content'], list):
                for content_item in message['content']:
                    if not isinstance(content_item, dict):
                        continue
                    if 'text' not in content_item or content_item.get('text') is None:
                        content_item['text'] = ""
                    if 'type' not in content_item:
                        content_item['type'] = "text"
    
    return example

def ensure_messages_text_strings(messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    messagesì˜ ëª¨ë“  í…ìŠ¤íŠ¸ í•„ë“œë¥¼ ë¬¸ìì—´ë¡œ ë³´ì¥í•©ë‹ˆë‹¤.
    contentëŠ” í•­ìƒ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ê°ì²´ ë°°ì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
    """
    result = []
    for msg in messages:
        if not isinstance(msg, dict) or "content" not in msg:
            continue
        
        new_msg = msg.copy()
        content = msg.get("content", [])
        
        # contentê°€ ë¬¸ìì—´ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        if isinstance(content, str):
            content = [{"type": "text", "text": content}]
        # contentê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        elif not isinstance(content, list):
            content = [content] if content else []
        
        new_content = []
        for content_item in content:
            if isinstance(content_item, dict):
                new_item = content_item.copy()
                if "text" in new_item:
                    new_item["text"] = ensure_string(new_item["text"])
                new_content.append(new_item)
            elif isinstance(content_item, str):
                # ë¬¸ìì—´ì¸ ê²½ìš° ê°ì²´ë¡œ ë³€í™˜
                new_content.append({"type": "text", "text": ensure_string(content_item)})
            else:
                # ê¸°íƒ€ íƒ€ì…ì€ ë¬¸ìì—´ë¡œ ë³€í™˜
                new_content.append({"type": "text", "text": ensure_string(content_item)})
        
        new_msg["content"] = new_content
        result.append(new_msg)
    
    return result

def ensure_vlm_format(sample: Dict[str, Any]) -> Dict[str, Any]:
    """
    ëª¨ë“  ìƒ˜í”Œì„ VLM í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì´ë¯¸ì§€ placeholderë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
    Qwen3-VL-MoEëŠ” ì´ë¯¸ì§€ í† í°ê³¼ ì´ë¯¸ì§€ featuresì˜ ê°œìˆ˜ê°€ ì¼ì¹˜í•´ì•¼ í•˜ë¯€ë¡œ,
    ì‹¤ì œ ì´ë¯¸ì§€ê°€ ìˆì„ ë•Œë§Œ ì´ë¯¸ì§€ placeholderë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
    """
    if not isinstance(sample, dict):
        return sample
    
    # messagesê°€ ì—†ìœ¼ë©´ ë³€í™˜ ë¶ˆê°€
    if "messages" not in sample or not isinstance(sample["messages"], list):
        return sample
    
    messages = sample["messages"].copy()
    images = sample.get("images", [])
    
    # imagesê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ˆë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    if not isinstance(images, list):
        images = [images] if images else []
    
    # ì´ë¯¸ì§€ê°€ ë¬¸ìì—´ ê²½ë¡œì¸ì§€ í™•ì¸ (ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ì´ ìˆëŠ”ì§€)
    has_images = False
    for img in images:
        if isinstance(img, str) and img.strip():
            # íŒŒì¼ ê²½ë¡œê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            if os.path.exists(img):
                has_images = True
                break
    
    # ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì´ë¯¸ì§€ placeholder ì¶”ê°€
    if has_images:
        first_user_msg_found = False
        for i, msg in enumerate(messages):
            if not isinstance(msg, dict) or msg.get("role") != "user":
                continue
            
            content = msg.get("content", [])
            if not isinstance(content, list):
                content = [content] if content else []
            
            # ì´ë¯¸ì§€ placeholderê°€ ìˆëŠ”ì§€ í™•ì¸
            has_image_placeholder = False
            for item in content:
                if isinstance(item, dict) and item.get("type") == "image":
                    has_image_placeholder = True
                    break
            
            # ì²« ë²ˆì§¸ user ë©”ì‹œì§€ì— ì´ë¯¸ì§€ placeholder ì¶”ê°€ (ì—†ëŠ” ê²½ìš°ì—ë§Œ)
            if not first_user_msg_found and not has_image_placeholder:
                content.insert(0, {"type": "image"})
                msg["content"] = content
                first_user_msg_found = True
                break
    
    # messages ì •ê·œí™”
    messages = ensure_messages_text_strings(messages)
    
    result = sample.copy()
    result["messages"] = messages
    result["images"] = images if images else []
    
    return result

def sanitize_sample_for_json(sample: Dict[str, Any]) -> Dict[str, Any]:
    """
    ìƒ˜í”Œì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.
    PIL Image ê°ì²´ë‚˜ ì§ë ¬í™” ë¶ˆê°€ëŠ¥í•œ ê°ì²´ë¥¼ ì œê±°í•©ë‹ˆë‹¤.
    """
    if not isinstance(sample, dict):
        return sample
    
    result = {}
    for key, value in sample.items():
        if key == "images":
            # imagesëŠ” ë¬¸ìì—´ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ë§Œ ìœ ì§€
            if isinstance(value, list):
                sanitized_images = []
                for img in value:
                    if isinstance(img, str) and img.strip():
                        sanitized_images.append(img)
                    # PIL Imageë‚˜ ë‹¤ë¥¸ ê°ì²´ëŠ” ë¬´ì‹œ (ì´ë¯¸ íŒŒì¼ë¡œ ì €ì¥ë˜ì–´ ìˆì–´ì•¼ í•¨)
                result[key] = sanitized_images
            else:
                result[key] = []
        else:
            # ë‹¤ë¥¸ í•„ë“œëŠ” ê·¸ëŒ€ë¡œ ë³µì‚¬ (ì¬ê·€ì ìœ¼ë¡œ ì²˜ë¦¬)
            if isinstance(value, dict):
                result[key] = sanitize_sample_for_json(value)
            elif isinstance(value, list):
                result[key] = [
                    sanitize_sample_for_json(item) if isinstance(item, dict) else item
                    for item in value
                ]
            else:
                # PIL Imageë‚˜ ë‹¤ë¥¸ ì§ë ¬í™” ë¶ˆê°€ëŠ¥í•œ ê°ì²´ëŠ” ë¬´ì‹œ
                try:
                    json.dumps(value)
                    result[key] = value
                except (TypeError, ValueError):
                    # ì§ë ¬í™” ë¶ˆê°€ëŠ¥í•œ ê°ì²´ëŠ” ë¬¸ìì—´ë¡œ ë³€í™˜ ì‹œë„
                    result[key] = str(value)
    
    return result

def dataset_exists(dataset_name: str) -> bool:
    """
    ì£¼ì–´ì§„ ë°ì´í„°ì…‹ì´ Hugging Face Hubì— ì¡´ì¬í•˜ëŠ”ì§€ ê°„ë‹¨íˆ í™•ì¸í•©ë‹ˆë‹¤.
    ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ì ‘ê·¼ ë¶ˆê°€í•˜ë©´ Falseë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        _ = get_dataset_config_names(dataset_name)
        return True
    except Exception:
        logger.warning(f"âš ï¸ ë°ì´í„°ì…‹ì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {dataset_name} (ê±´ë„ˆëœ€)")
        return False

# ============================================================
# ë°ì´í„°ì…‹ë³„ ì „ìš© ë³€í™˜ í”„ë¡œì„¸ì„œ í•¨ìˆ˜ë“¤
# ============================================================

def process_rstar_coder(dataset, dataset_name: str, max_samples: int, log_detail: bool = False) -> List[Dict[str, Any]]:
    """
    microsoft/rStar-Coder ë°ì´í„°ì…‹ ì „ìš© í”„ë¡œì„¸ì„œ
    ë°ì´í„°ì…‹ ì „ì²´ë¥¼ ì²˜ë¦¬í•˜ì—¬ messages í˜•ì‹ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    """
    results = []
    sample_count = 0
    # failed_count removed
    
    logger.debug(f"   ğŸ”§ rStar-Coder ì „ìš© í”„ë¡œì„¸ì„œ ì‹œì‘ (ìµœëŒ€ {max_samples}ê°œ ìƒ˜í”Œ)")
    
    for idx, sample in enumerate(dataset):
        if sample_count >= max_samples:
            break
        
        try:
            # rStar-Coderì˜ ì‹¤ì œ ì»¬ëŸ¼: question, seed_question, seed_source, response, code
            question = sample.get("question", "")
            seed_question = sample.get("seed_question", "")
            response = sample.get("response", "")
            code = sample.get("code", "")
            
            # ë””ë²„ê¹…: ì²˜ìŒ ëª‡ ê°œ ìƒ˜í”Œ ë¡œê¹… (DEBUG ë ˆë²¨)
            if log_detail and idx < 2:
                logger.debug(f"   ğŸ” rStar-Coder ìƒ˜í”Œ {idx}: keys={list(sample.keys())}")
            
            # question ë˜ëŠ” seed_question ì¤‘ í•˜ë‚˜ëŠ” ìˆì–´ì•¼ í•¨
            user_prompt = question.strip() if question and question.strip() else (seed_question.strip() if seed_question and seed_question.strip() else "")
            if not user_prompt:
                raise RuntimeError(f"Sample processing failed")
            
            # responseì™€ code ì¤‘ í•˜ë‚˜ëŠ” ìˆì–´ì•¼ í•¨
            assistant_content_parts = []
            if response and response.strip():
                assistant_content_parts.append(response.strip())
            if code and code.strip():
                if assistant_content_parts:
                    assistant_content_parts.append(f"\n\n```python\n{code.strip()}\n```")
                else:
                    assistant_content_parts.append(code.strip())
            
            if not assistant_content_parts:
                raise RuntimeError(f"Sample processing failed")
            
            assistant_text = "\n".join(assistant_content_parts)
            
            messages = [
                {"role": "user", "content": [{"type": "text", "text": user_prompt}]},
                {"role": "assistant", "content": [{"type": "text", "text": assistant_text}]}
            ]
            
            # Revert to text-only (no dummy image)
            results.append({"messages": messages, "images": []})
            sample_count += 1
            
        except Exception as e:
            logger.error(f"   âŒ rStar-Coder ìƒ˜í”Œ {idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise RuntimeError(f"Sample processing failed")
    

    return results

def process_metamath(dataset, dataset_name: str, max_samples: int, log_detail: bool = False) -> List[Dict[str, Any]]:
    """
    meta-math/MetaMathQA ë°ì´í„°ì…‹ ì „ìš© í”„ë¡œì„¸ì„œ
    """
    results = []
    sample_count = 0
    # failed_count removed
    
    logger.debug(f"   ğŸ”§ MetaMath ì „ìš© í”„ë¡œì„¸ì„œ ì‹œì‘ (ìµœëŒ€ {max_samples}ê°œ ìƒ˜í”Œ)")
    
    for idx, sample in enumerate(dataset):
        if sample_count >= max_samples:
            break
        
        try:
            query = sample.get("query", "")
            response = sample.get("response", "")
            
            if not query or not response:
                raise RuntimeError(f"Sample processing failed")
            
            messages = [
                {"role": "user", "content": [{"type": "text", "text": query}]},
                {"role": "assistant", "content": [{"type": "text", "text": response}]}
            ]
            
            results.append({"messages": messages, "images": []})
            sample_count += 1
            
        except Exception as e:
            logger.error(f"   âŒ MetaMath ìƒ˜í”Œ {idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise RuntimeError(f"Sample processing failed")
    

    return results

def process_math_python_reasoning(dataset, dataset_name: str, max_samples: int, log_detail: bool = False) -> List[Dict[str, Any]]:
    """
    sdiazlor/math-python-reasoning-dataset ì „ìš© í”„ë¡œì„¸ì„œ
    """
    results = []
    sample_count = 0
    # failed_count removed
    
    logger.debug(f"   ğŸ”§ Math-Python-Reasoning ì „ìš© í”„ë¡œì„¸ì„œ ì‹œì‘ (ìµœëŒ€ {max_samples}ê°œ ìƒ˜í”Œ)")
    
    for idx, sample in enumerate(dataset):
        if sample_count >= max_samples:
            break
        
        try:
            prompt = sample.get("prompt", "")
            completion = sample.get("completion", "")
            system_prompt = sample.get("system_prompt", "")
            
            # instruction/output í˜•ì‹ë„ ì§€ì› (í•˜ìœ„ í˜¸í™˜ì„±)
            if not prompt:
                prompt = sample.get("instruction", "")
            if not completion:
                completion = sample.get("output", "")
            
            if not prompt or not completion:
                raise RuntimeError(f"Sample processing failed")
            
            messages = []
            
            # system_promptê°€ ìˆìœ¼ë©´ system ë©”ì‹œì§€ë¡œ ì¶”ê°€
            if system_prompt:
                messages.append({"role": "system", "content": [{"type": "text", "text": system_prompt}]})
            
            messages.extend([
                {"role": "user", "content": [{"type": "text", "text": prompt}]},
                {"role": "assistant", "content": [{"type": "text", "text": completion}]}
            ])
            
            results.append({"messages": messages, "images": []})
            sample_count += 1
            
        except Exception as e:
            logger.error(f"   âŒ Math-Python-Reasoning ìƒ˜í”Œ {idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise RuntimeError(f"Sample processing failed")
    

    return results

def process_llava_onevision(dataset, dataset_name: str, max_samples: int, log_detail: bool = False) -> List[Dict[str, Any]]:
    """
    lmms-lab/LLaVA-OneVision-Data ì „ìš© í”„ë¡œì„¸ì„œ (multimodal)
    """
    results = []
    sample_count = 0
    # failed_count removed
    
    logger.debug(f"   ğŸ”§ LLaVA-OneVision ì „ìš© í”„ë¡œì„¸ì„œ ì‹œì‘ (ìµœëŒ€ {max_samples}ê°œ ìƒ˜í”Œ)")
    
    for idx, sample in enumerate(dataset):
        if sample_count >= max_samples:
            break
        
        try:
            # conversations + images í˜•ì‹
            conversations = sample.get("conversations", [])
            images = sample.get("images", [])
            
            if not conversations:
                raise RuntimeError(f"Sample processing failed")
            
            messages = []
            for conv in conversations:
                role = conv.get("from", "")
                value = conv.get("value", "")
                
                if role == "human":
                    messages.append({"role": "user", "content": [{"type": "text", "text": value}]})
                elif role == "gpt":
                    messages.append({"role": "assistant", "content": [{"type": "text", "text": value}]})
            
            if not messages:
                raise RuntimeError(f"Sample processing failed")
            
            # ì´ë¯¸ì§€ ì²˜ë¦¬
            image_list = []
            if images:
                flattened_images = validate_image_data(images)
                image_list = flattened_images if flattened_images else []
            
            results.append({"messages": messages, "images": image_list})
            sample_count += 1
            
        except Exception as e:
            logger.error(f"   âŒ LLaVA-OneVision ìƒ˜í”Œ {idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise RuntimeError(f"Sample processing failed")
    

    return results

def process_olmocr(dataset, dataset_name: str, max_samples: int, log_detail: bool = False) -> List[Dict[str, Any]]:
    """
    allenai/olmOCR-mix-1025 ì „ìš© í”„ë¡œì„¸ì„œ (OCR, multimodal)
    
    ë°ì´í„° êµ¬ì¡°:
    - natural_text: OCRëœ í…ìŠ¤íŠ¸ (ground truth)
    - pdf_relpath: PDF íŒŒì¼ ê²½ë¡œ (tar.gz ë‚´ë¶€)
    - url: ì›ë³¸ PDF URL
    - image: PDF í˜ì´ì§€ ì´ë¯¸ì§€ (ìˆëŠ” ê²½ìš°)
    
    VLMìš© instruction: "ì´ ë¬¸ì„œ í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”"
    """
    results = []
    sample_count = 0
    # failed_count removed
    
    logger.debug(f"   ğŸ”§ olmOCR ì „ìš© í”„ë¡œì„¸ì„œ ì‹œì‘ (ìµœëŒ€ {max_samples}ê°œ ìƒ˜í”Œ)")
    
    for idx, sample in enumerate(dataset):
        if sample_count >= max_samples:
            break
        
        try:
            # OCRëœ í…ìŠ¤íŠ¸ (ground truth)
            natural_text = sample.get("natural_text", "")
            if not natural_text or not natural_text.strip():
                if log_detail and idx < 5:
                    logger.warning(f"   âš ï¸ olmOCR ìƒ˜í”Œ {idx}: natural_textê°€ ë¹„ì–´ìˆìŒ")
                raise RuntimeError(f"Sample processing failed")
            
            # ì´ë¯¸ì§€ ì²˜ë¦¬ (PDF í˜ì´ì§€ ì´ë¯¸ì§€)
            image_list = []
            
            # 1. image í•„ë“œ í™•ì¸ (DatasetImage íƒ€ì…)
            if "image" in sample:
                img = sample["image"]
                if img is not None:
                    flattened_images = validate_image_data([img])
                    if flattened_images:
                        image_list = flattened_images
            
            # 2. images í•„ë“œ í™•ì¸ (ë¦¬ìŠ¤íŠ¸)
            if not image_list and "images" in sample:
                images = sample["images"]
                if images:
                    flattened_images = validate_image_data(images)
                    if flattened_images:
                        image_list = flattened_images
            
            # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ OCR íƒœìŠ¤í¬ê°€ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ ê±´ë„ˆë›°ê¸°
            if not image_list:
                raise RuntimeError(f"Sample processing failed")
            
            # Instruction: OCR íƒœìŠ¤í¬
            instruction = "ì´ ë¬¸ì„œ í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”. ì´ë¯¸ì§€ì—ì„œ ë³´ì´ëŠ” ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì •í™•í•˜ê²Œ ì½ì–´ì£¼ì„¸ìš”."
            
            # Messages êµ¬ì„± (ì´ë¯¸ì§€ í•„ìˆ˜)
            messages = [
                {
                    "role": "user",
                    "content": [
                        {"type": "image"},
                        {"type": "text", "text": instruction}
                    ]
                },
                {
                    "role": "assistant",
                    "content": [{"type": "text", "text": natural_text.strip()}]
                }
            ]
            
            results.append({"messages": messages, "images": image_list})
            sample_count += 1
            
        except Exception as e:
            logger.debug(f"   âŒ olmOCR ìƒ˜í”Œ {idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise RuntimeError(f"Sample processing failed")
    

    
    return results

def process_cord(dataset, dataset_name: str, max_samples: int, log_detail: bool = False) -> List[Dict[str, Any]]:
    """
    naver-clova-ix/cord-v2 ì „ìš© í”„ë¡œì„¸ì„œ (OCR, multimodal)
    
    ë°ì´í„° êµ¬ì¡° (ì›¹ì‚¬ì´íŠ¸ ì°¸ê³ ):
    - image: ì˜ìˆ˜ì¦ ì´ë¯¸ì§€ (DatasetImage íƒ€ì…)
    - ground_truth: OCRëœ í…ìŠ¤íŠ¸ (ground truth, JSON í˜•ì‹ì¼ ìˆ˜ ìˆìŒ)
    
    VLMìš© instruction: "ì´ ì˜ìˆ˜ì¦ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”"
    """
    results = []
    sample_count = 0
    # failed_count removed
    
    logger.debug(f"   ğŸ”§ CORD-v2 ì „ìš© í”„ë¡œì„¸ì„œ ì‹œì‘ (ìµœëŒ€ {max_samples}ê°œ ìƒ˜í”Œ)")
    
    for idx, sample in enumerate(dataset):
        if sample_count >= max_samples:
            break
        
        try:
            # OCRëœ í…ìŠ¤íŠ¸ (ground truth)
            ground_truth = sample.get("ground_truth", "")
            if not ground_truth or not str(ground_truth).strip():
                if log_detail and idx < 5:
                    logger.warning(f"   âš ï¸ CORD-v2 ìƒ˜í”Œ {idx}: ground_truthê°€ ë¹„ì–´ìˆìŒ")
                raise RuntimeError(f"Sample processing failed")
            
            # ground_truthê°€ JSON í˜•ì‹ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë¬¸ìì—´ë¡œ ë³€í™˜
            if isinstance(ground_truth, dict):
                import json
                ground_truth = json.dumps(ground_truth, ensure_ascii=False)
            else:
                ground_truth = str(ground_truth).strip()
            
            # ì´ë¯¸ì§€ ì²˜ë¦¬
            image_list = []
            
            # image í•„ë“œ í™•ì¸ (DatasetImage íƒ€ì…)
            if "image" in sample:
                img = sample["image"]
                if img is not None:
                    flattened_images = validate_image_data([img])
                    if flattened_images:
                        image_list = flattened_images
            
            # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ OCR íƒœìŠ¤í¬ê°€ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ ê±´ë„ˆë›°ê¸°
            if not image_list:
                raise RuntimeError(f"Sample processing failed")
            
            # Instruction: OCR íƒœìŠ¤í¬ (ì˜ìˆ˜ì¦ íŠ¹í™”)
            instruction = "ì´ ì˜ìˆ˜ì¦ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”. ì´ë¯¸ì§€ì—ì„œ ë³´ì´ëŠ” ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì •í™•í•˜ê²Œ ì½ì–´ì£¼ì„¸ìš”."
            
            # Messages êµ¬ì„± (ì´ë¯¸ì§€ í•„ìˆ˜)
            messages = [
                {
                    "role": "user",
                    "content": [
                        {"type": "image"},
                        {"type": "text", "text": instruction}
                    ]
                },
                {
                    "role": "assistant",
                    "content": [{"type": "text", "text": ground_truth}]
                }
            ]
            
            results.append({"messages": messages, "images": image_list})
            sample_count += 1
            
        except Exception as e:
            logger.debug(f"   âŒ CORD-v2 ìƒ˜í”Œ {idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise RuntimeError(f"Sample processing failed")
    

    
    return results

def process_ask_science_qg(dataset, dataset_name: str, max_samples: int, log_detail: bool = False) -> List[Dict[str, Any]]:
    """
    dhmeltzer/ask-science-qg ì „ìš© í”„ë¡œì„¸ì„œ (Science Q&A, í…ìŠ¤íŠ¸ ì „ìš©)
    
    ë°ì´í„° êµ¬ì¡° (ì›¹ì‚¬ì´íŠ¸ ì°¸ê³ ):
    - title: ì§ˆë¬¸ ì œëª©
    - selftext: ì§ˆë¬¸ ë³¸ë¬¸ (ì„ íƒì , ë¹„ì–´ìˆì„ ìˆ˜ ìˆìŒ)
    - answers.text: ë‹µë³€ í…ìŠ¤íŠ¸ (sequence/ë¦¬ìŠ¤íŠ¸)
    - answers.score: ë‹µë³€ ì ìˆ˜ (sequence/ë¦¬ìŠ¤íŠ¸)
    
    VLMìš© instruction: title + selftextë¥¼ ì§ˆë¬¸ìœ¼ë¡œ, answers.textë¥¼ ë‹µë³€ìœ¼ë¡œ
    """
    results = []
    sample_count = 0
    # failed_count removed
    
    logger.debug(f"   ğŸ”§ ask-science-qg ì „ìš© í”„ë¡œì„¸ì„œ ì‹œì‘ (ìµœëŒ€ {max_samples}ê°œ ìƒ˜í”Œ)")
    
    # ì²˜ìŒ ëª‡ ê°œ ìƒ˜í”Œì˜ ì‹¤ì œ êµ¬ì¡°ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•œ ë””ë²„ê¹… (DEBUG ë ˆë²¨)
    debug_samples_checked = 0
    max_debug_samples = 3  # 10 -> 3ìœ¼ë¡œ ê°ì†Œ
    
    for idx, sample in enumerate(dataset):
        if sample_count >= max_samples:
            break
        
        try:
            # ì²˜ìŒ ëª‡ ê°œ ìƒ˜í”Œì˜ ì „ì²´ êµ¬ì¡° ë¡œê¹… (DEBUG ë ˆë²¨)
            if debug_samples_checked < max_debug_samples and log_detail:
                logger.debug(f"   ğŸ” ask-science-qg ìƒ˜í”Œ {idx} êµ¬ì¡°: keys={list(sample.keys())}")
                debug_samples_checked += 1
            
            # ì§ˆë¬¸ êµ¬ì„±: title + selftext
            title = sample.get("title", "")
            selftext = sample.get("selftext", "")
            
            # titleì€ í•„ìˆ˜
            if not title or not str(title).strip():
                raise RuntimeError(f"Sample processing failed")
            
            # ì§ˆë¬¸ í…ìŠ¤íŠ¸ êµ¬ì„±
            question_parts = [str(title).strip()]
            if selftext and str(selftext).strip():
                question_parts.append(str(selftext).strip())
            question = "\n\n".join(question_parts)
            
            # ë‹µë³€ ì¶”ì¶œ - ì›¹ì‚¬ì´íŠ¸ êµ¬ì¡°: answers.text (sequence), answers.score (sequence)
            # HuggingFace datasetsì—ì„œ sequenceëŠ” í‰íƒ„í™”ë  ìˆ˜ ìˆìŒ: answers.text -> ìµœìƒìœ„ ë ˆë²¨
            answer_text = ""
            
            # Case 1: answers.textê°€ í‰íƒ„í™”ë˜ì–´ ìµœìƒìœ„ ë ˆë²¨ì— ìˆëŠ” ê²½ìš°
            answer_texts = sample.get("answers.text", None)
            answer_scores = sample.get("answers.score", None)
            
            # Case 2: answersê°€ dictì´ê³  answers.textê°€ ìˆëŠ” ê²½ìš°
            if answer_texts is None:
                answers = sample.get("answers", {})
                if isinstance(answers, dict) and len(answers) > 0:
                    answer_texts = answers.get("text", None)
                    answer_scores = answers.get("score", None)
            
            # Case 3: answersê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
            if answer_texts is None:
                answers = sample.get("answers", {})
                if isinstance(answers, (list, tuple)) and len(answers) > 0:
                    first_answer = answers[0]
                    if isinstance(first_answer, dict):
                        answer_texts = first_answer.get("text", None)
                    else:
                        answer_texts = first_answer
            
            # Case 4: answersê°€ ì§ì ‘ ë¬¸ìì—´ì¸ ê²½ìš°
            if answer_texts is None:
                answers = sample.get("answers", "")
                if isinstance(answers, str):
                    answer_texts = answers
            
            # answer_texts ì²˜ë¦¬
            if answer_texts is not None:
                # sequenceë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ì´ë¯¸ ë¦¬ìŠ¤íŠ¸ì¼ ìˆ˜ë„ ìˆìŒ)
                if not isinstance(answer_texts, (list, tuple)):
                    # ë‹¨ì¼ ê°’ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    answer_texts = [answer_texts]
                
                if len(answer_texts) > 0:
                    # scoresê°€ ìˆê³  ê¸¸ì´ê°€ ê°™ìœ¼ë©´ ê°€ì¥ ë†’ì€ ì ìˆ˜ ì„ íƒ
                    if answer_scores is not None:
                        if not isinstance(answer_scores, (list, tuple)):
                            answer_scores = [answer_scores]
                        
                        if len(answer_scores) == len(answer_texts) and len(answer_scores) > 0:
                            try:
                                # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ë‹µë³€ ì„ íƒ
                                best_idx = max(range(len(answer_scores)), key=lambda i: answer_scores[i] if isinstance(answer_scores[i], (int, float)) else 0)
                                answer_text = str(answer_texts[best_idx]).strip()
                            except Exception as e:
                                # ì ìˆ˜ ì„ íƒ ì‹¤íŒ¨ ì‹œ ì²« ë²ˆì§¸ ë‹µë³€ ì‚¬ìš©
                                answer_text = str(answer_texts[0]).strip()
                        else:
                            # scores ê¸¸ì´ê°€ ë‹¤ë¥´ë©´ ì²« ë²ˆì§¸ ë‹µë³€ ì‚¬ìš©
                            answer_text = str(answer_texts[0]).strip()
                    else:
                        # scoresê°€ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ë‹µë³€ ì‚¬ìš©
                        answer_text = str(answer_texts[0]).strip()
            
            # ë‹µë³€ì´ ë¹„ì–´ìˆìœ¼ë©´ ê±´ë„ˆë›°ê¸°
            if not answer_text:
                raise RuntimeError(f"Sample processing failed")
            
            # Messages êµ¬ì„±
            messages = [
                {
                    "role": "user",
                    "content": [{"type": "text", "text": question}]
                },
                {
                    "role": "assistant",
                    "content": [{"type": "text", "text": answer_text}]
                }
            ]
            
            results.append({"messages": messages, "images": []})
            sample_count += 1
            
        except Exception as e:
            logger.debug(f"   âŒ ask-science-qg ìƒ˜í”Œ {idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise RuntimeError(f"Sample processing failed")
    

    
    return results

def process_ocr_vqa(dataset, dataset_name: str, max_samples: int, log_detail: bool = False) -> List[Dict[str, Any]]:
    """
    howard-hou/OCR-VQA ì „ìš© í”„ë¡œì„¸ì„œ (OCR VQA, multimodal)
    
    ë°ì´í„° êµ¬ì¡° (ì›¹ì‚¬ì´íŠ¸ ì°¸ê³ ):
    - image: ì´ë¯¸ì§€ (DatasetImage íƒ€ì…)
    - questions: ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ (sequence)
    - answers: ë‹µë³€ ë¦¬ìŠ¤íŠ¸ (sequence)
    - ocr_tokens: OCR í† í° (sequence, ì„ íƒì )
    - ocr_info: OCR ì •ë³´ (list, ì„ íƒì )
    
    í•˜ë‚˜ì˜ ì´ë¯¸ì§€ì— ì—¬ëŸ¬ ì§ˆë¬¸-ë‹µë³€ ìŒì´ ìˆìœ¼ë¯€ë¡œ, ê° ìŒì„ ë³„ë„ ìƒ˜í”Œë¡œ ìƒì„±
    """
    results = []
    sample_count = 0
    # failed_count removed
    
    logger.debug(f"   ğŸ”§ OCR-VQA ì „ìš© í”„ë¡œì„¸ì„œ ì‹œì‘ (ìµœëŒ€ {max_samples}ê°œ ìƒ˜í”Œ)")
    
    debug_samples_checked = 0
    max_debug_samples = 2  # 5 -> 2ë¡œ ê°ì†Œ
    
    for idx, sample in enumerate(dataset):
        if sample_count >= max_samples:
            break
        
        try:
            # ì²˜ìŒ ëª‡ ê°œ ìƒ˜í”Œì˜ êµ¬ì¡° í™•ì¸ (DEBUG ë ˆë²¨)
            if debug_samples_checked < max_debug_samples and log_detail:
                logger.debug(f"   ğŸ” OCR-VQA ìƒ˜í”Œ {idx} êµ¬ì¡°: keys={list(sample.keys())}")
                debug_samples_checked += 1
            
            # ì´ë¯¸ì§€ ì²˜ë¦¬
            image = sample.get("image", None)
            if image is None:
                raise RuntimeError(f"Sample processing failed")
            
            # ì´ë¯¸ì§€ ê²€ì¦
            image_list = validate_image_data([image])
            if not image_list:
                raise RuntimeError(f"Sample processing failed")
            
            # questionsì™€ answers ì¶”ì¶œ
            questions = sample.get("questions", None)
            answers = sample.get("answers", None)
            
            # questionsì™€ answersê°€ ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸
            if not isinstance(questions, (list, tuple)) or not isinstance(answers, (list, tuple)):
                raise RuntimeError(f"Sample processing failed")
            
            if len(questions) == 0 or len(answers) == 0:
                raise RuntimeError(f"Sample processing failed")
            
            # ì§ˆë¬¸ê³¼ ë‹µë³€ì˜ ê°œìˆ˜ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ìµœì†Œ ê°œìˆ˜ë§Œí¼ë§Œ ì²˜ë¦¬
            num_pairs = min(len(questions), len(answers))
            
            # ê° ì§ˆë¬¸-ë‹µë³€ ìŒì„ ë³„ë„ ìƒ˜í”Œë¡œ ìƒì„±
            for qa_idx in range(num_pairs):
                if sample_count >= max_samples:
                    break
                
                question = str(questions[qa_idx]).strip()
                answer = str(answers[qa_idx]).strip()
                
                if not question or not answer:
                    continue
                
                # Messages êµ¬ì„±
                messages = [
                    {
                        "role": "user",
                        "content": [
                            {"type": "image"},
                            {"type": "text", "text": question}
                        ]
                    },
                    {
                        "role": "assistant",
                        "content": [{"type": "text", "text": answer}]
                    }
                ]
                
                results.append({"messages": messages, "images": image_list})
                sample_count += 1
            
        except Exception as e:
            logger.debug(f"   âŒ OCR-VQA ìƒ˜í”Œ {idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise RuntimeError(f"Sample processing failed")
    

    
    return results

def process_generic_instruction(dataset, dataset_name: str, max_samples: int, log_detail: bool = False) -> List[Dict[str, Any]]:
    """
    ë²”ìš© instruction-output í˜•ì‹ í”„ë¡œì„¸ì„œ
    """
    results = []
    sample_count = 0
    # failed_count removed
    
    logger.debug(f"   ğŸ”§ ë²”ìš© Instruction í”„ë¡œì„¸ì„œ ì‹œì‘ ({dataset_name}, ìµœëŒ€ {max_samples}ê°œ ìƒ˜í”Œ)")
    
    for idx, sample in enumerate(dataset):
        if sample_count >= max_samples:
            break
        
        try:
            # messages í˜•ì‹ì´ ì´ë¯¸ ìˆëŠ” ê²½ìš°
            if "messages" in sample and sample["messages"]:
                messages = validate_messages(sample["messages"])
                images = sample.get("images", [])
                results.append({"messages": messages, "images": images if images else []})
                sample_count += 1
                continue
            
            # trajectory í˜•ì‹ (UltraInteract_sft)
            if "trajectory" in sample and sample["trajectory"]:
                trajectory = sample["trajectory"]
                if isinstance(trajectory, list):
                    messages = []
                    for turn in trajectory:
                        if isinstance(turn, dict):
                            role = turn.get("role", "")
                            content = turn.get("content", "")
                            if role and content:
                                if role in ["user", "human"]:
                                    messages.append({"role": "user", "content": [{"type": "text", "text": str(content)}]})
                                elif role in ["assistant", "gpt"]:
                                    messages.append({"role": "assistant", "content": [{"type": "text", "text": str(content)}]})
                    if messages:
                        results.append({"messages": messages, "images": []})
                        sample_count += 1
                        continue
            
            # conversations í˜•ì‹
            if "conversations" in sample:
                conversations = sample["conversations"]
                messages = []
                for conv in conversations:
                    role = conv.get("from", conv.get("role", ""))
                    value = conv.get("value", conv.get("content", ""))
                    
                    if role in ["human", "user"]:
                        messages.append({"role": "user", "content": [{"type": "text", "text": value}]})
                    elif role in ["gpt", "assistant"]:
                        messages.append({"role": "assistant", "content": [{"type": "text", "text": value}]})
                
                if messages:
                    results.append({"messages": messages, "images": []})
                    sample_count += 1
                    continue
            
            # instruction-output í˜•ì‹
            if "instruction" in sample:
                instruction = sample.get("instruction", "")
                output = sample.get("output", sample.get("response", ""))
                
                if instruction and output:
                    messages = [
                        {"role": "user", "content": [{"type": "text", "text": instruction}]},
                        {"role": "assistant", "content": [{"type": "text", "text": output}]}
                    ]
                    results.append({"messages": messages, "images": []})
                    sample_count += 1
                    continue
            
            # prompt-response í˜•ì‹
            if "prompt" in sample:
                prompt = sample.get("prompt", "")
                response = sample.get("response", sample.get("completion", sample.get("output", "")))
                
                if prompt and response:
                    messages = [
                        {"role": "user", "content": [{"type": "text", "text": str(prompt)}]},
                        {"role": "assistant", "content": [{"type": "text", "text": str(response)}]}
                    ]
                    results.append({"messages": messages, "images": []})
                    sample_count += 1
                    continue
            
            # question-answer í˜•ì‹
            if "question" in sample:
                question = sample.get("question", "")
                answer = sample.get("answer", sample.get("response", ""))
                
                # ScienceQA í˜•ì‹ ì§€ì› (choices, hint, solution í¬í•¨)
                if "choices" in sample and "answer" in sample:
                    choices = sample["choices"]
                    hint = sample.get("hint", "")
                    solution = sample.get("solution", "")
                    
                    # ì§ˆë¬¸ êµ¬ì„±
                    query_text = question
                    if hint:
                        query_text = f"Hint: {hint}\n{query_text}"
                    
                    if choices:
                        query_text += "\nChoices:\n"
                        for i, choice in enumerate(choices):
                            query_text += f"({i}) {choice}\n"
                    
                    # ì •ë‹µ êµ¬ì„±
                    answer_idx = sample["answer"]
                    try:
                        # answerê°€ ì •ìˆ˜ ì¸ë±ìŠ¤ì¸ ê²½ìš°
                        if isinstance(answer_idx, int):
                            answer_text = choices[answer_idx]
                        else:
                            answer_text = str(answer_idx)
                    except:
                        answer_text = str(answer_idx)
                        
                    if solution:
                        answer_text += f"\n\nExplanation: {solution}"
                    
                    messages = [
                        {"role": "user", "content": [{"type": "text", "text": query_text}]},
                        {"role": "assistant", "content": [{"type": "text", "text": answer_text}]}
                    ]
                    
                    # ì´ë¯¸ì§€ ì²˜ë¦¬
                    images = []
                    if "image" in sample and sample["image"]:
                         # ì´ë¯¸ì§€ê°€ 1ê°œë¼ê³  ê°€ì • (ScienceQAëŠ” 1ê°œ) <= No this is fallback code. Use Every Image in datasetss
                         if isinstance(sample["image"], list):
                             images = sample["image"]
                         else:
                             images = [sample["image"]]
                    
                    results.append({"messages": messages, "images": images})
                    sample_count += 1
                    continue
                
                # ì¼ë°˜ QA
                if question and answer:
                    messages = [
                        {"role": "user", "content": [{"type": "text", "text": question}]},
                        {"role": "assistant", "content": [{"type": "text", "text": answer}]}
                    ]
                    results.append({"messages": messages, "images": []})
                    sample_count += 1
                    continue
            
            # ë³€í™˜ ì‹¤íŒ¨ - ì—”ê±°í•˜ê²Œ ì—ëŸ¬ ë°œìƒ
            sample_keys = list(sample.keys()) if isinstance(sample, dict) else type(sample).__name__
            raise RuntimeError(f"[{dataset_name}] ìƒ˜í”Œ {idx} ë³€í™˜ ì‹¤íŒ¨. í‚¤: {sample_keys}")
            
        except Exception as e:
            raise RuntimeError(f"[{dataset_name}] ìƒ˜í”Œ {idx} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    
    return results

# ë°ì´í„°ì…‹ë³„ í”„ë¡œì„¸ì„œ ë§¤í•‘
DATASET_PROCESSORS = {
    "microsoft/rStar-Coder": process_rstar_coder,
    "meta-math/MetaMathQA": process_metamath,
    "sdiazlor/math-python-reasoning-dataset": process_math_python_reasoning,
    "lmms-lab/LLaVA-OneVision-Data": process_llava_onevision,
    "allenai/olmOCR-mix-1025": process_olmocr,
    "naver-clova-ix/cord-v2": process_cord,
    "dhmeltzer/ask-science-qg": process_ask_science_qg,
    "howard-hou/OCR-VQA": process_ocr_vqa,
}

def get_processor_for_dataset(dataset_name: str):
    """
    ë°ì´í„°ì…‹ ì´ë¦„ì— ë”°ë¼ ì ì ˆí•œ í”„ë¡œì„¸ì„œ ë°˜í™˜
    """
    # ì •í™•í•œ ì´ë¦„ ë§¤ì¹­
    if dataset_name in DATASET_PROCESSORS:
        return DATASET_PROCESSORS[dataset_name]
    
    # ë¶€ë¶„ ë§¤ì¹­ (ì†Œë¬¸ì ë³€í™˜)
    dataset_name_lower = dataset_name.lower()
    for key, processor in DATASET_PROCESSORS.items():
        if key.lower() in dataset_name_lower:
            return processor
    
    # ê¸°ë³¸ í”„ë¡œì„¸ì„œ
    return process_generic_instruction


# ============================================================
# í•˜ìœ„ í˜¸í™˜ì„±: ê¸°ì¡´ convert_sample_to_messages í•¨ìˆ˜ (deprecated)
# ============================================================

def convert_sample_to_messages(sample: Dict[str, Any], dataset_name: str, log_failure: bool = False) -> Optional[Dict[str, Any]]:
    """
    ìƒ˜í”Œì„ messages í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (í•˜ìœ„ í˜¸í™˜ì„±ìš© - deprecated)
    
    ì´ í•¨ìˆ˜ëŠ” í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ë‚¨ê²¨ë‘¡ë‹ˆë‹¤.
    ìƒˆë¡œìš´ ì½”ë“œì—ì„œëŠ” ë°ì´í„°ì…‹ë³„ í”„ë¡œì„¸ì„œë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì„¸ìš”.
    
    Args:
        sample: ë³€í™˜í•  ìƒ˜í”Œ
        dataset_name: ë°ì´í„°ì…‹ ì´ë¦„
        log_failure: ë³€í™˜ ì‹¤íŒ¨ ì‹œ ë¡œê·¸ë¥¼ ë‚¨ê¸¸ì§€ ì—¬ë¶€
    """
    # rStar-Coder í˜•ì‹ ì²˜ë¦¬ (ê°€ì¥ ë¨¼ì € ì²´í¬ - êµ¬ì²´ì ì¸ ë°ì´í„°ì…‹)
    if "rstar-coder" in dataset_name.lower() or "rstar_coder" in dataset_name.lower():
        # ì‹¤ì œ keys í™•ì¸ ë° ì²˜ë¦¬
        sample_keys = list(sample.keys()) if isinstance(sample, dict) else []
        
        # rStar-Coderì˜ ì‹¤ì œ ì»¬ëŸ¼: question, seed_question, seed_source, response, code
        question = sample.get("question", "")
        seed_question = sample.get("seed_question", "")
        seed_source = sample.get("seed_source", "")
        response = sample.get("response", "")
        code = sample.get("code", "")
        
        # ë””ë²„ê¹…: ì²˜ìŒ ëª‡ ê°œ ìƒ˜í”Œì˜ keys ë¡œê¹…
        if log_failure:
            logger.debug(f"   ğŸ” rStar-Coder ìƒ˜í”Œ keys: {sample_keys}")
            logger.debug(f"   ğŸ” question: {bool(question)}, seed_question: {bool(seed_question)}, response: {bool(response)}, code: {bool(code)}")
            if question:
                logger.debug(f"   ğŸ” question preview: {question[:100]}")
            if seed_question:
                logger.debug(f"   ğŸ” seed_question preview: {seed_question[:100]}")
            if response:
                logger.debug(f"   ğŸ” response preview: {response[:100]}")
            if code:
                logger.debug(f"   ğŸ” code preview: {code[:100]}")
        
        # question ë˜ëŠ” seed_question ì¤‘ í•˜ë‚˜ëŠ” ìˆì–´ì•¼ í•¨
        user_prompt = question.strip() if question and question.strip() else (seed_question.strip() if seed_question and seed_question.strip() else "")
        if not user_prompt:
            if log_failure:
                logger.warning(f"   âš ï¸ rStar-Coder: questionê³¼ seed_questionì´ ëª¨ë‘ ë¹„ì–´ìˆìŒ. keys: {sample_keys}")
            return None
        
        # responseì™€ code ì¤‘ í•˜ë‚˜ëŠ” ìˆì–´ì•¼ í•¨
        assistant_content_parts = []
        if response and response.strip():
            assistant_content_parts.append(response.strip())
        if code and code.strip():
            if assistant_content_parts:
                assistant_content_parts.append(f"\n\n```python\n{code.strip()}\n```")
            else:
                assistant_content_parts.append(code.strip())
        
        if not assistant_content_parts:
            if log_failure:
                logger.warning(f"   âš ï¸ rStar-Coder: responseì™€ codeê°€ ëª¨ë‘ ë¹„ì–´ìˆìŒ. keys: {sample_keys}")
            return None
        
        assistant_text = "\n".join(assistant_content_parts)
        
        messages = [
            {"role": "user", "content": [{"type": "text", "text": user_prompt}]},
            {"role": "assistant", "content": [{"type": "text", "text": assistant_text}]}
        ]
        return {"messages": messages, "images": []}
    
    # ask-science-qg í˜•ì‹ ì²˜ë¦¬ (answers.text ì‚¬ìš©)
    if "ask-science-qg" in dataset_name.lower():
        question = sample.get("question", "")
        answers = sample.get("answers", {})
        
        # answers.text í•„ë“œ ì¶”ì¶œ (ìˆ«ìì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë¬¸ìì—´ë¡œ ë³€í™˜)
        if isinstance(answers, dict):
            answer_text = answers.get("text", "")
        elif isinstance(answers, list) and len(answers) > 0:
            # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²« ë²ˆì§¸ í•­ëª©ì˜ text ì‚¬ìš©
            if isinstance(answers[0], dict):
                answer_text = answers[0].get("text", "")
            else:
                answer_text = str(answers[0]) if answers[0] else ""
        else:
            answer_text = ""
        
        # ë¬¸ìì—´ë¡œ ë³€í™˜ ë³´ì¥
        question = ensure_string(question)
        answer_text = ensure_string(answer_text)
        
        if not question or not answer_text:
            if log_failure:
                sample_keys_str = list(sample.keys()) if isinstance(sample, dict) else 'N/A'
                logger.debug(f"[{dataset_name}] ask-science-qg: ë¹ˆ ì§ˆë¬¸ ë˜ëŠ” ë‹µë³€ - question: {bool(question)}, answer: {bool(answer_text)}, sample_keys: {sample_keys_str}")
            return None
        
        messages = [
            {"role": "user", "content": [{"type": "text", "text": question}]},
            {"role": "assistant", "content": [{"type": "text", "text": answer_text}]}
        ]
        
        # í…ìŠ¤íŠ¸ í•„ë“œ ë¬¸ìì—´ ë³´ì¥
        messages = ensure_messages_text_strings(messages)
        
        return {"messages": messages, "images": []}
    
    # ScienceQA í˜•ì‹ ì²˜ë¦¬
    if "ScienceQA" in dataset_name or "scienceqa" in dataset_name.lower():
        question = sample.get("question", "")
        choices = sample.get("choices", [])
        answer = sample.get("answer", "")
        explanation = sample.get("explanation", "")
        
        # ì§ˆë¬¸ê³¼ ì„ íƒì§€ êµ¬ì„±
        question_text = question
        if choices:
            choices_text = "\n".join([f"{chr(65+i)}. {choice}" for i, choice in enumerate(choices)])
            question_text = f"{question}\n\n{choices_text}"
        
        # ë‹µë³€ êµ¬ì„±
        answer_text = answer
        if explanation:
            answer_text = f"{answer}\n\nExplanation: {explanation}"
        
        # ì´ë¯¸ì§€ ì²˜ë¦¬
        img = sample.get("image", [])
        if not isinstance(img, list):
            img = [img] if img is not None else []
        img = validate_image_data(img)
        
        # ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ë©€í‹°ëª¨ë‹¬, ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ì „ìš©
        if img:
            messages = [
                {"role": "user", "content": [{"type": "image"}, {"type": "text", "text": question_text}]},
                {"role": "assistant", "content": [{"type": "text", "text": answer_text}]}
            ]
        else:
            messages = [
                {"role": "user", "content": [{"type": "text", "text": question_text}]},
                {"role": "assistant", "content": [{"type": "text", "text": answer_text}]}
            ]
        
        return {"messages": messages, "images": img if img else []}
    
    # LLaVA-OneVision-Data í˜•ì‹ ì²˜ë¦¬
    if "llava-onevision" in dataset_name.lower() or "onevision" in dataset_name.lower():
        # LLaVA í˜•ì‹: conversations ë˜ëŠ” messages í•„ë“œ ì‚¬ìš©
        if "conversations" in sample:
            messages = []
            img = sample.get("image", [])
            if not isinstance(img, list):
                img = [img] if img is not None else []
            img = validate_image_data(img)
            
            first_user = True
            for conv in sample["conversations"]:
                if isinstance(conv, dict):
                    role = conv.get("from", "").lower()
                    value = conv.get("value", "")
                    
                    if role in ["human", "user"]:
                        content = []
                        if first_user and img:
                            content.append({"type": "image"})
                            first_user = False
                        if value:
                            content.append({"type": "text", "text": str(value)})
                        if content:
                            messages.append({"role": "user", "content": content})
                    elif role in ["gpt", "assistant"]:
                        if value:
                            messages.append({"role": "assistant", "content": [{"type": "text", "text": str(value)}]})
            
            if messages and img:
                return {"messages": messages, "images": img}
            elif messages:
                # ì´ë¯¸ì§€ê°€ ì—†ì–´ë„ ì²˜ë¦¬
                return {"messages": messages, "images": []}
        
        # UltraFeedback / Binarized ì²˜ë¦¬
        if "ultrafeedback" in dataset_name.lower():
            # 1. messages í•„ë“œ ìš°ì„  í™•ì¸
            if "messages" in sample and isinstance(sample["messages"], list):
                try:
                    messages = validate_messages(sample["messages"])
                    return {"messages": messages, "images": []}
                except:
                    pass
            
            # 2. prompt/chosen í™•ì¸
            if "prompt" in sample and "chosen" in sample:
                prompt = sample["prompt"]
                chosen = sample["chosen"]
                
                response = ""
                if isinstance(chosen, list):
                    # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° assistant ë©”ì‹œì§€ ì°¾ê¸°
                    for m in chosen:
                        if isinstance(m, dict) and m.get("role") == "assistant":
                            # contentê°€ ë¦¬ìŠ¤íŠ¸ì¼ ìˆ˜ë„ ë¬¸ìì—´ì¼ ìˆ˜ë„ ìˆìŒ
                            content = m.get("content", "")
                            if isinstance(content, list):
                                parts = [x.get("text", "") for x in content if x.get("type") == "text"]
                                response = "\n".join(parts)
                            else:
                                response = str(content)
                            break
                    # ëª» ì°¾ì•˜ìœ¼ë©´ ë§ˆì§€ë§‰ í•­ëª© ì‚¬ìš©
                    if not response and chosen:
                        m = chosen[-1]
                        if isinstance(m, dict):
                            content = m.get("content", "")
                            response = str(content) if not isinstance(content, list) else "\n".join([x.get("text","") for x in content if x.get("type")=="text"])
                else:
                    response = str(chosen)
                
                messages = [
                    {"role": "user", "content": [{"type": "text", "text": prompt}]},
                    {"role": "assistant", "content": [{"type": "text", "text": response}]}
                ]
                return {"messages": messages, "images": []}

        # UltraInteract ì²˜ë¦¬
        if "ultrainteract" in dataset_name.lower():
            instruction = sample.get("instruction", "")
            response = sample.get("response", "")
            if not response and "trajectory" in sample:
                 response = str(sample["trajectory"])
            
            if instruction and response:
                messages = [
                    {"role": "user", "content": [{"type": "text", "text": instruction}]},
                    {"role": "assistant", "content": [{"type": "text", "text": response}]}
                ]
                return {"messages": messages, "images": []}

        
        # messages í˜•ì‹ ì§ì ‘ ì§€ì›
        if "messages" in sample and isinstance(sample["messages"], list):
            img = sample.get("image", [])
            if not isinstance(img, list):
                img = [img] if img is not None else []
            img = validate_image_data(img)
            
            messages = validate_messages(sample["messages"])
            return {"messages": messages, "images": img if img else []}
        
        # instruction-output í˜•ì‹
        if "instruction" in sample and "output" in sample:
            img = sample.get("image", [])
            if not isinstance(img, list):
                img = [img] if img is not None else []
            img = validate_image_data(img)
            
            if img:
                messages = [
                    {"role": "user", "content": [{"type": "image"}, {"type": "text", "text": sample["instruction"]}]},
                    {"role": "assistant", "content": [{"type": "text", "text": sample["output"]}]}
                ]
            else:
                # Input í•„ë“œê°€ ìˆëŠ” ê²½ìš° ì²˜ë¦¬
                user_text = sample["instruction"]
                if "input" in sample and sample["input"]:
                    user_text += f"\n\nInput:\n{sample['input']}"
                
                messages = [
                    {"role": "user", "content": [{"type": "text", "text": user_text}]},
                    {"role": "assistant", "content": [{"type": "text", "text": sample["output"]}]}
                ]
            
            return {"messages": messages, "images": img if img else []}
    
    # VQA í˜•ì‹ ì²˜ë¦¬ (VQAv2) - í•˜ìœ„ í˜¸í™˜ì„±
    if "VQA" in dataset_name or "vqa" in dataset_name.lower():
        question = sample.get("question", "")
        answers = sample.get("answers", [])
        if isinstance(answers, list) and len(answers) > 0:
            if isinstance(answers[0], dict):
                answer = answers[0].get("answer", "")
            else:
                answer = str(answers[0])
        else:
            answer = sample.get("answer", "")
        
        messages = [
            {"role": "user", "content": [{"type": "image"}, {"type": "text", "text": question}]},
            {"role": "assistant", "content": [{"type": "text", "text": answer}]}
        ]
        
        img = sample.get("image", [])
        if not isinstance(img, list):
            img = [img] if img is not None else []
        img = validate_image_data(img)
        if not img:
            return None
        
        return {"messages": messages, "images": img}
    
    # Flickr30k í˜•ì‹ ì²˜ë¦¬ - í•˜ìœ„ í˜¸í™˜ì„±
    if "flickr30k" in dataset_name.lower():
        captions = sample.get("caption", [])
        if not isinstance(captions, list):
            captions = [captions] if captions else []
        
        if not captions:
            return None
        
        caption = str(captions[0])
        
        messages = [
            {"role": "user", "content": [{"type": "image"}, {"type": "text", "text": "Describe this image."}]},
            {"role": "assistant", "content": [{"type": "text", "text": caption}]}
        ]
        
        img = sample.get("image", [])
        if not isinstance(img, list):
            img = [img] if img is not None else []
        img = validate_image_data(img)
        if not img:
            return None
        
        return {"messages": messages, "images": img}
    
    # CORD (OCR) í˜•ì‹ ì²˜ë¦¬
    if "cord" in dataset_name.lower():
        # CORDëŠ” ë¬¸ì„œ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨
        text = sample.get("text", "")
        if not text:
            return None
        
        messages = [
            {"role": "user", "content": [{"type": "image"}, {"type": "text", "text": "Extract and read the text from this document."}]},
            {"role": "assistant", "content": [{"type": "text", "text": text}]}
        ]
        
        img = sample.get("image", [])
        if not isinstance(img, list):
            img = [img] if img is not None else []
        img = validate_image_data(img)
        if not img:
            return None
        
        return {"messages": messages, "images": img}
    
    # FUNSD (OCR) í˜•ì‹ ì²˜ë¦¬
    if "funsd" in dataset_name.lower() or "layoutlmv3" in dataset_name.lower():
        words = sample.get("words", [])
        bboxes = sample.get("bboxes", [])
        
        # ë‹¨ì–´ë“¤ì„ í…ìŠ¤íŠ¸ë¡œ ê²°í•©
        text = " ".join([str(word) for word in words]) if words else ""
        if not text:
            return None
        
        messages = [
            {"role": "user", "content": [{"type": "image"}, {"type": "text", "text": "Extract and read the text from this document."}]},
            {"role": "assistant", "content": [{"type": "text", "text": text}]}
        ]
        
        img = sample.get("image", [])
        if not isinstance(img, list):
            img = [img] if img is not None else []
        img = validate_image_data(img)
        if not img:
            return None
        
        return {"messages": messages, "images": img}
    
    # SciAlpaca / Camel-AI Science í˜•ì‹ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì „ìš©)
    if "scialpaca" in dataset_name.lower() or "camel-ai/science" in dataset_name.lower():
        # ë‘ ë°ì´í„°ì…‹ ëª¨ë‘ instruction-output í˜•ì‹ì„ ë”°ë¦„
        instruction = sample.get("instruction", "")
        output = sample.get("output", "")
        
        # Camel-AI ScienceëŠ” message_1, message_2 í˜•ì‹ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ
        if not instruction and "message_1" in sample and "message_2" in sample:
            instruction = sample["message_1"]
            output = sample["message_2"]

        if not instruction or not output:
            return None
        
        messages = [
            {"role": "user", "content": [{"type": "text", "text": instruction}]},
            {"role": "assistant", "content": [{"type": "text", "text": output}]}
        ]
        return {"messages": messages, "images": []}

    # SciTLDR í˜•ì‹ ì²˜ë¦¬
    if "scitldr" in dataset_name.lower():
        # source (abstract) -> target (summary)
        source_text = " ".join(sample.get("source", []))
        target_text = " ".join(sample.get("target", []))
        
        if not source_text or not target_text:
            return None

        instruction = f"Summarize the following scientific text in one or two sentences:\n\n{source_text}"
        
        messages = [
            {"role": "user", "content": [{"type": "text", "text": instruction}]},
            {"role": "assistant", "content": [{"type": "text", "text": target_text}]}
        ]
        return {"messages": messages, "images": []}

    # SROIE (OCR) í˜•ì‹ ì²˜ë¦¬
    if "sroie" in dataset_name.lower():
        text = sample.get("text", "")
        if not text:
            return None
        
        messages = [
            {"role": "user", "content": [{"type": "image"}, {"type": "text", "text": "Extract and read the text from this document."}]},
            {"role": "assistant", "content": [{"type": "text", "text": text}]}
        ]
        
        img = sample.get("image", [])
        if not isinstance(img, list):
            img = [img] if img is not None else []
        img = validate_image_data(img)
        if not img:
            return None
        
        return {"messages": messages, "images": img}
    
    # Evol-CodeAlpaca í˜•ì‹ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì „ìš©)
    if "evol-codealpaca" in dataset_name.lower():
        instruction = sample.get("instruction", "")
        output = sample.get("output", "")
        _input = sample.get("input", "")
        if not instruction or not output:
            return None
        user_text = instruction if not _input else f"{instruction}\n\nInput:\n{_input}"
        messages = [
            {"role": "user", "content": [{"type": "text", "text": user_text}]},
            {"role": "assistant", "content": [{"type": "text", "text": output}]}
        ]
        return {"messages": messages, "images": []}
    
    # OCR-VQA ê³„ì—´ (í•˜ìœ„ í˜¸í™˜ì„±ìš© - ì‹¤ì œë¡œëŠ” process_ocr_vqa ì‚¬ìš©)
    if "ocr-vqa" in dataset_name.lower() or "ocrvqa" in dataset_name.lower():
        # OCR-VQAëŠ” questions (ë³µìˆ˜, ë¦¬ìŠ¤íŠ¸)ì™€ answers (ë³µìˆ˜, ë¦¬ìŠ¤íŠ¸)ë¥¼ ì‚¬ìš©
        # í•˜ë‚˜ì˜ ì´ë¯¸ì§€ì— ì—¬ëŸ¬ ì§ˆë¬¸-ë‹µë³€ ìŒì´ ìˆìœ¼ë¯€ë¡œ ì²« ë²ˆì§¸ ìŒë§Œ ì‚¬ìš© (í•˜ìœ„ í˜¸í™˜ì„±)
        questions = sample.get("questions", [])
        answers = sample.get("answers", [])
        
        # questions/answersê°€ ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸
        if not isinstance(questions, (list, tuple)) or not isinstance(answers, (list, tuple)):
            return None
        
        if len(questions) == 0 or len(answers) == 0:
            return None
        
        # ì²« ë²ˆì§¸ ì§ˆë¬¸-ë‹µë³€ ìŒ ì‚¬ìš©
        question = str(questions[0]).strip()
        answer = str(answers[0]).strip()
        
        if not question or not answer:
            return None
        
        messages = [
            {"role": "user", "content": [{"type": "image"}, {"type": "text", "text": question}]},
            {"role": "assistant", "content": [{"type": "text", "text": answer}]}
        ]
        
        img = sample.get("image", None)
        if img is None:
            return None
        
        img_list = validate_image_data([img])
        if not img_list:
            return None
        
        return {"messages": messages, "images": img_list}
    
    # MetaMathQA í˜•ì‹ ì²˜ë¦¬ (í•™ìŠµìš© ìˆ˜í•™ instruction)
    if "metamathqa" in dataset_name.lower() or "meta-math" in dataset_name.lower():
        query = sample.get("query", "")
        response = sample.get("response", "")
        if not query or not response:
            return None
        
        messages = [
            {"role": "user", "content": [{"type": "text", "text": query}]},
            {"role": "assistant", "content": [{"type": "text", "text": response}]}
        ]
        return {"messages": messages, "images": []}
    
    # Math-Python-Reasoning í˜•ì‹ ì²˜ë¦¬ (í•™ìŠµìš© ìˆ˜í•™ Python ì¶”ë¡ )
    if "math-python-reasoning" in dataset_name.lower():
        # prompt/completion/system_prompt í˜•ì‹ ì§€ì›
        prompt = sample.get("prompt", "")
        completion = sample.get("completion", "")
        system_prompt = sample.get("system_prompt", "")
        
        # instruction/output í˜•ì‹ë„ ì§€ì› (í•˜ìœ„ í˜¸í™˜ì„±)
        if not prompt:
            prompt = sample.get("instruction", "")
        if not completion:
            completion = sample.get("output", "")
        
        if not prompt or not completion:
            return None
        
        messages = []
        
        # system_promptê°€ ìˆìœ¼ë©´ system ë©”ì‹œì§€ë¡œ ì¶”ê°€
        if system_prompt:
            messages.append({"role": "system", "content": [{"type": "text", "text": system_prompt}]})
        
        messages.extend([
            {"role": "user", "content": [{"type": "text", "text": prompt}]},
            {"role": "assistant", "content": [{"type": "text", "text": completion}]}
        ])
        
        return {"messages": messages, "images": []}
    
    # UltraInteract í˜•ì‹ ì²˜ë¦¬ (í•™ìŠµìš© ë…¼ë¦¬ ì¶”ë¡  instruction)
    if "ultrainteract" in dataset_name.lower() or "ultra-interact" in dataset_name.lower():
        # UltraInteractëŠ” ë‹¤ì–‘í•œ í˜•ì‹ì´ ìˆì„ ìˆ˜ ìˆìŒ
        if "messages" in sample:
            messages = validate_messages(sample["messages"])
            return {"messages": messages, "images": []}
        elif "instruction" in sample and "output" in sample:
            messages = [
                {"role": "user", "content": [{"type": "text", "text": sample["instruction"]}]},
                {"role": "assistant", "content": [{"type": "text", "text": sample["output"]}]}
            ]
            return {"messages": messages, "images": []}
        elif "question" in sample and "answer" in sample:
            messages = [
                {"role": "user", "content": [{"type": "text", "text": sample["question"]}]},
                {"role": "assistant", "content": [{"type": "text", "text": sample["answer"]}]}
            ]
            return {"messages": messages, "images": []}
    
    # UltraFeedback í˜•ì‹ ì²˜ë¦¬ (í•™ìŠµìš© ì¶”ë¡  instruction)
    if "ultrafeedback" in dataset_name.lower():
        # UltraFeedbackì€ ë‹¤ì–‘í•œ í˜•ì‹ì´ ìˆì„ ìˆ˜ ìˆìŒ
        if "messages" in sample:
            messages = validate_messages(sample["messages"])
            return {"messages": messages, "images": []}
        elif "instruction" in sample and "output" in sample:
            messages = [
                {"role": "user", "content": [{"type": "text", "text": sample["instruction"]}]},
                {"role": "assistant", "content": [{"type": "text", "text": sample["output"]}]}
            ]
            return {"messages": messages, "images": []}
        elif "prompt" in sample and "response" in sample:
            messages = [
                {"role": "user", "content": [{"type": "text", "text": sample["prompt"]}]},
                {"role": "assistant", "content": [{"type": "text", "text": sample["response"]}]}
            ]
            return {"messages": messages, "images": []}
    
    # GSM8K í˜•ì‹ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì „ìš©) - ë²¤ì¹˜ë§ˆí¬ìš©, í•˜ìœ„ í˜¸í™˜ì„±
    if "gsm8k" in dataset_name.lower():
        question = sample.get("question", "")
        answer = sample.get("answer", "")
        if not question or not answer:
            return None
        
        messages = [
            {"role": "user", "content": [{"type": "text", "text": question}]},
            {"role": "assistant", "content": [{"type": "text", "text": answer}]}
        ]
        return {"messages": messages, "images": []}
    
    # MATH í˜•ì‹ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì „ìš©) - ë²¤ì¹˜ë§ˆí¬ìš©, í•˜ìœ„ í˜¸í™˜ì„±
    if "competition_math" in dataset_name.lower() or "hendrycks/math" in dataset_name.lower():
        problem = sample.get("problem", "")
        solution = sample.get("solution", "")
        if not problem or not solution:
            return None
        
        messages = [
            {"role": "user", "content": [{"type": "text", "text": problem}]},
            {"role": "assistant", "content": [{"type": "text", "text": solution}]}
        ]
        return {"messages": messages, "images": []}
    
    # PubMedQA í˜•ì‹ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì „ìš©) - ì œê±°ë¨, í•˜ìœ„ í˜¸í™˜ì„±
    if "pubmed_qa" in dataset_name.lower():
        question = sample.get("question", "")
        long_answer = sample.get("long_answer", "")
        final_decision = sample.get("final_decision", "")
        
        if not question:
            return None
        
        answer_text = long_answer if long_answer else final_decision
        if not answer_text:
            return None
        
        messages = [
            {"role": "user", "content": [{"type": "text", "text": question}]},
            {"role": "assistant", "content": [{"type": "text", "text": answer_text}]}
        ]
        return {"messages": messages, "images": []}
    
    # CodeSearchNet í˜•ì‹ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì „ìš©)
    if "code_search_net" in dataset_name.lower() or "codesearchnet" in dataset_name.lower():
        code = sample.get("code", "")
        docstring = sample.get("docstring", "")
        func_name = sample.get("func_name", "")
        
        if not code:
            return None
        
        # ì½”ë“œì™€ ì„¤ëª…ì„ instruction-output í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        instruction = f"Write code for: {docstring}" if docstring else f"Write code for function: {func_name}" if func_name else "Write the following code:"
        
        messages = [
            {"role": "user", "content": [{"type": "text", "text": instruction}]},
            {"role": "assistant", "content": [{"type": "text", "text": code}]}
        ]
        return {"messages": messages, "images": []}
    
    # CoNaLa í˜•ì‹ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì „ìš©)
    if "conala" in dataset_name.lower():
        intent = sample.get("intent", "")
        snippet = sample.get("snippet", "")
        
        if not intent or not snippet:
            return None
        
        messages = [
            {"role": "user", "content": [{"type": "text", "text": intent}]},
            {"role": "assistant", "content": [{"type": "text", "text": snippet}]}
        ]
        return {"messages": messages, "images": []}
    
    # rStar-Coder í˜•ì‹ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì „ìš©)
    if "rstar-coder" in dataset_name.lower() or "rstar_coder" in dataset_name.lower():
        # ì‹¤ì œ keys í™•ì¸ ë° ì²˜ë¦¬
        sample_keys = list(sample.keys()) if isinstance(sample, dict) else []
        
        # rStar-Coderì˜ ì‹¤ì œ ì»¬ëŸ¼: question, seed_question, seed_source, response, code
        question = sample.get("question", "")
        seed_question = sample.get("seed_question", "")
        seed_source = sample.get("seed_source", "")
        response = sample.get("response", "")
        code = sample.get("code", "")
        
        # ë””ë²„ê¹…: ì²˜ìŒ ëª‡ ê°œ ìƒ˜í”Œì˜ keys ë¡œê¹…
        if log_failure:
            logger.debug(f"   ğŸ” rStar-Coder ìƒ˜í”Œ keys: {sample_keys}")
            logger.debug(f"   ğŸ” question: {bool(question)}, seed_question: {bool(seed_question)}, response: {bool(response)}, code: {bool(code)}")
        
        # question ë˜ëŠ” seed_question ì¤‘ í•˜ë‚˜ëŠ” ìˆì–´ì•¼ í•¨
        user_prompt = question if question else seed_question
        if not user_prompt:
            if log_failure:
                logger.warning(f"   âš ï¸ rStar-Coder: questionê³¼ seed_questionì´ ëª¨ë‘ ë¹„ì–´ìˆìŒ. keys: {sample_keys}")
            return None
        
        # responseì™€ code ì¤‘ í•˜ë‚˜ëŠ” ìˆì–´ì•¼ í•¨
        assistant_content_parts = []
        if response and response.strip():
            assistant_content_parts.append(response.strip())
        if code and code.strip():
            if assistant_content_parts:
                assistant_content_parts.append(f"\n\n```python\n{code.strip()}\n```")
            else:
                assistant_content_parts.append(code.strip())
        
        if not assistant_content_parts:
            if log_failure:
                logger.warning(f"   âš ï¸ rStar-Coder: responseì™€ codeê°€ ëª¨ë‘ ë¹„ì–´ìˆìŒ. keys: {sample_keys}")
            return None
        
        assistant_text = "\n".join(assistant_content_parts)
        
        messages = [
            {"role": "user", "content": [{"type": "text", "text": user_prompt}]},
            {"role": "assistant", "content": [{"type": "text", "text": assistant_text}]}
        ]
        return {"messages": messages, "images": []}
    
    # The Stack / StarCoderData í˜•ì‹ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì „ìš©) - í•˜ìœ„ í˜¸í™˜ì„±
    if "the-stack" in dataset_name.lower() or "starcoderdata" in dataset_name.lower():
        content = sample.get("content", "")
        if not content:
            return None
        
        # ì½”ë“œ ë°ì´í„°ì…‹ì€ instruction-output í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        messages = [
            {"role": "user", "content": [{"type": "text", "text": "Write the following code:"}]},
            {"role": "assistant", "content": [{"type": "text", "text": content}]}
        ]
        return {"messages": messages, "images": []}
    
    # LogiQA í˜•ì‹ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì „ìš©) - ë²¤ì¹˜ë§ˆí¬ìš©, í•˜ìœ„ í˜¸í™˜ì„±
    if "logiqa" in dataset_name.lower():
        question = sample.get("question", "")
        options = sample.get("options", [])
        answer = sample.get("answer", "")
        
        if not question or not answer:
            return None
        
        question_text = question
        if options:
            options_text = "\n".join([f"{chr(65+i)}. {opt}" for i, opt in enumerate(options)])
            question_text = f"{question}\n\n{options_text}"
        
        messages = [
            {"role": "user", "content": [{"type": "text", "text": question_text}]},
            {"role": "assistant", "content": [{"type": "text", "text": answer}]}
        ]
        return {"messages": messages, "images": []}
    
    # ReClor í˜•ì‹ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì „ìš©) - ë²¤ì¹˜ë§ˆí¬ìš©, í•˜ìœ„ í˜¸í™˜ì„±
    if "reclor" in dataset_name.lower():
        question = sample.get("question", "")
        answers = sample.get("answers", [])
        label = sample.get("label", -1)
        
        if not question:
            return None
        
        question_text = question
        if answers and isinstance(answers, list):
            options_text = "\n".join([f"{chr(65+i)}. {ans}" for i, ans in enumerate(answers)])
            question_text = f"{question}\n\n{options_text}"
        
        answer_text = answers[label] if label >= 0 and label < len(answers) else (answers[0] if answers else "")
        if not answer_text:
            return None
        
        messages = [
            {"role": "user", "content": [{"type": "text", "text": question_text}]},
            {"role": "assistant", "content": [{"type": "text", "text": answer_text}]}
        ]
        return {"messages": messages, "images": []}
    
    # OpenOrca í˜•ì‹ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì „ìš©)
    if "openorca" in dataset_name.lower() or "open-orca" in dataset_name.lower():
        # OpenOrcaëŠ” conversations í˜•ì‹ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
        if "conversations" in sample:
            messages = []
            for conv in sample["conversations"]:
                if isinstance(conv, dict):
                    role = conv.get("from", "user")
                    value = conv.get("value", "")
                    if value:
                        role_mapped = "user" if role in ["human", "user"] else "assistant"
                        messages.append({
                            "role": role_mapped,
                            "content": [{"type": "text", "text": value}]
                        })
            if messages:
                return {"messages": messages, "images": []}
        
        # instruction-output í˜•ì‹
        if "instruction" in sample and "response" in sample:
            messages = [
                {"role": "user", "content": [{"type": "text", "text": sample["instruction"]}]},
                {"role": "assistant", "content": [{"type": "text", "text": sample["response"]}]}
            ]
            return {"messages": messages, "images": []}
    
    # smoltalk ë°ì´í„°ì…‹ ì²˜ë¦¬
    if "smoltalk" in dataset_name.lower():
        if "messages" in sample and isinstance(sample["messages"], list):
            # messagesê°€ ì´ë¯¸ ì˜¬ë°”ë¥¸ í˜•ì‹ì¸ ê²½ìš°
            messages = validate_messages(sample["messages"])
            # content í•„ë“œ ì •ê·œí™”
            messages = ensure_messages_text_strings(messages)
            img = sample.get("image", [])
            if not isinstance(img, list):
                img = [img] if img is not None else []
            img = validate_image_data(img)
            # smoltalkì€ ì´ë¯¸ì§€ê°€ ì—†ì–´ë„ í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œ ì²˜ë¦¬ ê°€ëŠ¥
            return {"messages": messages, "images": img if img else []}
    
    # simple_sft_datasetì˜ ê¸°ë³¸ ë³€í™˜ ë¡œì§ ì‚¬ìš©
    from data.simple_sft_dataset import convert_sample_to_messages as base_convert
    result = base_convert(sample, dataset_name)
    
    # base_convertê°€ Noneì„ ë°˜í™˜í•˜ê±°ë‚˜ ì´ë¯¸ì§€ê°€ ì—†ëŠ” ê²½ìš°, í…ìŠ¤íŠ¸ ì „ìš©ìœ¼ë¡œ ì²˜ë¦¬ ì‹œë„
    if result is None:
        # instruction-output í˜•ì‹ ì¬ì‹œë„
        if "instruction" in sample and "output" in sample:
            messages = [
                {"role": "user", "content": [{"type": "text", "text": sample["instruction"]}]},
                {"role": "assistant", "content": [{"type": "text", "text": sample["output"]}]}
            ]
            messages = ensure_messages_text_strings(messages)
            return {"messages": messages, "images": []}
        
        # ëª¨ë“  ë³€í™˜ ì‹œë„ ì‹¤íŒ¨
        if log_failure:
            sample_keys = list(sample.keys()) if isinstance(sample, dict) else "N/A"
            sample_preview = str(sample)[:200] if isinstance(sample, dict) else str(sample)[:200]
            logger.debug(f"[{dataset_name}] ìƒ˜í”Œ ë³€í™˜ ì‹¤íŒ¨ - ì§€ì›ë˜ì§€ ì•ŠëŠ” í˜•ì‹. ìƒ˜í”Œ í‚¤: {sample_keys}, ë¯¸ë¦¬ë³´ê¸°: {sample_preview}...")
    
    # base_convert ê²°ê³¼ ì •ê·œí™”
    if result:
        # messages ì •ê·œí™”
        if "messages" in result:
            result["messages"] = ensure_messages_text_strings(result["messages"])
        # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì„¤ì •
        if "images" in result:
            if not result["images"]:
                result["images"] = []
    
    return result

# Configure logger
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
handler = logging.StreamHandler()
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)

# ë„ë©”ì¸ë³„ ë°ì´í„°ì…‹ ì„¤ì •
# ê° ë„ë©”ì¸ë³„ë¡œ í…ìŠ¤íŠ¸ ì „ìš© ë˜ëŠ” ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì…‹ì„ ì§€ì •í•©ë‹ˆë‹¤.
# í…ìŠ¤íŠ¸ ì „ìš© ë°ì´í„°ì…‹ë„ í—ˆìš©í•˜ë©°, ìµœì¢…ì ìœ¼ë¡œ messages í˜•ì‹ìœ¼ë¡œ í†µí•©ë©ë‹ˆë‹¤.
DOMAIN_DATASETS = {
    "math": [
        "meta-math/MetaMathQA",  # MetaMathQA: ìˆ˜í•™ instruction ë°ì´í„°ì…‹ (í•™ìŠµìš©)
        "sdiazlor/math-python-reasoning-dataset",  # Math-Python-Reasoning: ìˆ˜í•™ Python ì¶”ë¡  (í•™ìŠµìš©)
    ],
    "science": [
        "derek-thomas/ScienceQA",  # SciTLDR: ê³¼í•™ ë…¼ë¬¸ ìš”ì•½ (í•™ìŠµìš©)
        "dhmeltzer/ask-science-qg"
    ],
    "code": [
        "theblackcat102/evol-codealpaca-v1", # Evol-CodeAlpaca: ì½”ë“œ instruction (í•™ìŠµìš©)
        "microsoft/rStar-Coder",  # rStar-Coder: ì½”ë“œ ë°ì´í„°ì…‹
    ],
    "puzzle": [
        "openbmb/UltraInteract_sft",  # UltraInteract_sft: ë…¼ë¦¬ ì¶”ë¡  instruction ë°ì´í„°ì…‹ (í•™ìŠµìš©)
        "HuggingFaceH4/ultrafeedback_binarized",  # UltraFeedback ìºì‹œ ë¬¸ì œ í•´ê²° í›„ ë³µì›
    ],
    "vision": [
        "lmms-lab/LLaVA-OneVision-Data",  # LLaVA-OneVision-Data: ë‹¤ì–‘í•œ ë¹„ì „ íƒœìŠ¤í¬ (ë©€í‹°ëª¨ë‹¬)
        # "textvqa",  # TextVQA: ì¡´ì¬í•˜ì§€ ì•ŠìŒ, ëŒ€ì²´ í•„ìš”
    ],
    "ocr": [
        "howard-hou/OCR-VQA",  # OCR-VQA: OCR ì§ˆì˜ì‘ë‹µ ë°ì´í„°ì…‹
        "naver-clova-ix/cord-v2",  # CORD-v2: ì˜ìˆ˜ì¦ OCR ë°ì´í„°ì…‹ (ì´ë¯¸ì§€ + ground_truth)
        # "allenai/olmOCR-mix-1025",  # olmOCR-mix: ë³„ë„ ì „ì²˜ë¦¬ í•„ìš” (olmocr íˆ´í‚·), HFì—ì„œ ì§ì ‘ ë¡œë“œ ì‹œ ì´ë¯¸ì§€ ë¯¸ì œê³µ
    ],
    "chat": [
        "HuggingFaceTB/smoltalk",  # SmolTalk: ì¼ë°˜ ì±„íŒ… (ë©€í‹°ëª¨ë‹¬ ê°€ëŠ¥)
        "Open-Orca/OpenOrca",  # OpenOrca: ì¼ë°˜ ëŒ€í™” (í…ìŠ¤íŠ¸ ì „ìš©)
    ]
}

def _generate_cache_key(domain_configs: Dict[str, List[str]], max_samples_per_domain: int, 
                       test_size: float, use_streaming: bool, max_workers: int) -> str:
    """ìºì‹œ í‚¤ ìƒì„±"""
    # ë„ë©”ì¸ ì„¤ì •ì„ ì •ë ¬í•˜ì—¬ ì¼ê´€ì„± ë³´ì¥
    sorted_domains = sorted(domain_configs.items())
    cache_data = {
        "domain_configs": sorted_domains,
        "max_samples_per_domain": max_samples_per_domain,
        "test_size": test_size,
        "use_streaming": use_streaming,
        "max_workers": max_workers
    }
    cache_str = json.dumps(cache_data, sort_keys=True, ensure_ascii=False)
    cache_hash = hashlib.md5(cache_str.encode('utf-8')).hexdigest()
    return f"multi_domain_{cache_hash}"

def get_domain_from_config(config_name: str, dataset_name: str) -> Optional[str]:
    """
    Config ì´ë¦„ê³¼ ë°ì´í„°ì…‹ ì´ë¦„ì„ ê¸°ë°˜ìœ¼ë¡œ ë„ë©”ì¸ì„ ì¶”ë¡ í•©ë‹ˆë‹¤.
    
    Args:
        config_name: ë°ì´í„°ì…‹ config ì´ë¦„
        dataset_name: ë°ì´í„°ì…‹ ì´ë¦„
    
    Returns:
        ì¶”ë¡ ëœ ë„ë©”ì¸ ì´ë¦„ ë˜ëŠ” None
    """
    config_lower = config_name.lower()
    dataset_lower = dataset_name.lower()
    
    # í‚¤ì›Œë“œ ê¸°ë°˜ ë„ë©”ì¸ ë§¤ì¹­ (ìš°ì„ ìˆœìœ„ ìˆœ)
    math_keywords = ["math", "mathematical", "algebra", "geometry", "calculus", "arithmetic", "equation"]
    science_keywords = ["science", "physics", "chemistry", "biology", "scientific", "astronomy", "geology"]
    code_keywords = ["code", "programming", "python", "javascript", "coding", "software", "algorithm", "function"]
    puzzle_keywords = ["puzzle", "logic", "reasoning", "riddle", "brain", "challenge", "problem"]
    vision_keywords = ["vision", "visual", "image", "photo", "picture", "camera", "see", "look"]
    ocr_keywords = ["ocr", "text", "document", "scan", "recognition", "read", "extract", "textual"]
    
    if any(keyword in config_lower for keyword in math_keywords):
        return "math"
    elif any(keyword in config_lower for keyword in science_keywords):
        return "science"
    elif any(keyword in config_lower for keyword in code_keywords):
        return "code"
    elif any(keyword in config_lower for keyword in puzzle_keywords):
        return "puzzle"
    elif any(keyword in config_lower for keyword in vision_keywords):
        return "vision"
    elif any(keyword in config_lower for keyword in ocr_keywords):
        return "ocr"
    
    # ë°ì´í„°ì…‹ ì´ë¦„ ê¸°ë°˜ ë§¤ì¹­
    if any(keyword in dataset_lower for keyword in math_keywords):
        return "math"
    elif any(keyword in dataset_lower for keyword in science_keywords):
        return "science"
    elif any(keyword in dataset_lower for keyword in code_keywords):
        return "code"
    elif any(keyword in dataset_lower for keyword in puzzle_keywords):
        return "puzzle"
    elif any(keyword in dataset_lower for keyword in vision_keywords):
        return "vision"
    elif any(keyword in dataset_lower for keyword in ocr_keywords):
        return "ocr"
    
    return None

def _process_dataset_config_split(
    domain: str,
    dataset_name: str,
    config: str,
    train_split: str,
    test_split: Optional[str],
    train_path: str,
    test_path: str,
    image_counter_lock: threading.Lock,
    shared_counters: Dict[str, Any],
    images_dir: str,
    samples_per_config: int,
    test_size: float,
    use_streaming: bool,
    domain_processed_lock: threading.Lock,
    domain_processed_dict: Dict[str, int],
    max_samples_per_domain: int
) -> Dict[str, Any]:
    """
    ë‹¨ì¼ ë°ì´í„°ì…‹ì˜ ë‹¨ì¼ configì™€ splitì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ (ë³‘ë ¬ ì²˜ë¦¬ìš©)
    ë°ì´í„°ì…‹ë³„ ì „ìš© í”„ë¡œì„¸ì„œë¥¼ ì‚¬ìš©í•˜ì—¬ messages í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    """
    result = {
        "train_count": 0,
        "test_count": 0,
    }
    
    try:
        # ë°ì´í„°ì…‹ì— ë§ëŠ” í”„ë¡œì„¸ì„œ ì„ íƒ
        processor = get_processor_for_dataset(dataset_name)
        logger.debug(f"   ğŸ¯ [{dataset_name}] í”„ë¡œì„¸ì„œ ì„ íƒ: {processor.__name__}")
        
        # Train split ì²˜ë¦¬
        try:
            logger.debug(f"   ğŸ” [{dataset_name}] Config {config} Train split {train_split} ë¡œë”©...")
            

            # Load Args êµ¬ì„± (ë³µêµ¬ë¨)
            load_kwargs = {
                "path": dataset_name,
                "split": train_split,
                "streaming": use_streaming,
                "trust_remote_code": True,
            }
            if config != "default":
                load_kwargs["name"] = config

            # [Dynamic Load] ë©”íƒ€ë°ì´í„° ì˜¤ë¥˜ ìš°íšŒ ë° ë™ì  Split/File ë§¤í•‘
            broken_metadata_datasets = ["lmms-lab/LLaVA-OneVision-Data", "howard-hou/OCR-VQA", "HuggingFaceH4/ultrafeedback_binarized", "HuggingFaceTB/smoltalk"]
            
            if any(broken in dataset_name for broken in broken_metadata_datasets):
                logger.warning(f"   ğŸ›¡ï¸ [{dataset_name}] ë©”íƒ€ë°ì´í„° ì˜¤ë¥˜ íšŒí”¼ -> Parquet ë™ì  ë¡œë”© ì‹œì‘")
                try:
                    # 1. ë¹Œë” ë¡œë“œ (ë©”íƒ€ë°ì´í„° í™•ë³´)
                    builder = load_dataset_builder(dataset_name, name=config if config != "default" else None, trust_remote_code=True)
                    
                    # 2. ì‚¬ìš© ê°€ëŠ¥í•œ Split í™•ì¸ ë° ë™ì  ë§¤í•‘
                    available_splits = list(builder.info.splits.keys()) if builder.info.splits else []
                    target_split = train_split
                    
                    if train_split not in available_splits:
                        candidates = [s for s in available_splits if "train" in s]
                        if candidates:
                            target_split = candidates[0]
                            logger.warning(f"   âš ï¸ Split '{train_split}' ë¶€ì¬ -> '{target_split}' ìë™ ë§¤í•‘")
                        else:
                            logger.error(f"   âŒ Split ë§¤í•‘ ì‹¤íŒ¨. ìš”ì²­: {train_split}, ê°€ìš©: {available_splits}")
                            raise ValueError(f"Split '{train_split}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    
                    # 3. íŒŒì¼ ë§¤í•‘ (Split ì´ë¦„ -> Parquet íŒŒì¼ ê²½ë¡œ)
                    data_files = builder.config.data_files
                    files = None
                    if isinstance(data_files, dict):
                        files = data_files.get(target_split)
                        if not files:
                            if "train" in data_files:
                                files = data_files["train"]
                            else:
                                for k in data_files.keys():
                                    if target_split in k or k in target_split:
                                        files = data_files.get(k)
                                        break
                    else:
                        files = data_files
                    
                    if not files:
                        raise ValueError(f"Files not found for split {target_split}")

                    # 4. Parquet ì—”ì§„ìœ¼ë¡œ ë¡œë“œ
                    train_dataset = load_dataset(
                        "parquet", 
                        data_files={target_split: files}, 
                        split=target_split, 
                        streaming=use_streaming
                    )
                    logger.debug(f"   âœ… Parquet ë™ì  ë¡œë”© ì„±ê³µ: Split '{target_split}'")
                    
                except Exception as pq_e:
                    logger.error(f"   âŒ Parquet ë¡œë”© ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {pq_e}")
                    raise pq_e 
            else:
                # ì¼ë°˜ ë°ì´í„°ì…‹ ë¡œë”©
                train_dataset = load_dataset(**load_kwargs)

            
            # ë°ì´í„°ì…‹ ì •ë³´ í™•ì¸
            dataset_size = None
            if not use_streaming:
                dataset_size = len(train_dataset) if hasattr(train_dataset, '__len__') else None
                if dataset_size == 0:
                    error_msg = f"âŒ [{dataset_name}] Config {config} Train split {train_split}ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."
                    logger.error(error_msg)
                    raise RuntimeError(error_msg)
            
            train_samples_per_config = samples_per_config
            if test_split:
                train_samples_per_config = int(samples_per_config * (1 - test_size))
            
            # ë„ë©”ì¸ë³„ ì²˜ë¦¬ëŸ‰ ì²´í¬
            with domain_processed_lock:
                current_domain_processed = domain_processed_dict.get(domain, 0)
                remaining_domain_capacity = max_samples_per_domain - current_domain_processed
                effective_max_samples = min(train_samples_per_config, remaining_domain_capacity)
            
            if effective_max_samples <= 0:
                logger.debug(f"   âš ï¸ [{dataset_name}] Config {config}: ë„ë©”ì¸ ì²˜ë¦¬ëŸ‰ í•œê³„ ë„ë‹¬, ê±´ë„ˆëœ€")
                return result
            
            # ============================================================
            # ë°ì´í„°ì…‹ë³„ í”„ë¡œì„¸ì„œ í˜¸ì¶œ (ì „ì²´ ë°ì´í„°ì…‹ ì²˜ë¦¬)
            # ============================================================
            # ë””ë²„ê¹…ì´ í•„ìš”í•œ ë°ì´í„°ì…‹ì€ í•­ìƒ ìƒì„¸ ë¡œê·¸ ì¶œë ¥
            log_detail = any(keyword in dataset_name.lower() for keyword in ["rstar", "ask-science"])
            converted_results = processor(train_dataset, dataset_name, effective_max_samples, log_detail=log_detail)
            
            logger.debug(f"   âœ… [{dataset_name}] Config {config} í”„ë¡œì„¸ì„œ ì™„ë£Œ: {len(converted_results)}ê°œ ìƒ˜í”Œ ë³€í™˜ë¨")
            
            # ë³€í™˜ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì—ëŸ¬
            if not converted_results:
                error_msg = f"âŒ [{dataset_name}] Config {config}: í”„ë¡œì„¸ì„œì—ì„œ ë³€í™˜ëœ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤."
                logger.error(error_msg)
                raise RuntimeError(error_msg)
            
            # ============================================================
            # ë³€í™˜ëœ ê²°ê³¼ë¥¼ íŒŒì¼ì— ì €ì¥
            # ============================================================
            train_processed = 0
            for idx, converted in enumerate(converted_results):
                try:
                    # messages í…ìŠ¤íŠ¸ ë¬¸ìì—´ ë³´ì¥
                    if "messages" in converted:
                        converted["messages"] = ensure_messages_text_strings(converted["messages"])
                    
                    # ì´ë¯¸ì§€ ì²˜ë¦¬ (PIL Image ê°ì²´ë¥¼ íŒŒì¼ë¡œ ì €ì¥)
                    image_paths = []
                    if "images" in converted and converted["images"]:
                        for img_obj in converted["images"]:
                            if isinstance(img_obj, Image.Image):
                                try:
                                    with image_counter_lock:
                                        current_counter = shared_counters["image_counter"]
                                        img_path = os.path.join(images_dir, f"{current_counter}.png")
                                        img_obj.save(img_path, "PNG")
                                        image_paths.append(img_path)
                                        shared_counters["image_counter"] += 1
                                except Exception as img_e:
                                    error_msg = f"âŒ [{dataset_name}] ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {img_e}"
                                    logger.error(error_msg)
                                    raise RuntimeError(error_msg) from img_e
                    
                    # ìµœì¢… ë°ì´í„° êµ¬ì„±
                    converted["images"] = image_paths
                    converted["domain"] = domain
                    
                    # VLM í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ëª¨ë“  ë°ì´í„°ë¥¼ VLM í˜•ì‹ìœ¼ë¡œ í†µì¼)
                    converted = ensure_vlm_format(converted)
                    
                    # JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì •ë¦¬
                    converted = sanitize_sample_for_json(converted)
                    
                    # íŒŒì¼ ì“°ê¸° (ë„ë©”ì¸ë³„ íŒŒì¼ì— append)
                    try:
                        json_str = json.dumps(converted, ensure_ascii=False)
                        with open(train_path, "a", encoding="utf-8") as f:
                            f.write(json_str + "\n")
                        
                        # ì¹´ìš´í„° ì—…ë°ì´íŠ¸ (thread-safe)
                        with domain_processed_lock:
                            shared_counters["domain_counts"][domain]["train"] += 1
                            shared_counters["total_processed"] += 1
                            domain_processed_dict[domain] = domain_processed_dict.get(domain, 0) + 1
                        
                        result["train_count"] += 1
                        train_processed += 1
                        
                    except (TypeError, ValueError) as json_e:
                        error_msg = f"âŒ [{dataset_name}] JSON ì§ë ¬í™” ì‹¤íŒ¨: {json_e}"
                        logger.error(error_msg)
                        raise RuntimeError(error_msg) from json_e
                
                except Exception as sample_e:
                    logger.error(f"âŒ [{dataset_name}] Train ìƒ˜í”Œ {idx} ì €ì¥ ì‹¤íŒ¨: {sample_e}")
                    # ì €ì¥ ì‹¤íŒ¨ ì‹œì—ë„ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì¤‘ë‹¨
                    raise RuntimeError(f"Train ìƒ˜í”Œ ì €ì¥ ì‹¤íŒ¨") from sample_e
            
            logger.debug(f"   âœ… [{dataset_name}] Config {config} Train split ì €ì¥ ì™„ë£Œ: {train_processed}ê°œ")
            
            del train_dataset
            gc.collect()
            
        except Exception as e:
            error_msg = f"âŒ [{dataset_name}] Config {config} Train split {train_split} ë¡œë“œ ì‹¤íŒ¨: {e}"
            logger.error(error_msg)
            traceback.print_exc()
            raise RuntimeError(error_msg) from e
        
        # Test split ì²˜ë¦¬ (ìˆëŠ” ê²½ìš°)
        if test_split:
            try:
                logger.debug(f"   ğŸ” [{dataset_name}] Config {config} Test split {test_split} ë¡œë”©...")
                
                # Test Load Args êµ¬ì„±
                # Test Load Args êµ¬ì„±
                test_load_kwargs = {
                    "path": dataset_name,
                    "split": test_split,
                    "streaming": use_streaming,
                    "trust_remote_code": True,
                }
                if config != "default":
                    test_load_kwargs["name"] = config
                
                # [Dynamic Load] Test Parquet ì§ì ‘ ë¡œë”© (ë™ì  ë§¤í•‘)
                if any(broken in dataset_name for broken in broken_metadata_datasets):
                    logger.warning(f"   ğŸ›¡ï¸ [{dataset_name}] (Test) ë©”íƒ€ë°ì´í„° ì˜¤ë¥˜ íšŒí”¼ -> Parquet ë™ì  ë¡œë”© ì‹œì‘")
                    try:
                        builder = load_dataset_builder(dataset_name, name=config if config != "default" else None, trust_remote_code=True)
                        
                        # 1. Split ë§¤í•‘
                        available_splits = list(builder.info.splits.keys()) if builder.info.splits else []
                        target_split = test_split
                        
                        if test_split not in available_splits:
                            # 'test'ë‚˜ 'val'ì´ í¬í•¨ëœ Split ê²€ìƒ‰
                            candidates = [s for s in available_splits if "test" in s or "val" in s]
                            if candidates:
                                target_split = candidates[0]
                                logger.warning(f"   âš ï¸ (Test) Split '{test_split}' ë¶€ì¬ -> '{target_split}' ìë™ ë§¤í•‘")
                            else:
                                logger.error(f"   âŒ (Test) Split ë§¤í•‘ ì‹¤íŒ¨. ìš”ì²­: {test_split}, ê°€ìš©: {available_splits}")
                                raise ValueError(f"Split '{test_split}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                        # 2. íŒŒì¼ ë§¤í•‘
                        data_files = builder.config.data_files
                        files = None
                        if isinstance(data_files, dict):
                             files = data_files.get(target_split)
                             if not files:
                                 # í‚¤ ì´ë¦„ ìœ ì—° ê²€ìƒ‰
                                 for k in data_files.keys():
                                     if target_split in k or k in target_split:
                                         files = data_files.get(k)
                                         break
                        else:
                             files = data_files

                        if not files:
                            raise ValueError(f"Files not found for split {target_split}")

                        test_dataset = load_dataset(
                            "parquet", 
                            data_files={target_split: files}, 
                            split=target_split, 
                            streaming=use_streaming
                        )
                        logger.debug(f"   âœ… (Test) Parquet ë™ì  ë¡œë”© ì„±ê³µ: Split '{target_split}'")
                    except Exception as pq_e:
                        logger.error(f"   âŒ Parquet ì§ì ‘ ë¡œë”© ì‹¤íŒ¨ (Test): {pq_e}")
                        raise pq_e # Fallback ê¸ˆì§€
                else:
                    test_dataset = load_dataset(**test_load_kwargs)
                
                test_samples_per_config = int(samples_per_config * test_size)
                
                # í”„ë¡œì„¸ì„œ í˜¸ì¶œ (ì „ì²´ ë°ì´í„°ì…‹ ì²˜ë¦¬)
                log_detail = "rstar" in dataset_name.lower()
                test_converted_results = processor(test_dataset, dataset_name, test_samples_per_config, log_detail=log_detail)
                
                logger.debug(f"   âœ… [{dataset_name}] Config {config} Test í”„ë¡œì„¸ì„œ ì™„ë£Œ: {len(test_converted_results)}ê°œ ìƒ˜í”Œ ë³€í™˜ë¨")
                
                # ë³€í™˜ëœ ê²°ê³¼ë¥¼ íŒŒì¼ì— ì €ì¥
                test_processed = 0
                for idx, converted in enumerate(test_converted_results):
                    try:
                        # messages í…ìŠ¤íŠ¸ ë¬¸ìì—´ ë³´ì¥
                        if "messages" in converted:
                            converted["messages"] = ensure_messages_text_strings(converted["messages"])
                        
                        # ì´ë¯¸ì§€ ì²˜ë¦¬
                        image_paths = []
                        if "images" in converted and converted["images"]:
                            for img_obj in converted["images"]:
                                if isinstance(img_obj, Image.Image):
                                    try:
                                        with image_counter_lock:
                                            current_counter = shared_counters["image_counter"]
                                            img_path = os.path.join(images_dir, f"{current_counter}.png")
                                            img_obj.save(img_path, "PNG")
                                            image_paths.append(img_path)
                                            shared_counters["image_counter"] += 1
                                    except Exception as img_e:
                                        error_msg = f"âŒ [{dataset_name}] ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {img_e}"
                                        logger.error(error_msg)
                                        raise RuntimeError(error_msg) from img_e
                        
                        # ìµœì¢… ë°ì´í„° êµ¬ì„±
                        converted["images"] = image_paths
                        converted["domain"] = domain
                        
                        # VLM í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ëª¨ë“  ë°ì´í„°ë¥¼ VLM í˜•ì‹ìœ¼ë¡œ í†µì¼)
                        converted = ensure_vlm_format(converted)
                        
                        # JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì •ë¦¬
                        converted = sanitize_sample_for_json(converted)
                        
                        # íŒŒì¼ ì“°ê¸° (ë„ë©”ì¸ë³„ íŒŒì¼ì— append)
                        try:
                            json_str = json.dumps(converted, ensure_ascii=False)
                            with open(test_path, "a", encoding="utf-8") as f:
                                f.write(json_str + "\n")
                            
                            # ì¹´ìš´í„° ì—…ë°ì´íŠ¸ (thread-safe)
                            with domain_processed_lock:
                                shared_counters["domain_counts"][domain]["test"] += 1
                                shared_counters["total_processed"] += 1
                            
                            result["test_count"] += 1
                            test_processed += 1
                            
                        except (TypeError, ValueError) as json_e:
                            error_msg = f"âŒ [{dataset_name}] JSON ì§ë ¬í™” ì‹¤íŒ¨: {json_e}"
                            logger.error(error_msg)
                            raise RuntimeError(error_msg) from json_e
                    
                    except Exception as sample_e:
                        logger.error(f"âŒ [{dataset_name}] Test ìƒ˜í”Œ {idx} ì €ì¥ ì‹¤íŒ¨: {sample_e}")
                        raise RuntimeError(f"Test ìƒ˜í”Œ ì €ì¥ ì‹¤íŒ¨") from sample_e
                
                logger.debug(f"   âœ… [{dataset_name}] Config {config} Test split ì €ì¥ ì™„ë£Œ: {test_processed}ê°œ")
                
                del test_dataset
                gc.collect()
                
            except Exception as e:
                error_msg = f"âŒ [{dataset_name}] Config {config} Test split {test_split} ì²˜ë¦¬ ì‹¤íŒ¨: {e}"
                logger.error(error_msg)
                traceback.print_exc()
                raise RuntimeError(error_msg) from e
    
    except Exception as e:
        error_msg = f"âŒ [{dataset_name}] Config {config} ì²˜ë¦¬ ì‹¤íŒ¨: {e}"
        logger.error(error_msg)
        traceback.print_exc()
        raise RuntimeError(error_msg) from e
    
    # ìµœì†Œí•œ í•˜ë‚˜ì˜ ìƒ˜í”Œì€ ì²˜ë¦¬ë˜ì–´ì•¼ í•¨
    # (í”„ë¡œì„¸ì„œì—ì„œ ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì´ë¯¸ RuntimeErrorë¥¼ ë°œìƒì‹œí‚¤ë¯€ë¡œ, ì—¬ê¸°ëŠ” ìµœì¢… ì²´í¬ë§Œ)
    if result["train_count"] == 0 and result["test_count"] == 0:
        error_msg = f"âŒ [{dataset_name}] Config {config}: ì²˜ë¦¬ëœ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤."
        logger.error(error_msg)
        logger.error(f"   ğŸ“‹ í™•ì¸ ì‚¬í•­:")
        logger.error(f"      - Config: {config}")
        logger.error(f"      - Train split: {train_split}")
        logger.error(f"      - Test split: {test_split}")
        logger.error(f"      - Streaming: {use_streaming}")
        logger.error(f"      - Samples per config: {samples_per_config}")
        
        raise RuntimeError(error_msg)
    
    return result

def _process_domain_datasets(
    domain: str,
    dataset_names: List[str],
    temp_dir: str,
    image_counter_lock: threading.Lock,
    shared_counters: Dict[str, Any],
    images_dir: str,
    max_samples_per_domain: int,
    test_size: float,
    use_streaming: bool,
    max_workers: int = 4
) -> Dict[str, Any]:
    """
    ë‹¨ì¼ ë„ë©”ì¸ì˜ ë°ì´í„°ì…‹ë“¤ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ (ë³‘ë ¬ ì²˜ë¦¬ìš©)
    ê° ë°ì´í„°ì…‹, config, splitì„ ìˆœì°¨ ì²˜ë¦¬ (ë„ë©”ì¸ë³„ ë³‘ë ¬ì€ ìƒìœ„ ë ˆë²¨ì—ì„œ)
    """
    # ë„ë©”ì¸ë³„ ì„ì‹œ íŒŒì¼ ìƒì„±
    domain_train_path = os.path.join(temp_dir, f"{domain}_train.jsonl")
    domain_test_path = os.path.join(temp_dir, f"{domain}_test.jsonl")
    
    # ë„ë©”ì¸ë³„ ì²˜ë¦¬ í†µê³„
    domain_stats = {
        "total_processed": 0,  # train_count + test_count í•©ê³„
    }
    
    # ScienceQA ë¯¸ëŸ¬ ì¤‘ë³µ ë°©ì§€ í”Œë˜ê·¸
    scienceqa_taken = False
    
    # ë„ë©”ì¸ë³„ ì²˜ë¦¬ëŸ‰ ì¶”ì  (thread-safe)
    domain_processed_lock = threading.Lock()
    domain_processed_dict = {domain: 0}
    
    # ëª¨ë“  ë°ì´í„°ì…‹/config/split ì‘ì—… ìˆ˜ì§‘
    tasks = []
    
    for dataset_name in dataset_names:
        try:
            logger.debug(f"   ğŸ“‹ {domain} ë„ë©”ì¸ - ë°ì´í„°ì…‹: {dataset_name}")
            
            # ë°ì´í„°ì…‹ ì¡´ì¬ í™•ì¸
            if not dataset_exists(dataset_name):
                error_msg = f"âŒ [{domain}] ë°ì´í„°ì…‹ì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {dataset_name}"
                logger.error(error_msg)
                raise RuntimeError(error_msg)
            
            # ë°ì´í„°ì…‹ì˜ config ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            try:
                available_configs = get_dataset_config_names(dataset_name)
                if not available_configs:
                    available_configs = ["default"]
            except Exception as e:
                error_msg = f"âŒ [{domain}] ë°ì´í„°ì…‹ {dataset_name}ì˜ Config ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}"
                logger.error(error_msg)
                traceback.print_exc()
                raise RuntimeError(error_msg) from e
            
            # LLaVA-OneVision-DataëŠ” onevision ì„œë¸Œì…‹ë§Œ ì‚¬ìš©
            if "llava-onevision" in dataset_name.lower() or "llava-onevision-data" in dataset_name.lower():
                filtered = [c for c in available_configs if "onevision" in str(c).lower()]
                if filtered:
                    available_configs = filtered
                else:
                    available_configs = available_configs[:5]
            
            # rStar-Coderì— í•œí•´ì„œë§Œ RL ê´€ë ¨ config ì œì™¸, SFTìš©ë§Œ ì‚¬ìš©
            if "rstar-coder" in dataset_name.lower() or "rstar_coder" in dataset_name.lower():
                rl_keywords = ["rl", "reinforcement", "synthetic_rl", "dpo", "ppo", "reward"]
                test_keywords = ["test_case", "test"]  # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìƒì„±ìš©ì€ ì œì™¸
                original_count = len(available_configs)
                
                # SFT í•™ìŠµìš© configë§Œ ì‚¬ìš© (test_case ì œì™¸)
                sft_configs = [
                    c for c in available_configs 
                    if str(c).lower() in ["seed_sft", "synthetic_sft"] 
                    and not any(test_kw in str(c).lower() for test_kw in test_keywords)
                ]
                if sft_configs:
                    available_configs = sft_configs
                else:
                    # RL ë° test ê´€ë ¨ config ì œì™¸
                    filtered_configs = [
                        c for c in available_configs 
                        if not any(keyword in str(c).lower() for keyword in rl_keywords)
                        and not any(test_kw in str(c).lower() for test_kw in test_keywords)
                    ]
                    if filtered_configs:
                        available_configs = filtered_configs
                    else:
                        # í•„í„°ë§ í›„ ë‚¨ì€ configê°€ ì—†ìœ¼ë©´ ì˜¤ë¥˜
                        error_msg = f"âŒ [{domain}] ë°ì´í„°ì…‹ {dataset_name}: ëª¨ë“  configê°€ RL ë˜ëŠ” test ê´€ë ¨ì…ë‹ˆë‹¤. SFT í•™ìŠµìš© configê°€ ì—†ìŠµë‹ˆë‹¤."
                        logger.error(error_msg)
                        raise RuntimeError(error_msg)
            
            # ScienceQA ë¯¸ëŸ¬ ì¤‘ë³µ ë°©ì§€
            if domain == "science" and ("scienceqa" in dataset_name.lower()):
                if scienceqa_taken:
                    continue
                scienceqa_taken = True
            
            # Configë³„ë¡œ ìƒ˜í”Œ ìˆ˜ ê³„ì‚°
            samples_per_config = max(1, max_samples_per_domain // max(len(available_configs), 1))
            
            # ê° configì— ëŒ€í•´ ì‘ì—… ìƒì„±
            for config in available_configs:
                try:
                    # ì‚¬ìš© ê°€ëŠ¥í•œ split í™•ì¸
                    try:
                        if config == "default":
                            available_splits = get_dataset_split_names(dataset_name)
                        else:
                            available_splits = get_dataset_split_names(dataset_name, config_name=config)
                        
                        # Train split ì„ íƒ: train_sft > train
                        train_split = None
                        if "train_sft" in available_splits:
                            train_split = "train_sft"
                        elif "train" in available_splits:
                            train_split = "train"
                        else:
                            error_msg = f"âŒ [{domain}] ë°ì´í„°ì…‹ {dataset_name} Config {config}ì— train ë˜ëŠ” train_sft splitì´ ì—†ìŠµë‹ˆë‹¤."
                            logger.error(error_msg)
                            raise RuntimeError(error_msg)
                        
                        # Test split ì„ íƒ: test_sft > test
                        test_split = None
                        if "test_sft" in available_splits:
                            test_split = "test_sft"
                        elif "test" in available_splits:
                            test_split = "test"
                    except Exception as e:
                        error_msg = f"âŒ [{domain}] ë°ì´í„°ì…‹ {dataset_name} Config {config}ì˜ Split ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}"
                        logger.error(error_msg)
                        traceback.print_exc()
                        raise RuntimeError(error_msg) from e
                    
                    # ì‘ì—… ì¶”ê°€
                    tasks.append({
                        "domain": domain,
                        "dataset_name": dataset_name,
                        "config": config,
                        "train_split": train_split,
                        "test_split": test_split,
                        "samples_per_config": samples_per_config
                    })
                
                except Exception as e:
                    error_msg = f"âŒ [{domain}] ë°ì´í„°ì…‹ {dataset_name} Config {config} ì¤€ë¹„ ì‹¤íŒ¨: {e}"
                    logger.error(error_msg)
                    traceback.print_exc()
                    raise RuntimeError(error_msg) from e
        
        except Exception as e:
            error_msg = f"âŒ [{domain}] ë°ì´í„°ì…‹ {dataset_name} ì¤€ë¹„ ì‹¤íŒ¨: {e}"
            logger.error(error_msg)
            traceback.print_exc()
            raise RuntimeError(error_msg) from e
    
    # ëª¨ë“  ì‘ì—…ì„ ìˆœì°¨ë¡œ ì‹¤í–‰ (ë„ë©”ì¸ë³„ ë³‘ë ¬ ì²˜ë¦¬ëŠ” ìƒìœ„ ë ˆë²¨ì—ì„œ ìˆ˜í–‰)
    if not tasks:
        error_msg = f"âŒ [{domain}] ë„ë©”ì¸ì— ì²˜ë¦¬í•  ì‘ì—…ì´ ì—†ìŠµë‹ˆë‹¤."
        logger.error(error_msg)
        raise RuntimeError(error_msg)
    
    logger.debug(f"   ğŸ“‹ {domain} ë„ë©”ì¸: {len(tasks)}ê°œ ì‘ì—…ì„ ìˆœì°¨ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
    
    # ë„ë©”ì¸ ë‚´ë¶€ëŠ” ìˆœì°¨ ì²˜ë¦¬ (ë„ë©”ì¸ë³„ ë³‘ë ¬ì€ ìƒìœ„ ë ˆë²¨ì—ì„œ ì²˜ë¦¬)
    for task in tasks:
        try:
            result = _process_dataset_config_split(
                domain=task["domain"],
                dataset_name=task["dataset_name"],
                config=task["config"],
                train_split=task["train_split"],
                test_split=task["test_split"],
                train_path=domain_train_path,
                test_path=domain_test_path,
                image_counter_lock=image_counter_lock,
                shared_counters=shared_counters,
                images_dir=images_dir,
                samples_per_config=task["samples_per_config"],
                test_size=test_size,
                use_streaming=use_streaming,
                domain_processed_lock=domain_processed_lock,
                domain_processed_dict=domain_processed_dict,
                max_samples_per_domain=max_samples_per_domain
            )
            # train_count + test_count í•©ê³„
            total_count = result.get("train_count", 0) + result.get("test_count", 0)
            domain_stats["total_processed"] += total_count
        except Exception as e:
            error_msg = f"âŒ [{domain}] ë°ì´í„°ì…‹ {task['dataset_name']} Config {task['config']} ì²˜ë¦¬ ì‹¤íŒ¨: {e}"
            logger.error(error_msg)
            logger.error("ğŸ›‘ ì˜¤ë¥˜ ë°œìƒìœ¼ë¡œ ì¸í•´ ëª¨ë“  ì‘ì—…ì„ ì·¨ì†Œí•˜ê³  í”„ë¡œì„¸ìŠ¤ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            traceback.print_exc()
            raise RuntimeError(error_msg) from e
    
    # ë„ë©”ì¸ë³„ ì²˜ë¦¬ í†µê³„ ë¡œê¹… ë° ê²€ì¦
    if domain_stats["total_processed"] == 0:
        error_msg = f"âŒ [{domain}] ë„ë©”ì¸: ì²˜ë¦¬ëœ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤."
        logger.error(error_msg)
        raise RuntimeError(error_msg)
    
    logger.debug(f"   ğŸ“Š {domain} ë„ë©”ì¸ ì²˜ë¦¬ í†µê³„: ì´ {domain_stats['total_processed']}ê°œ ìƒ˜í”Œ ì²˜ë¦¬ ì™„ë£Œ")
    
    return {
        "domain": domain,
        "domain_stats": domain_stats,
        "domain_processed": domain_processed_dict.get(domain, 0),
        "train_path": domain_train_path,
        "test_path": domain_test_path
    }

def get_multi_domain_sft_dataset(
    domain_configs: Optional[Dict[str, List[str]]] = None,
    tokenizer=None,
    max_length: int = 2048,
    max_samples_per_domain: int = 200,
    test_size: float = 0.1,
    use_streaming: bool = True,
    chunk_size: int = 1000,
    max_workers: int = 4,
    use_cache: bool = True,
    allow_text_only: bool = False
):
    """
    ë©€í‹° ë„ë©”ì¸ SFT ë°ì´í„°ì…‹ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        domain_configs: ë„ë©”ì¸ë³„ ë°ì´í„°ì…‹ ì„¤ì • ë”•ì…”ë„ˆë¦¬
            ì˜ˆ: {"math": ["dataset1", "dataset2"], "science": ["dataset3"]}
        tokenizer: í† í¬ë‚˜ì´ì €
        max_length: ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´
        max_samples_per_domain: ë„ë©”ì¸ë‹¹ ìµœëŒ€ ìƒ˜í”Œ ìˆ˜
        test_size: í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë¹„ìœ¨
        use_streaming: ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ ì‚¬ìš© ì—¬ë¶€
        chunk_size: ì²­í¬ í¬ê¸°
        max_workers: ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜
        use_cache: ìºì‹œ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
    
    Returns:
        DatasetDict with train/test splits, ê° ìƒ˜í”Œì— 'domain' í•„ë“œ í¬í•¨
    """
    if tokenizer is None:
        raise ValueError("Tokenizer must be provided")
    
    if domain_configs is None:
        domain_configs = DOMAIN_DATASETS
    
    # ìºì‹œ í‚¤ ìƒì„±
    cache_key = _generate_cache_key(domain_configs, max_samples_per_domain, test_size, use_streaming, max_workers)
    base_temp_dir = "/mls/conan/tmp"
    cache_dir = os.path.join(base_temp_dir, "cache", cache_key)
    cache_train_path = os.path.join(cache_dir, "train.jsonl")
    cache_test_path = os.path.join(cache_dir, "test.jsonl")
    cache_images_dir = os.path.join(cache_dir, "images")
    cache_meta_path = os.path.join(cache_dir, "cache_meta.json")
    
    # ìºì‹œ í™•ì¸
    if use_cache and os.path.exists(cache_train_path) and os.path.exists(cache_test_path):
        # íŒŒì¼ í¬ê¸° í™•ì¸ (ë¹ˆ íŒŒì¼ì´ ì•„ë‹Œì§€)
        if os.path.getsize(cache_train_path) > 0:
            logger.debug(f"ğŸ’¾ ìºì‹œëœ ë°ì´í„°ì…‹ ë°œê²¬: {cache_key}")
            logger.debug(f"   - ìºì‹œ ë””ë ‰í† ë¦¬: {cache_dir}")
            
            # ë©”íƒ€ë°ì´í„° í™•ì¸
            if os.path.exists(cache_meta_path):
                try:
                    with open(cache_meta_path, "r", encoding="utf-8") as f:
                        cache_meta = json.load(f)
                        logger.debug(f"   - ìºì‹œ ìƒì„± ì‹œê°„: {cache_meta.get('created_at', 'N/A')}")
                        logger.debug(f"   - Train ìƒ˜í”Œ ìˆ˜: {cache_meta.get('train_count', 'N/A')}")
                        logger.debug(f"   - Test ìƒ˜í”Œ ìˆ˜: {cache_meta.get('test_count', 'N/A')}")
                except Exception as e:
                    logger.warning(f"   âš ï¸ ìºì‹œ ë©”íƒ€ë°ì´í„° ì½ê¸° ì‹¤íŒ¨: {e}")
            
            # ìºì‹œëœ íŒŒì¼ë¡œë¶€í„° ë°ì´í„°ì…‹ ë¡œë“œ
            try:
                data_files = {}
                if os.path.exists(cache_train_path) and os.path.getsize(cache_train_path) > 0:
                    data_files["train"] = cache_train_path
                if os.path.exists(cache_test_path) and os.path.getsize(cache_test_path) > 0:
                    data_files["test"] = cache_test_path
                
                if not data_files:
                    logger.warning("   âš ï¸ ìºì‹œ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì¬ì²˜ë¦¬í•©ë‹ˆë‹¤.")
                    raise FileNotFoundError("Cache files are empty")
                
                logger.debug("ğŸ§  ìºì‹œëœ JSONL íŒŒì¼ë¡œë¶€í„° ë°ì´í„°ì…‹ ë¡œë”© (Memory Mapping í™œì„±í™”)...")
                
                # Using load_dataset("json") with explicit schema for memory-mapped loading
                from datasets import load_dataset as hf_load_dataset
                dataset_dict = hf_load_dataset("json", data_files=data_files, features=SFT_JSON_FEATURES)
                
                # CRITICAL RAM FIX: Slice dataset IMMEDIATELY after loading if it exceeds requested size
                # This prevents holding 3M+ Python objects in RAM during the .map() phase
                total_max_samples = max_samples_per_domain * len(domain_configs)
                for split in dataset_dict:
                    current_size = len(dataset_dict[split])
                    if current_size > total_max_samples * 2: # Keep some headroom for filtering
                        logger.debug(f"   âœ‚ï¸  Slicing {split} dataset from {current_size} to {total_max_samples * 2} to save RAM")
                        dataset_dict[split] = dataset_dict[split].select(range(total_max_samples * 2))
                
                logger.debug(f"   âœ… ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ (Memory Mapped): {dataset_dict}")
                
                # ì´ë¯¸ì§€ ê²½ë¡œ ì²˜ë¦¬ ë° ìºìŠ¤íŒ… (Memory Efficient)
                logger.debug("ğŸ–¼ï¸ ì´ë¯¸ì§€ ê²½ë¡œ ì²˜ë¦¬ ë° DatasetImage ìºìŠ¤íŒ… (num_proc í™œìš©)...")
                
                # Setup features for casting
                for split in dataset_dict:
                    current_features = dataset_dict[split].features
                    new_features = current_features.copy()
                    new_features['images'] = Sequence(DatasetImage(decode=True))
                    
                    # Use map with num_proc for faster execution
                    dataset_dict[split] = dataset_dict[split].map(
                        _preprocess_images_for_mapping,
                        fn_kwargs={"cache_images_dir": cache_images_dir},
                        batched=False,
                        num_proc=min(max_workers, 8),
                        features=new_features,
                        desc=f"Processing {split} images"
                    )
                
                logger.debug("âœ… ìºì‹œëœ ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ")
                return dataset_dict
                
            except Exception as e:
                logger.warning(f"   âš ï¸ ìºì‹œ ë¡œë“œ ì‹¤íŒ¨, ì¬ì²˜ë¦¬í•©ë‹ˆë‹¤: {e}")
                traceback.print_exc()
                # ìºì‹œ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë¡œì§ìœ¼ë¡œ ì§„í–‰
    
    # ìºì‹œê°€ ì—†ê±°ë‚˜ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš° ê¸°ì¡´ ì²˜ë¦¬ ë¡œì§
    logger.debug(f"ğŸ“¦ ë©€í‹° ë„ë©”ì¸ ë°ì´í„°ì…‹ ë¡œë”© ì‹œì‘ (ìºì‹œ ì—†ìŒ)")
    logger.debug(f"   - ë„ë©”ì¸ ìˆ˜: {len(domain_configs)}ê°œ")
    logger.debug(f"   - ë„ë©”ì¸ë‹¹ ìµœëŒ€ ìƒ˜í”Œ: {max_samples_per_domain}ê°œ")
    logger.debug(f"   - ì´ ìµœëŒ€ ìƒ˜í”Œ: {max_samples_per_domain * len(domain_configs)}ê°œ")
    logger.debug(f"   - streaming: {use_streaming}")
    logger.debug(f"   - ë³‘ë ¬ ì²˜ë¦¬: {max_workers}ê°œ ì›Œì»¤")
    
    log_memory_usage("ë©€í‹° ë„ë©”ì¸ ë°ì´í„°ì…‹ ë¡œë”© ì‹œì‘")
    
    # ìºì‹œ ë””ë ‰í† ë¦¬ ì‚¬ìš© (ê¸°ì¡´ temp_dir ëŒ€ì‹ )
    os.makedirs(cache_dir, exist_ok=True)
    images_dir = cache_images_dir
    os.makedirs(images_dir, exist_ok=True)

    try:
        train_jsonl_path = cache_train_path
        test_jsonl_path = cache_test_path
        
        # ì´ë¯¸ì§€ ì¹´ìš´í„° lock (ë³‘ë ¬ ì²˜ë¦¬ ì‹œ thread-safe)
        image_counter_lock = threading.Lock()
        
        # ê³µìœ  ì¹´ìš´í„° (thread-safe)
        shared_counters = {
            "total_processed": 0,
            "image_counter": 0,
            "domain_counts": defaultdict(lambda: {"train": 0, "test": 0})
        }

        # ê° ë„ë©”ì¸ë³„ë¡œ ì²˜ë¦¬ (ë³‘ë ¬í™”)
        domain_pbar = tqdm(domain_configs.items(), desc="ë„ë©”ì¸ ì²˜ë¦¬", unit="domain")
        
        # ë„ë©”ì¸ë³„ ë³‘ë ¬ ì²˜ë¦¬
        executor = ThreadPoolExecutor(max_workers=max_workers)
        future_to_domain = {}
        domain_file_paths = {}  # ë„ë©”ì¸ë³„ íŒŒì¼ ê²½ë¡œ ì €ì¥
        
        try:
            for domain, dataset_names in domain_configs.items():
                if not dataset_names:
                    error_msg = f"âŒ {domain} ë„ë©”ì¸ì— ë°ì´í„°ì…‹ì´ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                    logger.error(error_msg)
                    raise ValueError(error_msg)
                
                # ê° ë„ë©”ì¸ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬
                future = executor.submit(
                    _process_domain_datasets,
                    domain=domain,
                    dataset_names=dataset_names,
                    temp_dir=cache_dir,
                    image_counter_lock=image_counter_lock,
                    shared_counters=shared_counters,
                    images_dir=images_dir,
                    max_samples_per_domain=max_samples_per_domain,
                    test_size=test_size,
                    use_streaming=use_streaming,
                    max_workers=max_workers
                )
                future_to_domain[future] = domain
            
            # ì™„ë£Œëœ ì‘ì—… ì²˜ë¦¬
            for future in as_completed(future_to_domain):
                domain = future_to_domain[future]
                try:
                    result = future.result()
                    
                    if result is None:
                        logger.warning(f"â© {domain} ë„ë©”ì¸ ì²˜ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤ (Skipped).")
                        domain_pbar.update(1)
                        continue
                        
                    domain_file_paths[domain] = {
                        "train": result["train_path"],
                        "test": result["test_path"]
                    }
                    domain_pbar.update(1)
                    domain_pbar.set_description(f"ë„ë©”ì¸: {domain} ì™„ë£Œ")
                except Exception as e:
                    error_msg = f"âŒ {domain} ë„ë©”ì¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}"
                    logger.error(error_msg)
                    logger.error("ğŸ›‘ ì˜¤ë¥˜ ë°œìƒìœ¼ë¡œ ì¸í•´ ëª¨ë“  ì‘ì—…ì„ ì·¨ì†Œí•˜ê³  í”„ë¡œì„¸ìŠ¤ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                    traceback.print_exc()
                    domain_pbar.update(1)
                    
                    # ëª¨ë“  ë¯¸ì™„ë£Œ ì‘ì—… ì·¨ì†Œ
                    for f in future_to_domain:
                        if not f.done():
                            f.cancel()
                    
                    os._exit(1)
        finally:
            # ì •ìƒ ì™„ë£Œ ì‹œì—ë§Œ ì •ìƒ ì¢…ë£Œ
            try:
                executor.shutdown(wait=True)
            except:
                pass  # ì´ë¯¸ ì¢…ë£Œëœ ê²½ìš° ë¬´ì‹œ
        
        # ìµœì¢… ì¹´ìš´í„° ì—…ë°ì´íŠ¸
        domain_counts = shared_counters["domain_counts"]
        total_processed = shared_counters["total_processed"]
        image_counter = shared_counters["image_counter"]
        
        # ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ
        domain_pbar.close()
        
        # ë„ë©”ì¸ë³„ íŒŒì¼ì„ ìµœì¢… íŒŒì¼ë¡œ í•©ì¹˜ê¸°
        logger.debug("ğŸ”„ ë„ë©”ì¸ë³„ íŒŒì¼ì„ ìµœì¢… íŒŒì¼ë¡œ í•©ì¹˜ëŠ” ì¤‘...")
        with open(train_jsonl_path, "w", encoding="utf-8") as train_f, \
             open(test_jsonl_path, "w", encoding="utf-8") as test_f:
            
            for domain in domain_configs.keys():
                if domain not in domain_file_paths:
                    continue
                
                # Train íŒŒì¼ í•©ì¹˜ê¸°
                domain_train_path = domain_file_paths[domain]["train"]
                if os.path.exists(domain_train_path):
                    with open(domain_train_path, "r", encoding="utf-8") as f:
                        for line in f:
                            if line.strip():
                                train_f.write(line)
                
                # Test íŒŒì¼ í•©ì¹˜ê¸°
                domain_test_path = domain_file_paths[domain]["test"]
                if os.path.exists(domain_test_path):
                    with open(domain_test_path, "r", encoding="utf-8") as f:
                        for line in f:
                            if line.strip():
                                test_f.write(line)

        # ë„ë©”ì¸ë³„ í†µê³„ ì¶œë ¥ ë° ê²€ì¦
        if not domain_counts:
            error_msg = "âŒ ì²˜ë¦¬ëœ ë„ë©”ì¸ì´ ì—†ìŠµë‹ˆë‹¤."
            logger.error(error_msg)
            raise RuntimeError(error_msg)
        
        total_train_samples = sum(c["train"] for c in domain_counts.values())
        total_test_samples = sum(c["test"] for c in domain_counts.values())
        
        if total_train_samples == 0 and total_test_samples == 0:
            error_msg = "âŒ ì²˜ë¦¬ëœ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤."
            logger.error(error_msg)
            raise RuntimeError(error_msg)
        
        logger.debug("ğŸ“Š ë„ë©”ì¸ë³„ ìƒ˜í”Œ í†µê³„ (ê· ë“±í™” ì „):")
        for domain, counts in domain_counts.items():
            logger.debug(f"   - {domain}: Train {counts['train']}ê°œ, Test {counts['test']}ê°œ")
        
        # ë„ë©”ì¸ë³„ ìƒ˜í”Œ ìˆ˜ ê· ë“±í™”
        # ê° ë„ë©”ì¸ì—ì„œ ë™ì¼í•œ ìˆ˜ì˜ ìƒ˜í”Œì„ ì‚¬ìš©í•˜ë„ë¡ ì¡°ì •
        balanced_train_count = 0
        balanced_test_count = 0
        
        if domain_counts:
            min_train = min([c["train"] for c in domain_counts.values()] + [max_samples_per_domain])
            min_test = min([c["test"] for c in domain_counts.values()] + [int(max_samples_per_domain * test_size)])
            
            logger.debug(f"âš–ï¸ ë„ë©”ì¸ë³„ ìƒ˜í”Œ ìˆ˜ ê· ë“±í™”:")
            logger.debug(f"   - ìµœì†Œ Train ìƒ˜í”Œ ìˆ˜: {min_train}ê°œ")
            logger.debug(f"   - ìµœì†Œ Test ìƒ˜í”Œ ìˆ˜: {min_test}ê°œ")
            
            # JSONL íŒŒì¼ì„ ë‹¤ì‹œ ì½ì–´ì„œ ê· ë“±í™”
            if min_train > 0 or min_test > 0:
                logger.debug("ğŸ”„ ìƒ˜í”Œ ìˆ˜ ê· ë“±í™”ë¥¼ ìœ„í•´ JSONL íŒŒì¼ ì¬ì²˜ë¦¬...")
                
                # ì„ì‹œ íŒŒì¼ë¡œ ì¬ì‘ì„±
                balanced_train_path = os.path.join(cache_dir, "train_balanced.jsonl")
                balanced_test_path = os.path.join(cache_dir, "test_balanced.jsonl")
            
                domain_train_samples = defaultdict(list)
                domain_test_samples = defaultdict(list)
                
                # JSON íŒŒì‹± ì˜¤ë¥˜ ì¶”ì  (ë¦¬ìŠ¤íŠ¸ ì‚¬ìš© - mutable)
                json_parse_errors = {"train": [0], "test": [0]}
                
                # ê¸°ì¡´ JSONL íŒŒì¼ ì½ê¸° (robustí•œ JSON íŒŒì‹±)
                def safe_json_loads(line, line_num=None, error_counter=None):
                    """ì•ˆì „í•œ JSON íŒŒì‹± - ì˜¤ë¥˜ ë°œìƒ ì‹œ None ë°˜í™˜"""
                    try:
                        # ì¤„ë°”ê¿ˆ ì œê±° ë° ê³µë°± ì •ë¦¬
                        line = line.strip()
                        if not line:
                            return None
                        
                        # JSON íŒŒì‹± ì‹œë„
                        try:
                            sample = json.loads(line)
                        except json.JSONDecodeError as e:
                            # ë©€í‹°ë¼ì¸ JSON ì‹œë„ (ë¼ì¸ ëì— ë¶ˆì™„ì „í•œ JSONì´ ìˆì„ ìˆ˜ ìˆìŒ)
                            # ë§ˆì§€ë§‰ ë¶ˆì™„ì „í•œ ê°ì²´ë¥¼ ì œê±°í•˜ê³  ì¬ì‹œë„
                            if e.pos is not None and e.pos < len(line):
                                # ë¶ˆì™„ì „í•œ ë¶€ë¶„ì„ ì œê±°í•˜ê³  ì¬ì‹œë„
                                truncated_line = line[:e.pos].rstrip()
                                # ë§ˆì§€ë§‰ ë¶ˆì™„ì „í•œ ê°ì²´ ì œê±°
                                if truncated_line:
                                    # ë§ˆì§€ë§‰ ë¶ˆì™„ì „í•œ ê°ì²´ì˜ ì‹œì‘ ë¶€ë¶„ ì°¾ê¸°
                                    last_brace = truncated_line.rfind('}')
                                    last_bracket = truncated_line.rfind(']')
                                    last_pos = max(last_brace, last_bracket)
                                    if last_pos > 0:
                                        truncated_line = truncated_line[:last_pos + 1]
                                        try:
                                            sample = json.loads(truncated_line)
                                        except:
                                            raise e
                                    else:
                                        raise e
                                else:
                                    raise e
                            else:
                                raise e
                        
                        # ìƒ˜í”Œì´ dictê°€ ì•„ë‹ˆë©´ None ë°˜í™˜
                        if not isinstance(sample, dict):
                            return None
                        
                        # VLM í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                        sample = ensure_vlm_format(sample)
                        
                        return sample
                    except json.JSONDecodeError as e:
                        if error_counter is not None:
                            error_counter[0] += 1
                        if line_num is not None and error_counter is not None and error_counter[0] <= 10:
                            # ì²˜ìŒ 10ê°œ ì˜¤ë¥˜ë§Œ ìƒì„¸ ë¡œê·¸ ì¶œë ¥
                            logger.warning(f"âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜ (ë¼ì¸ {line_num}): {e}")
                            logger.warning(f"   ë¬¸ì œê°€ ìˆëŠ” ë¼ì¸ (ì²˜ìŒ 200ì): {line[:200]}")
                        return None
                    except Exception as e:
                        if error_counter is not None:
                            error_counter[0] += 1
                        if line_num is not None and error_counter is not None and error_counter[0] <= 10:
                            # ì²˜ìŒ 10ê°œ ì˜¤ë¥˜ë§Œ ìƒì„¸ ë¡œê·¸ ì¶œë ¥
                            logger.warning(f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ (ë¼ì¸ {line_num}): {e}")
                        return None
                
                # Train íŒŒì¼ ì½ê¸°
                train_line_num = 0
                with open(train_jsonl_path, "r", encoding="utf-8") as f:
                    for line in f:
                        train_line_num += 1
                        sample = safe_json_loads(line, train_line_num, error_counter=json_parse_errors["train"])
                        if sample is not None:
                            # Filter out text-only samples if allow_text_only=False
                            if not allow_text_only:
                                images = sample.get("images", [])
                                if not images or len(images) == 0:
                                    continue  # Skip text-only samples

                            domain = sample.get("domain", "unknown")
                            domain_train_samples[domain].append(sample)
                
                # Test íŒŒì¼ ì½ê¸°
                test_line_num = 0
                with open(test_jsonl_path, "r", encoding="utf-8") as f:
                    for line in f:
                        test_line_num += 1
                        sample = safe_json_loads(line, test_line_num, error_counter=json_parse_errors["test"])
                        if sample is not None:
                            # Filter out text-only samples if allow_text_only=False
                            if not allow_text_only:
                                images = sample.get("images", [])
                                if not images or len(images) == 0:
                                    continue  # Skip text-only samples

                            domain = sample.get("domain", "unknown")
                            domain_test_samples[domain].append(sample)
                
                # JSON íŒŒì‹± ì˜¤ë¥˜ ë¡œê·¸ ì¶œë ¥
                train_parse_errors = json_parse_errors["train"][0]
                test_parse_errors = json_parse_errors["test"][0]
                if train_parse_errors > 0 or test_parse_errors > 0:
                    logger.warning(f"âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ: Train {train_parse_errors}ê°œ, Test {test_parse_errors}ê°œ (ê±´ë„ˆëœ€)")
                
                # ê° ë„ë©”ì¸ë³„ë¡œ ìµœì†Œ ìƒ˜í”Œ ìˆ˜ë§Œí¼ë§Œ ì‚¬ìš©
                balanced_domain_counts = defaultdict(lambda: {"train": 0, "test": 0})
                
                with open(balanced_train_path, "w", encoding="utf-8") as train_f, \
                     open(balanced_test_path, "w", encoding="utf-8") as test_f:
                    
                    for domain in domain_configs.keys():
                        # Train ìƒ˜í”Œ ê· ë“±í™”
                        train_samples = domain_train_samples[domain]
                        if len(train_samples) > min_train:
                            random.shuffle(train_samples)
                            train_samples = train_samples[:min_train]
                        
                        for sample in train_samples:
                            try:
                                # VLM í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                                sample = ensure_vlm_format(sample)
                                # JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì •ë¦¬
                                sample = sanitize_sample_for_json(sample)
                                # ensure_ascii=Falseë¡œ íŠ¹ìˆ˜ ë¬¸ì ì œëŒ€ë¡œ ì²˜ë¦¬
                                train_f.write(json.dumps(sample, ensure_ascii=False) + "\n")
                                balanced_domain_counts[domain]["train"] += 1
                                balanced_train_count += 1
                            except Exception as e:
                                logger.warning(f"âš ï¸ Train ìƒ˜í”Œ ì €ì¥ ì‹¤íŒ¨ (ë„ë©”ì¸: {domain}): {e}")
                                continue
                        
                        # Test ìƒ˜í”Œ ê· ë“±í™”
                        test_samples = domain_test_samples[domain]
                        if len(test_samples) > min_test:
                            random.shuffle(test_samples)
                            test_samples = test_samples[:min_test]
                        
                        for sample in test_samples:
                            try:
                                # VLM í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                                sample = ensure_vlm_format(sample)
                                # JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì •ë¦¬
                                sample = sanitize_sample_for_json(sample)
                                # ensure_ascii=Falseë¡œ íŠ¹ìˆ˜ ë¬¸ì ì œëŒ€ë¡œ ì²˜ë¦¬
                                test_f.write(json.dumps(sample, ensure_ascii=False) + "\n")
                                balanced_domain_counts[domain]["test"] += 1
                                balanced_test_count += 1
                            except Exception as e:
                                logger.warning(f"âš ï¸ Test ìƒ˜í”Œ ì €ì¥ ì‹¤íŒ¨ (ë„ë©”ì¸: {domain}): {e}")
                                continue
                
                # ê· ë“±í™”ëœ íŒŒì¼ ê²€ì¦ ë° ì •ì œ
                logger.info("ğŸ” ê· ë“±í™”ëœ íŒŒì¼ ê²€ì¦ ì¤‘...")
                
                # Train íŒŒì¼ ê²€ì¦
                if os.path.exists(balanced_train_path):
                    valid_train_lines = []
                    with open(balanced_train_path, "r", encoding="utf-8") as f:
                        for line_num, line in enumerate(f, 1):
                            line = line.strip()
                            if not line:
                                continue
                            try:
                                sample = json.loads(line)
                                sample = ensure_vlm_format(sample)
                                sample = sanitize_sample_for_json(sample)
                                if isinstance(sample, dict) and "messages" in sample:
                                    valid_train_lines.append(json.dumps(sample, ensure_ascii=False))
                            except:
                                continue
                    
                    if valid_train_lines:
                        with open(balanced_train_path, "w", encoding="utf-8") as f:
                            for line in valid_train_lines:
                                f.write(line + "\n")
                        balanced_train_count = len(valid_train_lines)
                    else:
                        logger.warning("âš ï¸ ê· ë“±í™”ëœ Train íŒŒì¼ì— ìœ íš¨í•œ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤.")
                        balanced_train_count = 0
                
                # Test íŒŒì¼ ê²€ì¦
                if os.path.exists(balanced_test_path):
                    valid_test_lines = []
                    with open(balanced_test_path, "r", encoding="utf-8") as f:
                        for line_num, line in enumerate(f, 1):
                            line = line.strip()
                            if not line:
                                continue
                            try:
                                sample = json.loads(line)
                                sample = ensure_vlm_format(sample)
                                sample = sanitize_sample_for_json(sample)
                                if isinstance(sample, dict) and "messages" in sample:
                                    valid_test_lines.append(json.dumps(sample, ensure_ascii=False))
                            except:
                                continue
                    
                    if valid_test_lines:
                        with open(balanced_test_path, "w", encoding="utf-8") as f:
                            for line in valid_test_lines:
                                f.write(line + "\n")
                        balanced_test_count = len(valid_test_lines)
                    else:
                        logger.warning("âš ï¸ ê· ë“±í™”ëœ Test íŒŒì¼ì— ìœ íš¨í•œ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤.")
                        balanced_test_count = 0
                
                # ê· ë“±í™”ëœ íŒŒì¼ë¡œ êµì²´
                train_jsonl_path = balanced_train_path
                test_jsonl_path = balanced_test_path
                
                logger.info("ğŸ“Š ë„ë©”ì¸ë³„ ìƒ˜í”Œ í†µê³„ (ê· ë“±í™” í›„):")
                for domain, counts in balanced_domain_counts.items():
                    logger.info(f"   - {domain}: Train {counts['train']}ê°œ, Test {counts['test']}ê°œ")
                
                logger.info(f"âœ… ê· ë“±í™” ì™„ë£Œ: Train {balanced_train_count}ê°œ, Test {balanced_test_count}ê°œ")
                
                # ê· ë“±í™” í›„ ìƒ˜í”Œì´ ì—†ìœ¼ë©´ ì˜¤ë¥˜ ë°œìƒ
                if balanced_train_count == 0 and balanced_test_count == 0:
                    error_msg = "âŒ ê· ë“±í™” í›„ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤. JSON íŒŒì‹± ì˜¤ë¥˜ë‚˜ í•„í„°ë§ìœ¼ë¡œ ì¸í•´ ëª¨ë“  ìƒ˜í”Œì´ ì œê±°ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                    logger.error(error_msg)
                    raise RuntimeError(error_msg)
            else:
                total_train = sum(c["train"] for c in domain_counts.values())
                total_test = sum(c["test"] for c in domain_counts.values())
                balanced_train_count = total_train
                balanced_test_count = total_test
                logger.debug(f"âœ… ì´ ìƒ˜í”Œ ìˆ˜ì§‘ ì™„ë£Œ: Train {total_train}ê°œ, Test {total_test}ê°œ")
        else:
            balanced_train_count = 0
            balanced_test_count = 0
        
        # JSONL íŒŒì¼ë¡œë¶€í„° ë°ì´í„°ì…‹ ë¡œë“œ
        original_data_files = {}
        data_files = {}
        final_train_count = balanced_train_count
        final_test_count = balanced_test_count
        
        if final_train_count > 0:
            original_data_files["train"] = train_jsonl_path
            data_files["train"] = train_jsonl_path
        if final_test_count > 0:
            original_data_files["test"] = test_jsonl_path
            data_files["test"] = test_jsonl_path

        if not data_files:
            error_msg = "âŒ ë³€í™˜ëœ í›ˆë ¨ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ì…‹ í˜•ì‹ì„ í™•ì¸í•˜ì„¸ìš”."
            logger.error(error_msg)
            raise RuntimeError(error_msg)
        
        if final_train_count == 0:
            error_msg = "âŒ Train ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤."
            logger.error(error_msg)
            raise RuntimeError(error_msg)
        
        logger.info("ğŸ§  JSONL íŒŒì¼ë¡œë¶€í„° ë°ì´í„°ì…‹ ë¡œë”©...")
        logger.info(f"   - Train íŒŒì¼: {data_files.get('train', 'N/A')}")
        logger.info(f"   - Test íŒŒì¼: {data_files.get('test', 'N/A')}")
        
        # JSONL íŒŒì¼ ê²€ì¦ ë° ì •ì œ (ë¹ˆ íŒŒì¼, ì˜ëª»ëœ JSON ë¼ì¸ ì œê±°)
        cleaned_data_files = {}
        for split_name, file_path in data_files.items():
            try:
                logger.info(f"   ğŸ“‹ {split_name} íŒŒì¼ ê²€ì¦ ë° ì •ì œ ì¤‘...")
                
                # íŒŒì¼ ì¡´ì¬ ë° í¬ê¸° í™•ì¸
                if not os.path.exists(file_path):
                    logger.error(f"   âŒ {split_name} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
                    continue
                
                file_size = os.path.getsize(file_path)
                if file_size == 0:
                    logger.error(f"   âŒ {split_name} íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤: {file_path}")
                    continue
                
                # íŒŒì¼ ì½ê¸° ë° ìœ íš¨í•œ JSON ë¼ì¸ë§Œ ì¶”ì¶œ
                valid_lines = []
                total_lines = 0
                invalid_lines = 0
                
                with open(file_path, "r", encoding="utf-8") as f:
                    for line_num, line in enumerate(f, 1):
                        total_lines += 1
                        line = line.strip()
                        if not line:
                            continue
                        
                        try:
                            # JSON íŒŒì‹± ì‹œë„
                            sample = json.loads(line)
                            
                            # VLM í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                            sample = ensure_vlm_format(sample)
                            
                            # JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì •ë¦¬
                            sample = sanitize_sample_for_json(sample)
                            
                            # ìœ íš¨í•œ ìƒ˜í”Œì¸ì§€ í™•ì¸ (messages í•„ë“œ í•„ìˆ˜)
                            if not isinstance(sample, dict) or "messages" not in sample:
                                invalid_lines += 1
                                if invalid_lines <= 5:
                                    logger.warning(f"   âš ï¸ {split_name} íŒŒì¼ {line_num}ë²ˆì§¸ ì¤„: messages í•„ë“œê°€ ì—†ìŒ")
                                continue
                            
                            # ìœ íš¨í•œ JSON ë¼ì¸ìœ¼ë¡œ ì €ì¥
                            valid_lines.append(json.dumps(sample, ensure_ascii=False))
                            
                        except json.JSONDecodeError as e:
                            invalid_lines += 1
                            if invalid_lines <= 5:
                                logger.warning(f"   âš ï¸ {split_name} íŒŒì¼ {line_num}ë²ˆì§¸ ì¤„ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                                logger.warning(f"      ì¤„ ë‚´ìš© (ì²˜ìŒ 200ì): {line[:200]}")
                            continue
                        except Exception as e:
                            invalid_lines += 1
                            if invalid_lines <= 5:
                                logger.warning(f"   âš ï¸ {split_name} íŒŒì¼ {line_num}ë²ˆì§¸ ì¤„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                            continue
                
                # ìœ íš¨í•œ ë¼ì¸ì´ ì—†ìœ¼ë©´ ê±´ë„ˆë›°ê¸°
                if not valid_lines:
                    logger.error(f"   âŒ {split_name} íŒŒì¼ì— ìœ íš¨í•œ JSON ë¼ì¸ì´ ì—†ìŠµë‹ˆë‹¤ (ì´ {total_lines}ì¤„, ìœ íš¨í•˜ì§€ ì•Šì€ ë¼ì¸ {invalid_lines}ê°œ)")
                    continue
                
                # ì •ì œëœ íŒŒì¼ë¡œ ì €ì¥
                cleaned_file_path = file_path + ".cleaned"
                with open(cleaned_file_path, "w", encoding="utf-8") as f:
                    for valid_line in valid_lines:
                        f.write(valid_line + "\n")
                
                logger.info(f"   âœ… {split_name} íŒŒì¼ ê²€ì¦ ì™„ë£Œ: ì´ {total_lines}ì¤„ ì¤‘ {len(valid_lines)}ê°œ ìœ íš¨ (í¬ê¸°: {file_size / 1024 / 1024:.2f} MB)")
                if invalid_lines > 0:
                    logger.warning(f"   âš ï¸ {invalid_lines}ê°œ ìœ íš¨í•˜ì§€ ì•Šì€ ë¼ì¸ ì œê±°ë¨")
                
                cleaned_data_files[split_name] = cleaned_file_path
                
            except Exception as e:
                logger.error(f"   âŒ {split_name} íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {e}")
                traceback.print_exc()
        
        # ì •ì œëœ íŒŒì¼ì´ ì—†ìœ¼ë©´ ì˜¤ë¥˜
        if not cleaned_data_files:
            error_msg = "âŒ ì •ì œëœ JSONL íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
            logger.error(error_msg)
            raise RuntimeError(error_msg)
        
        # ì •ì œëœ íŒŒì¼ë¡œ êµì²´
        data_files = cleaned_data_files
        
        
        try:
            # Reload from JSONL with memory mapping enabled (streaming=False but using load_dataset("json"))
            # JSONL í˜•ì‹ìœ¼ë¡œ ëª…ì‹œì ìœ¼ë¡œ ì§€ì • (lines=True)
            logger.info("ğŸ“¦ ë°ì´í„°ì…‹ ë¡œë”© ì¤‘...")
            dataset_dict = load_dataset("json", data_files=data_files, features=SFT_JSON_FEATURES)
        except Exception as load_e:
            logger.error(f"âŒ JSONL íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {load_e}")
            logger.error(f"   - Train íŒŒì¼: {data_files.get('train', 'N/A')}")
            logger.error(f"   - Test íŒŒì¼: {data_files.get('test', 'N/A')}")
            
            # ë¬¸ì œê°€ ìˆëŠ” ìƒ˜í”Œ ì°¾ê¸° (58ë²ˆì§¸ ì¤„ ì£¼ë³€ í¬í•¨)
            for split_name, file_path in data_files.items():
                logger.debug(f"   ğŸ” {split_name} íŒŒì¼ì—ì„œ ë¬¸ì œ ìƒ˜í”Œ ê²€ìƒ‰ ì¤‘...")
                try:
                    with open(file_path, "r", encoding="utf-8") as f:
                        for line_num, line in enumerate(f, 1):
                            # 58ë²ˆì§¸ ì¤„ ì£¼ë³€ê³¼ ì²˜ìŒ 100ì¤„ í™•ì¸
                            if line_num > 100 and (line_num < 50 or line_num > 70):
                                continue
                            if line.strip():
                                try:
                                    sample = json.loads(line)
                                    # messages êµ¬ì¡° í™•ì¸
                                    if "messages" in sample:
                                        for msg_idx, msg in enumerate(sample["messages"]):
                                            if "content" in msg:
                                                content = msg["content"]
                                                # contentê°€ ë¬¸ìì—´ì¸ ê²½ìš°
                                                if isinstance(content, str):
                                                    logger.error(f"   âŒ {split_name} íŒŒì¼ {line_num}ë²ˆì§¸ ì¤„, ë©”ì‹œì§€ {msg_idx}: contentê°€ ë¬¸ìì—´ì„ (ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•¨)")
                                                    logger.error(f"      content íƒ€ì…: {type(content)}, ê°’: {repr(content)[:200]}")
                                                    logger.error(f"      ì „ì²´ ë©”ì‹œì§€: {json.dumps(msg, ensure_ascii=False, indent=2)[:500]}")
                                                # contentê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
                                                elif isinstance(content, list):
                                                    for content_idx, content_item in enumerate(content):
                                                        # content_itemì´ ë¬¸ìì—´ì¸ ê²½ìš°
                                                        if isinstance(content_item, str):
                                                            logger.error(f"   âŒ {split_name} íŒŒì¼ {line_num}ë²ˆì§¸ ì¤„, ë©”ì‹œì§€ {msg_idx}, content[{content_idx}]: ë¬¸ìì—´ì„ (ê°ì²´ì—¬ì•¼ í•¨)")
                                                            logger.error(f"      content_item íƒ€ì…: {type(content_item)}, ê°’: {repr(content_item)[:200]}")
                                                        # content_itemì´ dictì¸ ê²½ìš°
                                                        elif isinstance(content_item, dict):
                                                            if "text" in content_item:
                                                                text_value = content_item["text"]
                                                                if not isinstance(text_value, str):
                                                                    logger.error(f"   âŒ {split_name} íŒŒì¼ {line_num}ë²ˆì§¸ ì¤„, ë©”ì‹œì§€ {msg_idx}, content[{content_idx}]: textê°€ ë¬¸ìì—´ì´ ì•„ë‹˜")
                                                                    logger.error(f"      íƒ€ì…: {type(text_value)}, ê°’: {repr(text_value)[:100]}")
                                                else:
                                                    logger.error(f"   âŒ {split_name} íŒŒì¼ {line_num}ë²ˆì§¸ ì¤„, ë©”ì‹œì§€ {msg_idx}: contentê°€ ì˜ˆìƒì¹˜ ëª»í•œ íƒ€ì…")
                                                    logger.error(f"      content íƒ€ì…: {type(content)}, ê°’: {repr(content)[:200]}")
                                except json.JSONDecodeError as e:
                                    logger.error(f"   âŒ {split_name} íŒŒì¼ {line_num}ë²ˆì§¸ ì¤„: JSON íŒŒì‹± ì‹¤íŒ¨ - {e}")
                                    logger.error(f"      ì¤„ ë‚´ìš©: {line[:300]}")
                except Exception as e:
                    logger.error(f"   âŒ {split_name} íŒŒì¼ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
                    traceback.print_exc()
            
            raise
        
        # ì •ì œëœ íŒŒì¼ ì •ë¦¬ (ì›ë³¸ íŒŒì¼ë¡œ êµì²´)
        logger.info("ğŸ§¹ ì •ì œëœ íŒŒì¼ ì •ë¦¬ ì¤‘...")
        for split_name, cleaned_file_path in cleaned_data_files.items():
            try:
                if split_name in original_data_files:
                    original_file_path = original_data_files[split_name]
                    if os.path.exists(cleaned_file_path):
                        # ì •ì œëœ íŒŒì¼ë¡œ ì›ë³¸ íŒŒì¼ êµì²´
                        if os.path.exists(original_file_path):
                            os.remove(original_file_path)
                        shutil.move(cleaned_file_path, original_file_path)
                        logger.debug(f"   âœ… {split_name} íŒŒì¼ ì •ì œ ì™„ë£Œ: {original_file_path}")
            except Exception as e:
                logger.warning(f"   âš ï¸ {split_name} íŒŒì¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        
        logger.info("ğŸ–¼ï¸ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì´ë¯¸ì§€ ê°ì²´ë¡œ ìºìŠ¤íŒ… (lazy loading)...")
        for split in dataset_dict:
            current_features = dataset_dict[split].features
            new_features = current_features.copy()
            if 'images' in new_features:
                def preprocess_images(example):
                    """ì´ë¯¸ì§€ ë°ì´í„° ì „ì²˜ë¦¬ - ì¤‘ì²© ë¦¬ìŠ¤íŠ¸ í‰ë©´í™”"""
                    if 'images' in example and example['images']:
                        example['images'] = validate_image_data(example['images'])
                    # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ìœ ì§€
                    elif 'images' not in example:
                        example['images'] = []
                    return example
                
                dataset_dict[split] = dataset_dict[split].map(preprocess_images)
                # ì´ë¯¸ì§€ê°€ ìˆëŠ” ìƒ˜í”Œë§Œ Sequence(DatasetImage)ë¡œ ìºìŠ¤íŒ…
                # ë¹ˆ ë¦¬ìŠ¤íŠ¸ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
                if isinstance(new_features['images'], Sequence):
                    new_features['images'] = Sequence(DatasetImage(decode=True))
                    dataset_dict[split] = dataset_dict[split].cast(new_features)

        logger.debug("âœ… ë©€í‹° ë„ë©”ì¸ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ")
        
        # ì²˜ë¦¬ ì™„ë£Œ í›„ ë©”íƒ€ë°ì´í„° ì €ì¥
        try:
            cache_meta = {
                "created_at": datetime.now().isoformat(),
                "train_count": balanced_train_count,
                "test_count": balanced_test_count,
                "domain_configs": domain_configs,
                "max_samples_per_domain": max_samples_per_domain,
                "test_size": test_size,
                "use_streaming": use_streaming,
                "max_workers": max_workers,
                "cache_key": cache_key
            }
            with open(cache_meta_path, "w", encoding="utf-8") as f:
                json.dump(cache_meta, f, indent=2, ensure_ascii=False)
            logger.debug(f"ğŸ’¾ ë°ì´í„°ì…‹ ìºì‹œ ì €ì¥ ì™„ë£Œ: {cache_dir}")
        except Exception as e:
            logger.warning(f"âš ï¸ ìºì‹œ ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
        
        return dataset_dict

    except Exception as e:
        logger.error(f"âŒ ë©€í‹° ë„ë©”ì¸ ë°ì´í„°ì…‹ ë¡œë”© ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        # ì‹¤íŒ¨ ì‹œì—ë„ ìºì‹œ ë””ë ‰í† ë¦¬ëŠ” ìœ ì§€ (ë¶€ë¶„ì ìœ¼ë¡œ ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ìˆì„ ìˆ˜ ìˆìŒ)
        # shutil.rmtree(cache_dir, ignore_errors=True)
        raise Exception(f"ğŸ˜¢ ë©€í‹° ë„ë©”ì¸ ë°ì´í„°ì…‹ ë¡œë”© ì‹œë„ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.") from e


def create_simple_collate_fn(processor, max_length: int = 2048, allow_text_only: bool = True):
    """
    SFTTrainerìš© ì»¤ìŠ¤í…€ data collator - DeepSpeed ZeRO-3 ìµœì í™” ë²„ì „
    (ëª¨ë“  ë­í¬ê°€ ë™ì¼í•œ ëª¨ë‹¬ë¦¬í‹° êµ¬ì¡°ë¥¼ ê°–ë„ë¡ ëŒ€ì¹­ì„± ìœ ì§€)
    """
    import re
    from trl.trainer.sft_trainer import DataCollatorForVisionLanguageModeling
    
    class CustomSFTDataCollator(DataCollatorForVisionLanguageModeling):
        def __init__(self, processor, max_length: int = 2048, allow_text_only: bool = True):
            super().__init__(processor=processor, max_length=max_length)
            self.processor = processor
            self.max_length = max_length
            self.allow_text_only = allow_text_only
            
            # No Siglip - use native processor for Qwen3-VL-MoE compatibility

            # Detect image token for Qwen3-VL/Qwen2-VL
            self.image_token = None
            for attr in ['image_token', 'im_start_token', 'vision_token']:
                if hasattr(self.processor, attr):
                    token = getattr(self.processor, attr)
                    if isinstance(token, str): self.image_token = token; break
            if self.image_token is None: self.image_token = '<image>'
            
            # Dummy image for ZeRO-3 symmetry (Compatible with Qwen3-VL-MoE)
            # Use size divisible by patch_size(16) * spatial_merge_size(2)
            self.dummy_image = Image.new('RGB', (64, 64), (0, 0, 0))

        def _collate_language_modeling(self, examples):
            """
            Modified for Universal Exoskeleton:
            1. Enforce specific token count (196) to match Siglip vision tower features.
            2. Bypass Qwen dynamic token calculation by passing images=None to processor.
            3. Manually inject Siglip-processed pixel_values and image_grid_thw.
            """
            messages = [example["messages"] for example in examples]
            
            # 1. Collect Images & Texts
            images = []
            has_real_images = []
            
            for example in examples:
                img = example.get("images", None)
                if img is not None and (isinstance(img, list) and len(img) > 0):
                    extracted_img = img[0] if isinstance(img, list) else img
                    images.append(extracted_img)
                    has_real_images.append(True)
                else:
                    images.append(self.dummy_image)
                    has_real_images.append(False)

            tokenizer = self.processor.tokenizer if hasattr(self.processor, 'tokenizer') else self.processor
            
            texts = []
            for i, m in enumerate(messages):
                # Check if message has image placeholder
                has_image_in_msg = False
                for msg in m:
                    if isinstance(msg.get('content'), list):
                        for item in msg['content']:
                            if isinstance(item, dict) and item.get('type') == 'image':
                                has_image_in_msg = True
                
                # If no image in message but we have image, inject image placeholder
                if not has_image_in_msg:
                    if m and m[0]['role'] == 'user':
                        if isinstance(m[0]['content'], str):
                            m[0]['content'] = [{"type": "image"}, {"type": "text", "text": m[0]['content']}]
                        elif isinstance(m[0]['content'], list):
                            m[0]['content'].insert(0, {"type": "image"})

                # CRITICAL: Use PROCESSOR.apply_chat_template, not tokenizer!
                # Only the processor knows how to generate image tokens for Qwen3-VL-MoE
                text = self.processor.apply_chat_template(m, tokenize=False, add_generation_prompt=False)
                texts.append(text)

            # 2. Process with NATIVE processor (text + images together)
            # This ensures image_grid_thw is computed correctly for Qwen3-VL-MoE
            try:
                output = self.processor(
                    text=texts,
                    images=images,  # Let native processor handle images
                    return_tensors="pt",
                    padding=True,
                    truncation=True,
                    max_length=self.max_length
                )
            except Exception as e:
                print(f"âš ï¸ Native image processing failed: {e}. Falling back to text-only.")
                output = self.processor(
                    text=texts,
                    images=None,
                    return_tensors="pt",
                    padding=True,
                    truncation=True,
                    max_length=self.max_length
                )

            # 5. Handle Labels (Masking)
            input_ids = output["input_ids"]
            if "labels" not in output or output["labels"] is None:
                output["labels"] = input_ids.clone()
            
            labels = output["labels"]
            
            # Mask special vision tokens
            # 151652: <|vision_start|>, 151653: <|vision_end|>, 151655: <|image_pad|>
            special_ids = [151652, 151653, 151655]
            for sid in special_ids:
                labels[labels == sid] = -100
            
            # Mask padding
            if tokenizer.pad_token_id is not None:
                labels[labels == tokenizer.pad_token_id] = -100
                
            output["labels"] = labels
            
            return output

        def __call__(self, features):
             # Just pass through to our custom collator logic
             return self.torch_call(examples=features)
    
    return CustomSFTDataCollator(processor, max_length=max_length, allow_text_only=allow_text_only)


# ë„ë©”ì¸ë³„ ë°ì´í„°ì…‹ ë¹Œë” í•¨ìˆ˜ë“¤
def math_domain_dataset(tokenizer, max_samples: int = 200, use_streaming: bool = True, max_workers: int = 4):
    """ìˆ˜í•™ ë„ë©”ì¸ ë°ì´í„°ì…‹"""
    log_memory_usage("ìˆ˜í•™ ë„ë©”ì¸ ë°ì´í„°ì…‹ ì‹œì‘")
    dataset = get_multi_domain_sft_dataset(
        domain_configs={"math": DOMAIN_DATASETS["math"]},
        tokenizer=tokenizer,
        max_samples_per_domain=max_samples,
        use_streaming=use_streaming,
        max_workers=max_workers
    )
    log_memory_usage("ìˆ˜í•™ ë„ë©”ì¸ ë°ì´í„°ì…‹ ì™„ë£Œ")
    return dataset

def science_domain_dataset(tokenizer, max_samples: int = 200, use_streaming: bool = True, max_workers: int = 4):
    """ê³¼í•™ ë„ë©”ì¸ ë°ì´í„°ì…‹"""
    log_memory_usage("ê³¼í•™ ë„ë©”ì¸ ë°ì´í„°ì…‹ ì‹œì‘")
    dataset = get_multi_domain_sft_dataset(
        domain_configs={"science": DOMAIN_DATASETS["science"]},
        tokenizer=tokenizer,
        max_samples_per_domain=max_samples,
        use_streaming=use_streaming,
        max_workers=max_workers
    )
    log_memory_usage("ê³¼í•™ ë„ë©”ì¸ ë°ì´í„°ì…‹ ì™„ë£Œ")
    return dataset

def code_domain_dataset(tokenizer, max_samples: int = 200, use_streaming: bool = True, max_workers: int = 4):
    """ì½”ë“œ ë„ë©”ì¸ ë°ì´í„°ì…‹"""
    log_memory_usage("ì½”ë“œ ë„ë©”ì¸ ë°ì´í„°ì…‹ ì‹œì‘")
    dataset = get_multi_domain_sft_dataset(
        domain_configs={"code": DOMAIN_DATASETS["code"]},
        tokenizer=tokenizer,
        max_samples_per_domain=max_samples,
        use_streaming=use_streaming,
        max_workers=max_workers
    )
    log_memory_usage("ì½”ë“œ ë„ë©”ì¸ ë°ì´í„°ì…‹ ì™„ë£Œ")
    return dataset

def puzzle_domain_dataset(tokenizer, max_samples: int = 200, use_streaming: bool = True, max_workers: int = 4):
    """í¼ì¦ ë„ë©”ì¸ ë°ì´í„°ì…‹"""
    log_memory_usage("í¼ì¦ ë„ë©”ì¸ ë°ì´í„°ì…‹ ì‹œì‘")
    dataset = get_multi_domain_sft_dataset(
        domain_configs={"puzzle": DOMAIN_DATASETS["puzzle"]},
        tokenizer=tokenizer,
        max_samples_per_domain=max_samples,
        use_streaming=use_streaming,
        max_workers=max_workers
    )
    log_memory_usage("í¼ì¦ ë„ë©”ì¸ ë°ì´í„°ì…‹ ì™„ë£Œ")
    return dataset

def vision_domain_dataset(tokenizer, max_samples: int = 200, use_streaming: bool = True, max_workers: int = 4):
    """ë¹„ì „ ë„ë©”ì¸ ë°ì´í„°ì…‹"""
    log_memory_usage("ë¹„ì „ ë„ë©”ì¸ ë°ì´í„°ì…‹ ì‹œì‘")
    dataset = get_multi_domain_sft_dataset(
        domain_configs={"vision": DOMAIN_DATASETS["vision"]},
        tokenizer=tokenizer,
        max_samples_per_domain=max_samples,
        use_streaming=use_streaming,
        max_workers=max_workers
    )
    log_memory_usage("ë¹„ì „ ë„ë©”ì¸ ë°ì´í„°ì…‹ ì™„ë£Œ")
    return dataset

def ocr_domain_dataset(tokenizer, max_samples: int = 200, use_streaming: bool = True, max_workers: int = 4):
    """OCR ë„ë©”ì¸ ë°ì´í„°ì…‹"""
    log_memory_usage("OCR ë„ë©”ì¸ ë°ì´í„°ì…‹ ì‹œì‘")
    dataset = get_multi_domain_sft_dataset(
        domain_configs={"ocr": DOMAIN_DATASETS["ocr"]},
        tokenizer=tokenizer,
        max_samples_per_domain=max_samples,
        use_streaming=use_streaming,
        max_workers=max_workers
    )
    log_memory_usage("OCR ë„ë©”ì¸ ë°ì´í„°ì…‹ ì™„ë£Œ")
    return dataset

def all_domains_dataset(tokenizer, max_samples_per_domain: int = 200, use_streaming: bool = True, max_workers: int = 4):
    """ëª¨ë“  ë„ë©”ì¸ í†µí•© ë°ì´í„°ì…‹"""
    log_memory_usage("ì „ì²´ ë„ë©”ì¸ ë°ì´í„°ì…‹ ì‹œì‘")
    dataset = get_multi_domain_sft_dataset(
        domain_configs=DOMAIN_DATASETS,
        tokenizer=tokenizer,
        max_samples_per_domain=max_samples_per_domain,
        use_streaming=use_streaming,
        max_workers=max_workers
    )
    log_memory_usage("ì „ì²´ ë„ë©”ì¸ ë°ì´í„°ì…‹ ì™„ë£Œ")
    return dataset


if __name__ == "__main__":
    from transformers import AutoTokenizer
    
    logger.debug("ğŸš€ ë©€í‹° ë„ë©”ì¸ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    log_memory_usage("í”„ë¡œê·¸ë¨ ì‹œì‘")
    
    tokenizer = AutoTokenizer.from_pretrained("google/gemma-2b-it")
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
    
    log_memory_usage("í† í¬ë‚˜ì´ì € ë¡œë“œ í›„")
    
    # ì „ì²´ ë„ë©”ì¸ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸
    try:
        logger.debug("ğŸ“¦ ì „ì²´ ë„ë©”ì¸ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸")
        dataset = all_domains_dataset(tokenizer, max_samples_per_domain=50, use_streaming=True)
        log_memory_usage("ì „ì²´ ë„ë©”ì¸ ë°ì´í„°ì…‹ ìƒì„± í›„")
        
        logger.debug(f"ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ: {dataset}")
        
        # ë„ë©”ì¸ë³„ ìƒ˜í”Œ í™•ì¸
        if 'train' in dataset:
            train_domains = {}
            for i in range(min(100, len(dataset['train']))):
                sample = dataset['train'][i]
                domain = sample.get('domain', 'unknown')
                train_domains[domain] = train_domains.get(domain, 0) + 1
            
            logger.debug(f"Train ì„¸íŠ¸ ë„ë©”ì¸ ë¶„í¬: {train_domains}")
        
    except Exception as e:
        logger.error(f"ì „ì²´ ë„ë©”ì¸ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
    
    log_memory_usage("í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    logger.debug("âœ… ë©€í‹° ë„ë©”ì¸ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

