#!/usr/bin/env python3
"""
SPECTRA ì»´í¬ë„ŒíŠ¸ë³„ ìë™ ì ê²€ ìŠ¤í¬ë¦½íŠ¸
ê° ì»´í¬ë„ŒíŠ¸ë¥¼ ë¹„í™œì„±í™”í•˜ë©´ì„œ backward ì—ëŸ¬ ë°œìƒ ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
ì‹¤ì œ í•™ìŠµ ëŒ€ì‹  ë‹¨ì¼ forward/backward í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰í•˜ì—¬ ë¹ ë¥´ê²Œ ì ê²€í•©ë‹ˆë‹¤.
"""

import os
import sys
import json
import time
import subprocess
import traceback
from datetime import datetime
from pathlib import Path

# ì‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì •
WORKSPACE = "/home/conan/workspace/llm_training"

# í…ŒìŠ¤íŠ¸ ì„¤ì •
TEST_CONFIG = {
    "timeout_seconds": 600,  # 10ë¶„ íƒ€ì„ì•„ì›ƒ
    "report_path": f"{WORKSPACE}/spectra_component_report.md",
}

# í…ŒìŠ¤íŠ¸í•  ì»´í¬ë„ŒíŠ¸ ëª©ë¡
COMPONENT_TESTS = [
    {
        "name": "baseline_no_spectra",
        "description": "SPECTRA ì™„ì „ ë¹„í™œì„±í™” (Qwen3 ì›ë˜ MoE)",
        "env_vars": {"SPECTRA_DISABLE_ALL": "1"},
    },
    {
        "name": "disable_expert_dispatch",
        "description": "Expert dispatch ë¹„í™œì„±í™” (hidden_states ê·¸ëŒ€ë¡œ ë°˜í™˜)",
        "env_vars": {"SPECTRA_DISABLE_EXPERT_DISPATCH": "1"},
    },
    {
        "name": "disable_router",
        "description": "SPECTRARouter ë¹„í™œì„±í™” (uniform routing)",
        "env_vars": {"SPECTRA_DISABLE_ROUTER": "1"},
    },
    {
        "name": "disable_shared_experts",
        "description": "shared_experts ì²˜ë¦¬ ë¹„í™œì„±í™”",
        "env_vars": {"SPECTRA_DISABLE_SHARED_EXPERTS": "1"},
    },
    {
        "name": "disable_intent_gated",
        "description": "IntentGatedContextCell ë¹„í™œì„±í™”",
        "env_vars": {"SPECTRA_DISABLE_INTENT_GATED": "1"},
    },
    {
        "name": "disable_expression_proj",
        "description": "ExpressionProjector ë¹„í™œì„±í™”",
        "env_vars": {"SPECTRA_DISABLE_EXPRESSION_PROJ": "1"},
    },
    {
        "name": "full_spectra",
        "description": "SPECTRA ì „ì²´ í™œì„±í™” (í˜„ì¬ ìƒíƒœ)",
        "env_vars": {},
    },
]

# ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš© Python ìŠ¤í¬ë¦½íŠ¸
QUICK_TEST_SCRIPT = '''
import os
import sys
import torch
import json

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ["SPECTRA_TEST_MODE"] = "1"
{env_setup}

# DeepSpeed/Accelerate ê´€ë ¨ í™˜ê²½ ë³€ìˆ˜
os.environ["CUDA_VISIBLE_DEVICES"] = "0"
os.environ["TOKENIZERS_PARALLELISM"] = "false"

print(f"[TEST] Starting component test: {test_name}")
print(f"[TEST] Environment: {{k: v for k, v in os.environ.items() if 'SPECTRA' in k}}")

try:
    # ìµœì†Œí•œì˜ import
    sys.path.insert(0, "{workspace}")
    
    from transformers import AutoConfig, AutoModelForCausalLM
    from models.spectra_model import SPECTRAExoskeletonMoEInjector, SPECTRATextConfig
    import deepspeed
    
    print("[TEST] Loading model config...")
    
    # Config ë¡œë“œ
    config_path = "{workspace}/spectra_sft/config/spectra_qwen_config.json"
    with open(config_path) as f:
        full_config = json.load(f)
    
    model_name = full_config["model_config"]["model_name_or_path"]
    
    # ëª¨ë¸ ë¡œë“œ (ZeRO-3 ì‚¬ìš©)
    print("[TEST] Loading model with DeepSpeed ZeRO-3...")
    
    ds_config = {{
        "train_batch_size": 1,
        "gradient_accumulation_steps": 1,
        "fp16": {{"enabled": False}},
        "bf16": {{"enabled": True}},
        "zero_optimization": {{
            "stage": 3,
            "offload_param": {{
                "device": "cpu",
                "pin_memory": True
            }},
            "overlap_comm": True,
            "contiguous_gradients": True,
            "reduce_bucket_size": 5e7,
            "stage3_prefetch_bucket_size": 5e7,
            "stage3_param_persistence_threshold": 1e5
        }}
    }}
    
    # DeepSpeed ì´ˆê¸°í™”
    deepspeed.init_distributed()
    
    with deepspeed.zero.Init(config_dict_or_path=ds_config):
        config = AutoConfig.from_pretrained(model_name, trust_remote_code=True)
        model = AutoModelForCausalLM.from_pretrained(
            model_name,
            config=config,
            torch_dtype=torch.bfloat16,
            trust_remote_code=True,
        )
    
    # SPECTRA injection (í™˜ê²½ ë³€ìˆ˜ì— ë”°ë¼ ë¹„í™œì„±í™”ë  ìˆ˜ ìˆìŒ)
    if os.environ.get("SPECTRA_DISABLE_ALL") != "1":
        print("[TEST] Injecting SPECTRA...")
        spectra_config = SPECTRATextConfig(**full_config["model_config"]["spectra_params"])
        spectra_config.hidden_size = config.text_config.hidden_size
        injector = SPECTRAExoskeletonMoEInjector(spectra_config)
        model = injector.inject(model)
    else:
        print("[TEST] SPECTRA disabled, using original Qwen3 MoE")
    
    # DeepSpeed ì—”ì§„ ì´ˆê¸°í™”
    model_engine, _, _, _ = deepspeed.initialize(
        model=model,
        config=ds_config,
        model_parameters=model.parameters()
    )
    
    model_engine.train()
    
    # ë”ë¯¸ ì…ë ¥ ìƒì„±
    print("[TEST] Creating dummy input...")
    batch_size = 1
    seq_len = 128  # ì§§ì€ ì‹œí€€ìŠ¤ë¡œ í…ŒìŠ¤íŠ¸
    
    input_ids = torch.randint(0, 1000, (batch_size, seq_len), device="cuda")
    attention_mask = torch.ones_like(input_ids)
    labels = input_ids.clone()
    
    # Forward pass
    print("[TEST] Running forward pass...")
    outputs = model_engine(
        input_ids=input_ids,
        attention_mask=attention_mask,
        labels=labels,
    )
    loss = outputs.loss
    print(f"[TEST] Forward pass completed. Loss: {{loss.item():.4f}}")
    
    # Backward pass
    print("[TEST] Running backward pass...")
    model_engine.backward(loss)
    print("[TEST] Backward pass completed successfully!")
    
    # ì„±ê³µ
    print("[TEST] âœ… TEST PASSED")
    sys.exit(0)
    
except Exception as e:
    print(f"[TEST] âŒ TEST FAILED: {{type(e).__name__}}: {{str(e)}}")
    import traceback
    traceback.print_exc()
    
    # íŠ¹ì • ì—ëŸ¬ ì²´í¬
    error_str = str(e)
    if "size of tensor a (0)" in error_str and "size of tensor b (2048)" in error_str:
        print("[TEST] ERROR_TYPE: tensor_size_mismatch_0_vs_2048")
    elif "CUDA out of memory" in error_str or "OutOfMemoryError" in error_str:
        print("[TEST] ERROR_TYPE: cuda_oom")
    else:
        print(f"[TEST] ERROR_TYPE: other")
    
    sys.exit(1)
'''


def run_test(test_config: dict) -> dict:
    """ë‹¨ì¼ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    result = {
        "name": test_config["name"],
        "description": test_config["description"],
        "status": "unknown",
        "error_message": None,
        "error_type": None,
        "duration_seconds": 0,
        "start_time": datetime.now().isoformat(),
    }
    
    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì½”ë“œ ìƒì„±
    env_setup_lines = []
    for k, v in test_config.get("env_vars", {}).items():
        env_setup_lines.append(f'os.environ["{k}"] = "{v}"')
    env_setup = "\n".join(env_setup_lines)
    
    # í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
    test_script = QUICK_TEST_SCRIPT.format(
        env_setup=env_setup,
        test_name=test_config["name"],
        workspace=WORKSPACE,
    )
    
    # ì„ì‹œ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ìƒì„±
    script_path = f"{WORKSPACE}/_temp_component_test.py"
    with open(script_path, "w") as f:
        f.write(test_script)
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    cmd = [
        "bash", "-c",
        f"source /home/conan/miniconda3/etc/profile.d/conda.sh && "
        f"conda activate llm_train && "
        f"cd {WORKSPACE} && "
        f"python {script_path}"
    ]
    
    start_time = time.time()
    try:
        process = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=TEST_CONFIG["timeout_seconds"]
        )
        
        result["duration_seconds"] = time.time() - start_time
        output = process.stdout + process.stderr
        
        # ê²°ê³¼ ë¶„ì„
        if "âœ… TEST PASSED" in output:
            result["status"] = "PASSED"
        elif "ERROR_TYPE: tensor_size_mismatch_0_vs_2048" in output:
            result["status"] = "FAILED"
            result["error_type"] = "tensor_size_mismatch"
            result["error_message"] = "tensor a (0) vs tensor b (2048)"
        elif "ERROR_TYPE: cuda_oom" in output:
            result["status"] = "OOM"
            result["error_type"] = "cuda_oom"
            result["error_message"] = "CUDA out of memory"
        elif "âŒ TEST FAILED" in output:
            result["status"] = "FAILED"
            # ì—ëŸ¬ ë©”ì‹œì§€ ì¶”ì¶œ
            for line in output.split("\n"):
                if "TEST FAILED:" in line:
                    result["error_message"] = line.split("TEST FAILED:")[-1].strip()[:200]
                    break
        else:
            result["status"] = "FAILED"
            result["error_message"] = f"Unknown error (exit code: {process.returncode})"
            
    except subprocess.TimeoutExpired:
        result["status"] = "TIMEOUT"
        result["error_message"] = f"Test timed out after {TEST_CONFIG['timeout_seconds']} seconds"
        result["duration_seconds"] = TEST_CONFIG["timeout_seconds"]
    except Exception as e:
        result["status"] = "ERROR"
        result["error_message"] = str(e)
        result["duration_seconds"] = time.time() - start_time
    
    # ì„ì‹œ íŒŒì¼ ì‚­ì œ
    try:
        os.remove(script_path)
    except:
        pass
    
    result["end_time"] = datetime.now().isoformat()
    return result


def generate_report(results: list) -> str:
    """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
    report = []
    report.append("# SPECTRA ì»´í¬ë„ŒíŠ¸ ì ê²€ ë¦¬í¬íŠ¸")
    report.append(f"\n**ìƒì„± ì‹œê°„**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report.append(f"\n**ì—ëŸ¬ íƒ€ì…**: `RuntimeError: The size of tensor a (0) must match the size of tensor b (2048)`")
    
    report.append("\n## ìš”ì•½")
    
    passed = sum(1 for r in results if r["status"] == "PASSED")
    failed = sum(1 for r in results if r["status"] == "FAILED")
    other = len(results) - passed - failed
    
    report.append(f"\n| í•­ëª© | ê°’ |")
    report.append(f"|------|-----|")
    report.append(f"| ì´ í…ŒìŠ¤íŠ¸ | {len(results)} |")
    report.append(f"| ì„±ê³µ | {passed} |")
    report.append(f"| ì‹¤íŒ¨ | {failed} |")
    report.append(f"| ê¸°íƒ€ | {other} |")
    
    report.append("\n## ìƒì„¸ ê²°ê³¼")
    report.append("\n| ì»´í¬ë„ŒíŠ¸ | ì„¤ëª… | ìƒíƒœ | ì†Œìš” ì‹œê°„ | ì—ëŸ¬ |")
    report.append("|----------|------|------|----------|------|")
    
    for r in results:
        status_emoji = {
            "PASSED": "âœ…",
            "FAILED": "âŒ",
            "OOM": "ğŸ’¾",
            "TIMEOUT": "â°",
            "ERROR": "ğŸ”¥",
        }.get(r["status"], "â“")
        
        error_msg = r.get("error_message", "-") or "-"
        if len(error_msg) > 50:
            error_msg = error_msg[:50] + "..."
        
        report.append(f"| `{r['name']}` | {r['description']} | {status_emoji} {r['status']} | {r['duration_seconds']:.1f}s | {error_msg} |")
    
    report.append("\n## ë¶„ì„")
    
    # ë¬¸ì œ ì»´í¬ë„ŒíŠ¸ ì‹ë³„
    baseline_passed = any(r["name"] == "baseline_no_spectra" and r["status"] == "PASSED" for r in results)
    full_spectra_failed = any(r["name"] == "full_spectra" and r["status"] == "FAILED" for r in results)
    
    if baseline_passed:
        report.append("\n### ë°œê²¬ ì‚¬í•­")
        report.append("- âœ… **SPECTRA ì—†ì´ Qwen3 MoEëŠ” ì •ìƒ ì‘ë™** (baseline í…ŒìŠ¤íŠ¸ í†µê³¼)")
        
        if full_spectra_failed:
            report.append("- âŒ **SPECTRA ì „ì²´ í™œì„±í™” ì‹œ ì—ëŸ¬ ë°œìƒ**")
            
            # ë¬¸ì œ ì»´í¬ë„ŒíŠ¸ ì‹ë³„
            report.append("\n### ë¬¸ì œ ì»´í¬ë„ŒíŠ¸ ì‹ë³„")
            
            problem_found = False
            for r in results:
                if r["name"] not in ["baseline_no_spectra", "full_spectra"]:
                    if r["status"] == "PASSED":
                        report.append(f"- ğŸ¯ **`{r['name']}`** ë¹„í™œì„±í™” ì‹œ ì •ìƒ ì‘ë™")
                        report.append(f"  - â†’ **ì´ ì»´í¬ë„ŒíŠ¸({r['description']})ê°€ ë¬¸ì œì˜ ì›ì¸!**")
                        problem_found = True
                    elif r["status"] == "FAILED":
                        report.append(f"- âš ï¸ `{r['name']}` ë¹„í™œì„±í™”í•´ë„ ì—¬ì „íˆ ì—ëŸ¬ ë°œìƒ")
            
            if not problem_found:
                report.append("- âš ï¸ ë‹¨ì¼ ì»´í¬ë„ŒíŠ¸ ë¹„í™œì„±í™”ë¡œëŠ” ë¬¸ì œ í•´ê²° ë¶ˆê°€")
                report.append("- â†’ **ë³µí•©ì ì¸ ë¬¸ì œ ë˜ëŠ” ì—¬ëŸ¬ ì»´í¬ë„ŒíŠ¸ ë™ì‹œ ë¹„í™œì„±í™” í•„ìš”**")
    else:
        report.append("\n### âš ï¸ ì£¼ì˜")
        report.append("- baseline í…ŒìŠ¤íŠ¸(SPECTRA ì—†ì´ Qwen3 MoE)ë„ ì‹¤íŒ¨")
        report.append("- ë¬¸ì œê°€ SPECTRAê°€ ì•„ë‹Œ ë‹¤ë¥¸ ê³³ì— ìˆì„ ìˆ˜ ìˆìŒ")
    
    report.append("\n## ê¶Œì¥ ì‚¬í•­")
    
    # ë¬¸ì œ ì»´í¬ë„ŒíŠ¸ì— ëŒ€í•œ ê¶Œì¥ ì‚¬í•­
    for r in results:
        if r["name"] not in ["baseline_no_spectra", "full_spectra"] and r["status"] == "PASSED":
            report.append(f"\n### `{r['name']}` ìˆ˜ì • í•„ìš”")
            report.append(f"- **ë¬¸ì œ ì»´í¬ë„ŒíŠ¸**: {r['description']}")
            report.append("- **í•´ê²° ë°©ì•ˆ**:")
            report.append("  1. DeepSpeed ZeRO-3ì™€ í˜¸í™˜ë˜ë„ë¡ ì¬ì„¤ê³„")
            report.append("  2. backward ì¤‘ tensor shape ë¶ˆì¼ì¹˜ ì›ì¸ ë¶„ì„")
            report.append("  3. ë¶„ì‚° íŒŒë¼ë¯¸í„° ì ‘ê·¼ ë°©ì‹ ìˆ˜ì •")
            break
    
    report.append("\n---")
    report.append(f"\n*ì´ ë¦¬í¬íŠ¸ëŠ” ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*")
    
    return "\n".join(report)


def main():
    print("=" * 70)
    print("SPECTRA ì»´í¬ë„ŒíŠ¸ ìë™ ì ê²€ ì‹œì‘")
    print("=" * 70)
    print(f"í…ŒìŠ¤íŠ¸ ê°œìˆ˜: {len(COMPONENT_TESTS)}")
    print(f"íƒ€ì„ì•„ì›ƒ: {TEST_CONFIG['timeout_seconds']}ì´ˆ")
    print("=" * 70)
    
    results = []
    
    for i, test in enumerate(COMPONENT_TESTS):
        print(f"\n{'='*70}")
        print(f"[{i+1}/{len(COMPONENT_TESTS)}] í…ŒìŠ¤íŠ¸: {test['name']}")
        print(f"  ì„¤ëª…: {test['description']}")
        print(f"  í™˜ê²½ ë³€ìˆ˜: {test.get('env_vars', {})}")
        print(f"  ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%H:%M:%S')}")
        print("-" * 70)
        
        result = run_test(test)
        results.append(result)
        
        status_emoji = {"PASSED": "âœ…", "FAILED": "âŒ", "OOM": "ğŸ’¾", "TIMEOUT": "â°"}.get(result["status"], "â“")
        print(f"\n  ê²°ê³¼: {status_emoji} {result['status']}")
        if result["error_message"]:
            print(f"  ì—ëŸ¬: {result['error_message'][:100]}")
        print(f"  ì†Œìš” ì‹œê°„: {result['duration_seconds']:.1f}ì´ˆ")
        
        # ì¤‘ê°„ ê²°ê³¼ ì €ì¥
        with open(TEST_CONFIG["report_path"] + ".json", "w") as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
    
    # ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±
    report = generate_report(results)
    with open(TEST_CONFIG["report_path"], "w") as f:
        f.write(report)
    
    print("\n" + "=" * 70)
    print("ì ê²€ ì™„ë£Œ!")
    print(f"ë¦¬í¬íŠ¸ ì €ì¥ ìœ„ì¹˜: {TEST_CONFIG['report_path']}")
    print("=" * 70)
    
    # ë¦¬í¬íŠ¸ ì¶œë ¥
    print("\n" + report)


if __name__ == "__main__":
    main()
