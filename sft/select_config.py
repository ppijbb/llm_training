#!/usr/bin/env python3
"""
Configuration Selector for G3MoE SFT Training
Based on Google's Gemini fine-tuning guidelines
"""

import os
import sys
import json
import argparse
from typing import Dict, Any

def analyze_dataset_characteristics(dataset_path: str = None, dataset_name: str = None) -> Dict[str, Any]:
    """
    Analyze dataset characteristics to recommend appropriate config
    """
    try:
        if dataset_name:
            # For HF Hub datasets, provide general estimates
            if dataset_name == "Gunulhona/open_m_3":
                return {
                    "estimated_size": 10000,
                    "avg_context_length": 800,
                    "recommendation": "large"
                }
            else:
                print(f"Unknown dataset: {dataset_name}")
                return {"estimated_size": 1000, "avg_context_length": 500, "recommendation": "small"}
        
        if dataset_path and os.path.exists(dataset_path):
            # Analyze local JSONL file
            import json
            examples = []
            with open(dataset_path, 'r', encoding='utf-8') as f:
                for line in f:
                    try:
                        examples.append(json.loads(line.strip()))
                        if len(examples) >= 1000:  # Sample first 1000 for analysis
                            break
                    except:
                        continue
            
            total_examples = len(examples)
            if examples:
                # Estimate average context length
                avg_length = sum(len(str(ex)) for ex in examples) / len(examples)
                return {
                    "estimated_size": total_examples,
                    "avg_context_length": avg_length // 4,  # Rough token estimate
                    "recommendation": "large" if total_examples >= 1000 or avg_length >= 2000 else "small"
                }
    
    except Exception as e:
        print(f"Error analyzing dataset: {e}")
    
    # Default fallback
    return {"estimated_size": 1000, "avg_context_length": 500, "recommendation": "small"}

def get_config_recommendation(dataset_size: int, avg_context_length: int) -> str:
    """
    Get configuration recommendation based on Google guidelines and context length
    """
    if avg_context_length >= 50000:  # Very long context (50K+ tokens)
        return "120k_deepspeed"
    elif dataset_size < 1000 and avg_context_length < 500:
        return "small"
    else:
        return "large"

def display_recommendations():
    """
    Display Google's official recommendations
    """
    print("ğŸ¯ Google Gemini Fine-tuning Guidelines")
    print("=" * 50)
    
    print("\nğŸ“Š ì†Œê·œëª¨ ë°ì´í„°ì…‹ (< 1000ê°œ ì˜ˆì œ, í‰ê·  ì»¨í…ìŠ¤íŠ¸ < 500í† í°):")
    print("   â€¢ Epochs: 20")
    print("   â€¢ Learning Rate: 2e-4 (10x multiplier)")
    print("   â€¢ LoRA Rank: 4")
    print("   â€¢ Max Sequence Length: 1024")
    print("   â€¢ Config: sft/config/g3moe_small_dataset_config.json")
    
    print("\nğŸ“Š ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ (>= 1000ê°œ ì˜ˆì œ ë˜ëŠ” í‰ê·  ì»¨í…ìŠ¤íŠ¸ >= 500í† í°):")
    print("   â€¢ Epochs: 10")
    print("   â€¢ Learning Rate: 1e-4 (5x multiplier)")
    print("   â€¢ LoRA Rank: 8")
    print("   â€¢ Max Sequence Length: 120000")
    print("   â€¢ Config: sft/config/g3moe_large_dataset_config.json")
    
    print("\nğŸš€ ì´ˆì¥ë¬¸ ì»¨í…ìŠ¤íŠ¸ (>= 50K í† í°, DeepSpeed í•„ìˆ˜):")
    print("   â€¢ Epochs: 5")
    print("   â€¢ Learning Rate: 5e-5")
    print("   â€¢ LoRA Rank: 16")
    print("   â€¢ Max Sequence Length: 120000")
    print("   â€¢ DeepSpeed: ZeRO-3 + CPU Offload")
    print("   â€¢ Config: sft/config/g3moe_120k_deepspeed_config.json")
    
    print("\nğŸ”‘ í•µì‹¬ ì›ì¹™:")
    print("   â€¢ í’ˆì§ˆ > ì–‘: ê³ í’ˆì§ˆ ì†Œê·œëª¨ ë°ì´í„°ì…‹ì´ ë” íš¨ê³¼ì ")
    print("   â€¢ LoRA í™œìš©: ë©”ëª¨ë¦¬ íš¨ìœ¨ì  fine-tuning")
    print("   â€¢ ë³µì¡í•œ ì˜ˆì œ ì¤‘ì‹¬: ê¸°ë³¸ ëª¨ë¸ì´ ì–´ë ¤ì›Œí•˜ëŠ” ì¼€ì´ìŠ¤ì— ì§‘ì¤‘")
    print("   â€¢ ê²€ì¦ ë°ì´í„°ì…‹: ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•œ í•„ìˆ˜ ìš”ì†Œ")

def main():
    parser = argparse.ArgumentParser(description="Select optimal G3MoE SFT configuration")
    parser.add_argument("--dataset-name", type=str, help="HuggingFace dataset name")
    parser.add_argument("--dataset-path", type=str, help="Local dataset file path")
    parser.add_argument("--dataset-size", type=int, help="Manual dataset size")
    parser.add_argument("--avg-context-length", type=int, help="Manual average context length")
    parser.add_argument("--show-guidelines", action="store_true", help="Show Google guidelines")
    
    args = parser.parse_args()
    
    if args.show_guidelines:
        display_recommendations()
        return
    
    print("ğŸš€ G3MoE SFT Configuration Selector")
    print("=" * 40)
    
    # Analyze dataset characteristics
    if args.dataset_size and args.avg_context_length:
        analysis = {
            "estimated_size": args.dataset_size,
            "avg_context_length": args.avg_context_length,
            "recommendation": get_config_recommendation(args.dataset_size, args.avg_context_length)
        }
    else:
        analysis = analyze_dataset_characteristics(args.dataset_path, args.dataset_name)
    
    print(f"\nğŸ“Š ë°ì´í„°ì…‹ ë¶„ì„ ê²°ê³¼:")
    print(f"   â€¢ ì˜ˆìƒ ë°ì´í„°ì…‹ í¬ê¸°: {analysis['estimated_size']:,}ê°œ")
    print(f"   â€¢ í‰ê·  ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {analysis['avg_context_length']:,}í† í°")
    
    # Get recommendation
    recommendation = analysis['recommendation']
    
    print(f"\nğŸ¯ ê¶Œì¥ ì„¤ì •: {recommendation.upper()} dataset configuration")
    
    if recommendation == "small":
        config_file = "sft/config/g3moe_small_dataset_config.json"
        print(f"   â€¢ ì„¤ì • íŒŒì¼: {config_file}")
        print(f"   â€¢ ì‹¤í–‰ ëª…ë ¹: ./sft/run_g3moe_sft.sh {config_file}")
        print("\nğŸ“‹ ì„¤ì • ì„¸ë¶€ì‚¬í•­:")
        print("   â€¢ Epochs: 20")
        print("   â€¢ Learning Rate: 2e-4")
        print("   â€¢ LoRA Rank: 4")
        print("   â€¢ Batch Size: 2")
        print("   â€¢ Max Sequence Length: 120000")
    elif recommendation == "120k_deepspeed":
        config_file = "sft/config/g3moe_120k_deepspeed_config.json"
        print(f"   â€¢ ì„¤ì • íŒŒì¼: {config_file}")
        print(f"   â€¢ ì‹¤í–‰ ëª…ë ¹: ./sft/run_g3moe_deepspeed.sh {config_file}")
        print("\nğŸ“‹ ì„¤ì • ì„¸ë¶€ì‚¬í•­:")
        print("   â€¢ Epochs: 5")
        print("   â€¢ Learning Rate: 5e-5")
        print("   â€¢ LoRA Rank: 16")
        print("   â€¢ Batch Size: 1")
        print("   â€¢ Max Sequence Length: 120000")
        print("   â€¢ DeepSpeed: ZeRO-3 (CPU Offload)")
        print("   â€¢ GPU ìš”êµ¬ì‚¬í•­: 80GB+ VRAM")
        print("   â€¢ RAM ìš”êµ¬ì‚¬í•­: 64GB+ System RAM")
    else:
        config_file = "sft/config/g3moe_large_dataset_config.json"
        print(f"   â€¢ ì„¤ì • íŒŒì¼: {config_file}")
        print(f"   â€¢ ì‹¤í–‰ ëª…ë ¹: ./sft/run_g3moe_deepspeed.sh {config_file}")
        print("\nğŸ“‹ ì„¤ì • ì„¸ë¶€ì‚¬í•­:")
        print("   â€¢ Epochs: 10")
        print("   â€¢ Learning Rate: 1e-4")
        print("   â€¢ LoRA Rank: 8")
        print("   â€¢ Batch Size: 1")
        print("   â€¢ Max Sequence Length: 120000")
        print("   â€¢ DeepSpeed: ZeRO-3")
    
    print(f"\nğŸ’¡ ì„¤ì • íŒŒì¼ í™•ì¸:")
    if os.path.exists(config_file):
        print(f"   âœ… {config_file} íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤.")
    else:
        print(f"   âŒ {config_file} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("   ë¨¼ì € ì„¤ì • íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
    
    print(f"\nğŸ”— ì°¸ê³ ìë£Œ:")
    print("   â€¢ Google Gemini Fine-tuning Guide:")
    print("     https://medium.com/google-cloud/fine-tuning-gemini-best-practices-for-data-hyperparameters-and-evaluation-65f7c7b6b15f")

if __name__ == "__main__":
    main() 